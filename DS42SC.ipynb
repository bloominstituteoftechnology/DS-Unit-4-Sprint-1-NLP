{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpPcbYew_ttN"
   },
   "source": [
    "# Part 1 - Working with Text Data\n",
    "\n",
    "### Use Python string methods remove irregular whitespace from the following string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "dtotEnsStY5o",
    "outputId": "c4e8a355-5366-4b7a-ddf8-740e9f1fbc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  This is a    string   that has  \n",
      " a lot of  extra \n",
      "   whitespace.   \n"
     ]
    }
   ],
   "source": [
    "whitespace_string = \"\\n\\n  This is a    string   that has  \\n a lot of  extra \\n   whitespace.   \"\n",
    "\n",
    "print(whitespace_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9-MkBwasXx8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a string that has a lot of extra whitespace.\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(whitespace_string.split()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vg1-d2aAsXLn"
   },
   "source": [
    "### Use Regular Expressions to take the dates in the following .txt file and put them into a dataframe with columns for:\n",
    "\n",
    "[RegEx dates.txt](https://github.com/ryanleeallred/datasets/blob/master/dates.txt)\n",
    "\n",
    "- Day\n",
    "- Month\n",
    "- Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWDiN4C9_0sq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'March 8, 2015\\nMarch 15, 2015\\nMarch 22, 2015\\nMarch 29, 2015\\nApril 5, 2015\\nApril 12, 2015\\nApril 19, 2015\\nApril 26, 2015\\nMay 3, 2015\\nMay 10, 2015\\nMay 17, 2015\\nMay 24, 2015\\nMay 31, 2015\\nJune 7, 2015\\nJune 14, 2015\\nJune 21, 2015\\nJune 28, 2015\\nJuly 5, 2015\\nJuly 12, 2015\\nJuly 19, 2015'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dates.txt', 'r', encoding='utf-8') as f:\n",
    "  contents = f.read()\n",
    "  \n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('March', '8', '2015')\n",
      "('March', '15', '2015')\n",
      "('March', '22', '2015')\n",
      "('March', '29', '2015')\n",
      "('April', '5', '2015')\n",
      "('April', '12', '2015')\n",
      "('April', '19', '2015')\n",
      "('April', '26', '2015')\n",
      "('May', '3', '2015')\n",
      "('May', '10', '2015')\n",
      "('May', '17', '2015')\n",
      "('May', '24', '2015')\n",
      "('May', '31', '2015')\n",
      "('June', '7', '2015')\n",
      "('June', '14', '2015')\n",
      "('June', '21', '2015')\n",
      "('June', '28', '2015')\n",
      "('July', '5', '2015')\n",
      "('July', '12', '2015')\n",
      "('July', '19', '2015')\n"
     ]
    }
   ],
   "source": [
    "regex = r\"([a-zA-Z]+) (\\d+), (\\d\\d\\d\\d)\" \n",
    "\n",
    "search_result = re.findall(regex, contents)\n",
    "\n",
    "for match in search_result:\n",
    "  print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>March</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>March</td>\n",
       "      <td>15</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March</td>\n",
       "      <td>22</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>March</td>\n",
       "      <td>29</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>April</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>April</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>April</td>\n",
       "      <td>19</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>April</td>\n",
       "      <td>26</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>May</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>May</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>May</td>\n",
       "      <td>17</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>May</td>\n",
       "      <td>24</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>May</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>June</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>June</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>June</td>\n",
       "      <td>21</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>June</td>\n",
       "      <td>28</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>July</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>July</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>July</td>\n",
       "      <td>19</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month Day  Year\n",
       "0   March   8  2015\n",
       "1   March  15  2015\n",
       "2   March  22  2015\n",
       "3   March  29  2015\n",
       "4   April   5  2015\n",
       "5   April  12  2015\n",
       "6   April  19  2015\n",
       "7   April  26  2015\n",
       "8     May   3  2015\n",
       "9     May  10  2015\n",
       "10    May  17  2015\n",
       "11    May  24  2015\n",
       "12    May  31  2015\n",
       "13   June   7  2015\n",
       "14   June  14  2015\n",
       "15   June  21  2015\n",
       "16   June  28  2015\n",
       "17   July   5  2015\n",
       "18   July  12  2015\n",
       "19   July  19  2015"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDate = pd.DataFrame(search_result, columns=['Month', 'Day','Year'])\n",
    "dfDate.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4Q0dgoe_uBW"
   },
   "source": [
    "# Part 2 - Bag of Words \n",
    "\n",
    "### Use the twitter sentiment analysis dataset found at this link for the remainder of the Sprint Challenge:\n",
    "\n",
    "[Twitter Sentiment Analysis Dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/twitter_sentiment_binary.csv)\n",
    "\n",
    " ### Clean and tokenize the documents ensuring the following properties of the text:\n",
    "\n",
    "1) Text should be lowercase.\n",
    "\n",
    "2) Stopwords should be removed.\n",
    "\n",
    "3) Punctuation should be removed.\n",
    "\n",
    "4) Tweets should be tokenized at the word level. \n",
    "\n",
    "(The above don't necessarily need to be completed in that specific order.)\n",
    "\n",
    "### Output some cleaned tweets so that we can see that you made all of the above changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xzdhyTS_3F9"
   },
   "outputs": [],
   "source": [
    "#  \n",
    "url='https://raw.githubusercontent.com/ryanleeallred/datasets/master/twitter_sentiment_binary.csv'\n",
    "df=pd.read_csv(url)\n",
    "df.head()\n",
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SentimentText'] = df['SentimentText'].str.lower()\n",
    "df.head()\n",
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "table = str.maketrans('','', string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my apl frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i missed the new moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. omgaga. im sooo  im gunna cry. i'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                       is so sad for my apl frie...\n",
       "1          0                     i missed the new moon trail...\n",
       "2          1                            omg its already 7:30 :o\n",
       "3          0            .. omgaga. im sooo  im gunna cry. i'...\n",
       "4          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df2.copy()\n",
    "def clean_doc(doc):\n",
    "\t# split into tokens by white space\n",
    "\t#tokens = str(doc).split(' ')\n",
    "    tokens = word_tokenize(doc)\n",
    "    #  lowercase\n",
    "    lowercase_tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each token\n",
    "    no_punctuation = [w.translate(table) for w in lowercase_tokens]\n",
    "    # Remove words that aren't alphabetic\n",
    "    alphabetic = [word for word in no_punctuation if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    words = [w for w in alphabetic if not w in stop_words]\n",
    "\t# filter out short tokens\n",
    "\t#tokens = [word for word in words if len(word)>1]\n",
    "    return words\n",
    "\n",
    "df['SentimentText'] = df['SentimentText'].apply(clean_doc)\n",
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SentimentText'] = df.SentimentText.apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>missed new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>omgaga im sooo im gunna cry dentist since supo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>think mi bf cheating tt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                                     sad apl friend\n",
       "1          0                            missed new moon trailer\n",
       "2          1                                        omg already\n",
       "3          0  omgaga im sooo im gunna cry dentist since supo...\n",
       "4          0                            think mi bf cheating tt"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q764vszGqiUh"
   },
   "source": [
    "### How should TF-IDF scores be interpreted? How are they calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2Ji7BMhqs3M"
   },
   "source": [
    "#### Term Frequency / Inverse Document Frequency  #####\n",
    "\n",
    "Term Frequency: Percentage of words in document for each word\n",
    "  TF = num of times word occurs (frequency) divided by the total num of word in   the document\n",
    "\n",
    "Inverse Document Frequency: A penalty for the word existing in a high number of documents.\n",
    "    IDF = log2(total-#-documents/ #-documents-including-word )\n",
    "\n",
    "TF-IDF weighs a keyword in any content and assigns the importance to that keyword based on the number of times it appears in the document. It also checks how relevant the keyword is. Each word has its respective TF and IDF score. The product of the TF and IDF scores of a term is called the TF-IDF weight of that term.\n",
    "\n",
    "Put simply, the higher the TF-IDF score (weight), the rarer the term and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3iUeBKtG_uEK"
   },
   "source": [
    "# Part 3 - Document Classification\n",
    "\n",
    "1) Use Train_Test_Split to create train and test datasets.\n",
    "\n",
    "2) Vectorize the tokenized documents using your choice of vectorization method. \n",
    "\n",
    " - Stretch goal: Use both of the methods that we talked about in class.\n",
    "\n",
    "3) Create a vocabulary using the X_train dataset and transform both your X_train and X_test data using that vocabulary.\n",
    "\n",
    "4) Use your choice of binary classification algorithm to train and evaluate your model's accuracy. Report both train and test accuracies.\n",
    "\n",
    " - Stretch goal: Use an error metric other than accuracy and implement/evaluate multiple classifiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TX8OEgUP_3ee"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.SentimentText.tolist()\n",
    "y = df.Sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ca': 351, 'nt': 1533, 'sleep': 1973, 'suggest': 2099, 'watching': 2370, 'quot': 1749, 'girlfriend': 925, 'experience': 770, 'ii': 1127, 'school': 1873, 'haha': 986, 'reminding': 1794, 'case': 380, 'forgot': 875, 'la': 1243, 'love': 1344, 'country': 531, 'music': 1481, 'little': 1309, 'cake': 355, 'got': 951, 'ta': 2134, 'dont': 664, 'know': 1237, 'coffee': 467, 'changes': 401, 'colour': 473, 'lt': 1351, 'gt': 972, 'everybody': 749, 'dancing': 587, 'pop': 1675, 'twitpic': 2286, 'working': 2437, 'photo': 1627, 'alas': 55, 'wan': 2354, 'na': 1486, 'hear': 1031, 'brian': 308, 'bet': 227, 'cute': 572, 'like': 1293, 'voice': 2341, 'friend': 890, 'told': 2218, 'youtube': 2491, 'video': 2333, 'download': 669, 'testing': 2168, 'finished': 841, 'noticed': 1531, 'replied': 1797, 'week': 2386, 'ago': 35, 'speed': 2030, 'http': 1105, 'time': 2208, 'long': 1326, 'failed': 782, 'party': 1602, 'dinner': 645, 'kinda': 1227, 'thing': 2184, 'sign': 1946, 'good': 943, 'night': 1513, 'sun': 2104, 'rise': 1823, 'way': 2374, 'terrible': 2166, 'address': 23, 'sniff': 1991, 'sunny': 2106, 'today': 2217, 'ooooh': 1566, 'yes': 2482, 'dammit': 583, 'sigh': 1944, 'cool': 519, 'things': 2185, 'happening': 1005, 'heyy': 1055, 'hot': 1096, 'day': 602, 'event': 746, 'balls': 190, 'fly': 856, 'wide': 2401, 'right': 1820, 'doctor': 657, 'lol': 1322, 'new': 1507, 'nice': 1510, 'meet': 1404, 'happy': 1008, 'mother': 1465, 'sad': 1847, 'step': 2063, 'come': 474, 'mommy': 1454, 'makes': 1369, 'mad': 1362, 'yeah': 2474, 'remember': 1791, 'hoping': 1091, 'fell': 818, 'amy': 85, 'chat': 409, 'hon': 1083, 'xxx': 2465, 'yep': 2480, 'think': 2187, 'old': 1554, 'far': 795, 'eh': 711, 'exams': 757, 'im': 1130, 'leaving': 1276, 'group': 966, 'car': 372, 'club': 463, 'traffic': 2242, 'drinking': 680, 'wine': 2409, 'buying': 348, 'iphone': 1158, 'ahhh': 44, 'really': 1770, 'want': 2356, 'pictures': 1636, 'badly': 186, 'shows': 1940, 'bad': 185, 'ones': 1557, 'rip': 1822, 'miss': 1440, 'favorite': 804, 'teacher': 2153, 'important': 1135, 'person': 1618, 'wo': 2420, 'help': 1047, 'lose': 1336, 'following': 868, 'amp': 84, 'woot': 2431, 'tummy': 2267, 'hurts': 1117, 'goodnight': 946, 'twitter': 2287, 'looks': 1333, 'gon': 941, 'trade': 2241, 'wont': 2428, 'let': 1282, 'bc': 208, 'original': 1575, 'thinking': 2188, 'homework': 1081, 'building': 334, 'oh': 1547, 'son': 2002, 'gun': 978, 'realize': 1768, 'sry': 2043, 'congrats': 500, 'graduation': 957, 'sweetie': 2127, 'loved': 1345, 'high': 1059, 'ok': 1551, 'beautiful': 215, 'woman': 2423, 'rock': 1827, 'thanks': 2177, 'sharing': 1915, 'xo': 2461, 'said': 1851, 'blue': 270, 'work': 2434, 'goin': 937, 'amberbenson': 80, 'afford': 28, 'year': 2476, 'gunna': 979, 'read': 1761, 'talk': 2142, 'tomorrow': 2220, 'awww': 172, 'poor': 1674, 'hope': 1089, 'feel': 812, 'better': 230, 'soon': 2006, 'used': 2321, 'phone': 1625, 'cell': 392, 'booo': 282, 'calvinharris': 363, 'met': 1417, 'pleasure': 1659, 'hi': 1057, 'huge': 1108, 'fan': 791, 'amazing': 77, 'respond': 1805, 'make': 1368, 'going': 938, 'fantastic': 794, 'start': 2051, 'sunday': 2105, 'king': 1228, 'gone': 942, 'probably': 1707, 'attack': 149, 'expect': 766, 'follow': 863, 'feels': 816, 'left': 1277, 'lonely': 1325, 'getting': 920, 'hang': 999, 'song': 2003, 'favourite': 805, 'crazy': 545, 'bit': 247, 'weird': 2391, 'different': 641, 'men': 1410, 'sell': 1894, 'hair': 994, 'yoga': 2487, 'use': 2320, 'need': 1500, 'free': 885, 'stock': 2066, 'great': 961, 'looking': 1332, 'fixed': 847, 'grand': 958, 'bits': 251, 'appreciate': 117, 'rain': 1753, 'wanted': 2357, 'ya': 2467, 'morning': 1464, 'wednesday': 2384, 'food': 870, 'french': 886, 'ended': 720, 'field': 824, 'walk': 2350, 'end': 719, 'send': 1896, 'pm': 1665, 'ask': 137, 'people': 1614, 'invite': 1155, 'yum': 2497, 'worth': 2446, 'dude': 688, 'mr': 1473, 'sir': 1959, 'coming': 480, 'waiting': 2347, 'beta': 228, 'post': 1681, 'wait': 2346, 'longer': 1327, 'doin': 661, 'xbox': 2459, 'play': 1652, 'finally': 834, 'asleep': 140, 'wow': 2448, 'speak': 2027, 'truth': 2259, 'dear': 608, 'thank': 2176, 'welcome': 2392, 'fix': 846, 'face': 778, 'bass': 200, 'whats': 2397, 'ur': 2317, 'buddy': 331, 'slept': 1976, 'father': 800, 'eat': 703, 'birthday': 246, 'followers': 866, 'thats': 2180, 'life': 1289, 'plan': 1647, 'nights': 1515, 'awe': 165, 'yess': 2483, 'able': 0, 'big': 235, 'house': 1100, 'loads': 1318, 'fun': 901, 'officially': 1546, 'dress': 677, 'alexandramusic': 61, 'singing': 1956, 'moment': 1453, 'white': 2398, 'cars': 379, 'usually': 2328, 'prefer': 1693, 'alexalltimelow': 60, 'signing': 1948, 'stuff': 2091, 'awkward': 170, 'sorry': 2013, 'convince': 513, 'lovely': 1346, 'job': 1186, 'site': 1964, 'look': 1329, 'thai': 2175, 'seriously': 1902, 'hours': 1099, 'friday': 889, 'fair': 783, 'sore': 2012, 'feet': 817, 'arms': 125, 'loose': 1334, 'jimmy': 1184, 'lady': 1246, 'tired': 2212, 'playing': 1656, 'sister': 1961, 'hahahaha': 991, 'understand': 2303, 'trying': 2262, 'followfriday': 867, 'guys': 982, 'girl': 924, 'gave': 909, 'bands': 193, 'hahaha': 989, 'hugs': 1109, 'wish': 2416, 'el': 712, 'fail': 781, 'worry': 2443, 'friends': 892, 'aww': 171, 'nervous': 1504, 'andyclemmensen': 90, 'close': 457, 'eyes': 775, 'talking': 2145, 'doll': 662, 'interested': 1150, 'later': 1257, 'tonight': 2221, 'smile': 1985, 'care': 375, 'tell': 2160, 'game': 905, 'sa': 1846, 'stupid': 2092, 'boys': 296, 'pic': 1630, 'home': 1080, 'july': 1201, 'bout': 291, 'buy': 347, 'ticket': 2203, 'baby': 180, 'seen': 1892, 'movie': 1470, 'yall': 2469, 'laughed': 1260, 'lunch': 1355, 'nd': 1496, 'massage': 1385, 'sounds': 2019, 'ashleytisdale': 135, 'pa': 1583, 'bring': 312, 'soup': 2020, 'add': 19, 'milk': 1429, 'slightly': 1977, 'unfortunately': 2305, 'local': 1319, 'size': 1968, 'order': 1573, 'spend': 2033, 'scared': 1869, 'uni': 2306, 'fans': 793, 'nuts': 1535, 'came': 365, 'sooo': 2008, 'jealous': 1179, 'times': 2209, 'clean': 448, 'early': 697, 'bday': 210, 'check': 412, 'ass': 141, 'forward': 879, 'stand': 2046, 'link': 1302, 'feelings': 815, 'thought': 2192, 'lie': 1288, 'yea': 2473, 'oooo': 1565, 'instead': 1148, 'musicmonday': 1483, 'nope': 1522, 'project': 1717, 'bug': 332, 'stuck': 2085, 'knows': 1240, 'bed': 217, 'lookin': 1331, 'reason': 1771, 'awake': 162, 'atm': 148, 'omg': 1556, 'saw': 1864, 'ha': 984, 'certainly': 395, 'myweakness': 1485, 'heels': 1040, 'ohhhh': 1550, 'awesome': 166, 'damn': 584, 'sooner': 2007, 'monday': 1456, 'cause': 388, 'freaking': 884, 'jam': 1175, 'actually': 15, 'aplusk': 111, 'makeup': 1370, 'say': 1865, 'thoughts': 2193, 'lying': 1357, 'id': 1120, 'mcfly': 1396, 'reply': 1799, 'sounded': 2018, 'cheers': 416, 'lot': 1341, 'bloody': 267, 'keeping': 1208, 'till': 2207, 'ex': 754, 'band': 192, 'le': 1269, 'meeting': 1405, 'cheer': 415, 'hey': 1054, 'chuck': 441, 'bb': 205, 'england': 724, 'real': 1764, 'truly': 2257, 'opening': 1569, 'sing': 1954, 'lost': 1340, 'camera': 366, 'pics': 1634, 'tried': 2252, 'luck': 1352, 'fresh': 887, 'da': 577, 'called': 359, 'chocolate': 433, 'works': 2439, 'known': 1239, 'crappy': 540, 'beginning': 221, 'en': 718, 'middle': 1423, 'proper': 1722, 'stop': 2070, 'lame': 1249, 'ebay': 706, 'dollars': 663, 'coz': 537, 'drunk': 686, 'visit': 2339, 'fall': 786, 'rest': 1807, 'took': 2225, 'social': 1994, 'media': 1402, 'friendly': 891, 'cash': 381, 'didnt': 635, 'brother': 322, 'dad': 578, 'likes': 1296, 'nick': 1512, 'says': 1868, 'useless': 2323, 'head': 1024, 'sure': 2113, 'away': 164, 'anymore': 106, 'hard': 1009, 'ppl': 1687, 'watch': 2367, 'red': 1781, 'dat': 594, 'updated': 2310, 'previous': 1699, 'peeps': 1613, 'male': 1372, 'aw': 161, 'seeing': 1891, 'brain': 299, 'finger': 838, 'hm': 1069, 'best': 226, 'breakfast': 304, 'open': 1568, 'window': 2407, 'radio': 1752, 'gf': 921, 'iremember': 1163, 'havin': 1020, 'yesterday': 2484, 'twilight': 2283, 'lucky': 1354, 'ran': 1756, 'solo': 1998, 'mothers': 1466, 'comin': 479, 'blessed': 258, 'moon': 1462, 'prob': 1706, 'bbq': 207, 'means': 1400, 'bought': 290, 'alot': 69, 'owe': 1582, 'shirt': 1922, 'weeks': 2389, 'weekend': 2387, 'aceybongos': 9, 'guitar': 977, 'join': 1190, 'nooooo': 1521, 'xd': 2460, 'past': 1606, 'sarah': 1857, 'studio': 2088, 'dang': 588, 'yay': 2472, 'danny': 589, 'hate': 1014, 'screw': 1877, 'spot': 2038, 'blast': 256, 'brought': 324, 'definitely': 617, 'museum': 1480, 'crap': 539, 'season': 1882, 'went': 2394, 'walked': 2351, 'funny': 902, 'sat': 1858, 'london': 1324, 'ff': 823, 'ohh': 1548, 'meant': 1401, 'message': 1414, 'computer': 492, 'update': 2309, 'dog': 659, 'joining': 1192, 'road': 1825, 'god': 935, 'awful': 167, 'ugh': 2295, 'build': 333, 'dunno': 692, 'broke': 319, 'yard': 2470, 'lived': 1311, 'ps': 1726, 'guy': 981, 'sent': 1899, 'super': 2108, 'mary': 1384, 'page': 1586, 'cat': 383, 'bclub': 209, 'shoot': 1927, 'jokes': 1194, 'resist': 1803, 'dave': 600, 'keeps': 1209, 'hurt': 1116, 'giving': 930, 'crc': 547, 'huh': 1110, 'leave': 1274, 'bathroom': 202, 'managed': 1377, 'literally': 1308, 'threw': 2195, 'air': 49, 'small': 1980, 'glass': 932, 'ohhh': 1549, 'prices': 1701, 'dropped': 685, 'booked': 279, 'days': 603, 'ms': 1475, 'wear': 2377, 'nite': 1516, 'evening': 745, 'dm': 654, 'skype': 1972, 'info': 1142, 'hehe': 1042, 'confused': 498, 'especially': 741, 'apple': 114, 'die': 636, 'disappointed': 648, 'voting': 2344, 'kidding': 1220, 'usual': 2327, 'shoes': 1926, 'clothes': 460, 'guess': 974, 'save': 1861, 'twin': 2284, 'title': 2214, 'knew': 1235, 'ng': 1509, 'version': 2331, 'mo': 1448, 'cold': 468, 'email': 714, 'shut': 1941, 'stay': 2058, 'money': 1458, 'live': 1310, 'maybe': 1395, 'tht': 2198, 'listening': 1307, 'sex': 1908, 'hospital': 1094, 'wasnt': 2364, 'blog': 262, 'comment': 481, 'comeagainjen': 475, 'fucking': 899, 'tweeting': 2279, 'recipe': 1775, 'felt': 820, 'happened': 1004, 'tv': 2273, 'fine': 837, 'kill': 1222, 'glad': 931, 'try': 2260, 'unless': 2308, 'special': 2029, 'second': 1887, 'mate': 1388, 'story': 2076, 'aye': 175, 'web': 2380, 'listen': 1305, 'alex': 59, 'boo': 277, 'hug': 1107, 'kiss': 1230, 'hanging': 1000, 'hmmm': 1071, 'missed': 1441, 'bored': 283, 'drink': 679, 'tax': 2149, 'checking': 414, 'google': 948, 'rocks': 1829, 'max': 1394, 'shit': 1924, 'safe': 1850, 'trip': 2253, 'ready': 1763, 'hill': 1062, 'run': 1842, 'happiness': 1007, 'summer': 2103, 'sky': 1971, 'goodbye': 944, 'rite': 1824, 'sweet': 2125, 'dreams': 676, 'dc': 604, 'yummy': 2498, 'lake': 1247, 'btw': 329, 'totally': 2234, 'adam': 17, 'tour': 2237, 'videos': 2334, 'break': 303, 'ice': 1119, 'heart': 1034, 'church': 442, 'bradiewebbstack': 298, 'fight': 825, 'forget': 874, 'alright': 70, 'feeling': 814, 'minute': 1437, 'ate': 145, 'miles': 1426, 'filled': 830, 'drive': 682, 'crashed': 542, 'saved': 1862, 'lmfao': 1315, 'wash': 2363, 'wana': 2355, 'blame': 255, 'family': 789, 'xx': 2464, 'response': 1806, 'dead': 605, 'rich': 1816, 'pick': 1631, 'mail': 1365, 'tweet': 2275, 'dying': 694, 'horrible': 1092, 'liked': 1294, 'absolutely': 1, 'started': 2052, 'using': 2326, 'lines': 1301, 'forever': 873, 'lets': 1283, 'dnt': 655, 'babe': 177, 'messed': 1416, 'kid': 1219, 'type': 2292, 'write': 2449, 'cousin': 534, 'pleased': 1658, 'fav': 802, 'peace': 1611, 'twittering': 2288, 'tweetie': 2278, 'congratulations': 501, 'heard': 1032, 'noooo': 1520, 'clearly': 451, 'philippines': 1623, 'orange': 1572, 'book': 278, 'hmm': 1070, 'se': 1879, 'question': 1741, 'flowers': 854, 'yo': 2486, 'picture': 1635, 'ugly': 2296, 'layout': 1267, 'needs': 1502, 'logo': 1321, 'enjoyed': 727, 'reading': 1762, 'soccer': 1993, 'team': 2154, 'yellow': 2479, 'jb': 1178, 'soo': 2005, 'suppose': 2111, 'dvd': 693, 'release': 1789, 'david': 601, 'sis': 1960, 'showed': 1937, 'couple': 532, 'cam': 364, 'winter': 2414, 'pain': 1589, 'idea': 1121, 'sings': 1958, 'youuu': 2493, 'craving': 544, 'glasses': 933, 'pissed': 1641, 'happen': 1003, 'plz': 1664, 'eye': 774, 'comes': 477, 'loving': 1349, 'hahah': 988, 'word': 2432, 'included': 1139, 'longest': 1328, 'poem': 1668, 'world': 2440, 'hour': 1098, 'age': 31, 'loves': 1348, 'texas': 2169, 'havent': 1018, 'saving': 1863, 'america': 82, 'plus': 1663, 'currently': 569, 'alohaarleen': 68, 'hello': 1046, 'pay': 1608, 'smells': 1983, 'gross': 965, 'decided': 612, 'photos': 1629, 'trending': 2250, 'topic': 2230, 'lots': 1342, 'board': 271, 'ipod': 1159, 'ftw': 895, 'buckhollywood': 330, 'room': 1832, 'staying': 2060, 'turned': 2270, 'laptop': 1253, 'headache': 1025, 'alauderdale': 56, 'weather': 2379, 'lolz': 1323, 'nyc': 1538, 'half': 995, 'memory': 1409, 'theres': 2182, 'alive': 65, 'catching': 385, 'attention': 151, 'believe': 222, 'ive': 1172, 'month': 1459, 'um': 2299, 'creative': 550, 'energy': 723, 'amandapalmer': 76, 'appreciated': 118, 'sound': 2017, 'airport': 50, 'china': 428, 'falling': 787, 'apart': 109, 'mini': 1434, 'delicious': 622, 'sugar': 2098, 'purple': 1733, 'died': 637, 'worst': 2445, 'pretty': 1697, 'easy': 702, 'scary': 1870, 'movies': 1471, 'short': 1930, 'profile': 1714, 'comments': 482, 'gettin': 919, 'company': 486, 'wit': 2419, 'babes': 178, 'chance': 398, 'living': 1313, 'mama': 1374, 'mind': 1432, 'downloaded': 670, 'cover': 535, 'universe': 2307, 'sucks': 2097, 'planning': 1650, 'alyankovic': 71, 'website': 2381, 'words': 2433, 'ashley': 133, 'cuz': 575, 'soooo': 2009, 'excited': 759, 'tweets': 2280, 'sick': 1943, 'girlie': 926, 'husband': 1118, 'daily': 581, 'fast': 797, 'raining': 1754, 'body': 276, 'crack': 538, 'quick': 1743, 'code': 466, 'hell': 1044, 'deserve': 628, 'signed': 1947, 'pizza': 1644, 'park': 1599, 'regular': 1785, 'updates': 2311, 'treat': 2247, 'win': 2406, 'request': 1802, 'heavy': 1037, 'hav': 1017, 'ty': 2291, 'wishes': 2417, 'helped': 1048, 'wondering': 2427, 'years': 2477, 'learn': 1271, 'wtf': 2455, 'agentbooth': 32, 'worried': 2441, 'nap': 1492, 'course': 533, 'def': 615, 'practice': 1688, 'stressed': 2083, 'power': 1686, 'level': 1285, 'florida': 853, 'women': 2424, 'wet': 2396, 'japan': 1177, 'including': 1140, 'hotel': 1097, 'round': 1834, 'dream': 675, 'change': 399, 'concert': 494, 'wee': 2385, 'darling': 592, 'andrewdearling': 87, 'bless': 257, 'sexy': 1909, 'wall': 2353, 'europe': 744, 'green': 962, 'unfollow': 2304, 'considering': 505, 'mmmm': 1447, 'beans': 212, 'places': 1646, 'list': 1304, 'fish': 844, 'mall': 1373, 'ears': 698, 'yikes': 2485, 'coollike': 521, 'pub': 1727, 'magic': 1364, 'tough': 2236, 'note': 1527, 'self': 1893, 'pull': 1729, 'twice': 2282, 'gym': 983, 'depends': 625, 'wild': 2405, 'wings': 2410, 'near': 1497, 'apartment': 110, 'closed': 458, 'crying': 562, 'shame': 1913, 'honest': 1084, 'france': 881, 'flight': 851, 'fully': 900, 'babygirlparis': 181, 'joe': 1188, 'kno': 1236, 'dance': 586, 'goes': 936, 'mrs': 1474, 'broken': 320, 'stopped': 2071, 'machine': 1361, 'pocket': 1666, 'bye': 350, 'tea': 2151, 'awwww': 173, 'wrong': 2453, 'upload': 2314, 'error': 739, 'mom': 1452, 'cut': 571, 'workout': 2438, 'running': 1843, 'late': 1255, 'surprised': 2117, 'shot': 1933, 'conference': 496, 'manage': 1376, 'bro': 317, 'trouble': 2254, 'nearly': 1498, 'apparently': 113, 'showing': 1939, 'pass': 1603, 'blink': 259, 'light': 1290, 'tears': 2156, 'plans': 1651, 'snap': 1990, 'fuck': 896, 'wwwtweeterfollowcom': 2458, 'train': 2244, 'vip': 2337, 'doc': 656, 'silly': 1949, 'shaundiviney': 1916, 'gold': 939, 'squarespace': 2042, 'worse': 2444, 'winning': 2412, 'wonder': 2425, 'gives': 929, 'dry': 687, 'mouth': 1467, 'colorblindfish': 472, 'mean': 1398, 'inaperfectworld': 1138, 'mix': 1445, 'reminded': 1793, 'joy': 1198, 'children': 425, 'seat': 1883, 'gay': 910, 'ear': 695, 'songs': 2004, 'min': 1431, 'realized': 1769, 'kind': 1226, 'mood': 1461, 'deleted': 621, 'excuse': 762, 'minutes': 1438, 'suck': 2095, 'sydney': 2133, 'iranelection': 1161, 'british': 314, 'slowly': 1979, 'store': 2072, 'holy': 1079, 'making': 1371, 'slow': 1978, 'connection': 503, 'dogs': 660, 'creepy': 552, 'teeth': 2158, 'darn': 593, 'telling': 2161, 'respect': 1804, 'ed': 707, 'article': 129, 'caught': 387, 'nasty': 1493, 'stomach': 2069, 'flu': 855, 'gets': 918, 'australia': 157, 'til': 2206, 'joined': 1191, 'thx': 2202, 'quite': 1747, 'mess': 1413, 'aubreyoday': 152, 'easier': 700, 'office': 1544, 'characters': 405, 'saturday': 1859, 'box': 292, 'supposed': 2112, 'camp': 367, 'wedding': 2383, 'concerts': 495, 'ruin': 1838, 'arent': 122, 'aim': 47, 'charlie': 407, 'challenge': 397, 'dressed': 678, 'accident': 6, 'swear': 2123, 'gud': 973, 'myspace': 1484, 'character': 404, 'blokeslib': 264, 'quickly': 1744, 'copy': 522, 'low': 1350, 'andy': 89, 'daddy': 579, 'lil': 1298, 'incredible': 1141, 'black': 252, 'paid': 1588, 'problem': 1708, 'area': 121, 'woke': 2422, 'looked': 1330, 'replies': 1798, 'shall': 1912, 'released': 1790, 'anniversary': 98, 'catch': 384, 'boston': 287, 'star': 2048, 'trek': 2249, 'point': 1669, 'deep': 614, 'cost': 527, 'fed': 809, 'mum': 1479, 'andrew': 86, 'adorable': 25, 'anyways': 108, 'bunny': 338, 'pieces': 1639, 'puts': 1736, 'contest': 509, 'cancer': 370, 'windows': 2408, 'sleeping': 1974, 'track': 2240, 'student': 2086, 'card': 373, 'bobbyllew': 275, 'enjoying': 728, 'talented': 2141, 'artist': 130, 'changing': 402, 'episode': 736, 'likely': 1295, 'bus': 340, 'difficult': 642, 'million': 1430, 'chrisdjmoyles': 439, 'rubbish': 1836, 'turn': 2269, 'pix': 1643, 'puppy': 1731, 'state': 2055, 'sold': 1997, 'shirts': 1923, 'thankyou': 2178, 'chips': 432, 'followed': 864, 'cream': 548, 'finals': 835, 'wants': 2359, 'needed': 1501, 'vegas': 2330, 'isnt': 1165, 'news': 1508, 'date': 596, 'fingers': 839, 'crossed': 557, 'thanx': 2179, 'britneyspears': 316, 'bummed': 335, 'seats': 1884, 'gig': 923, 'agree': 36, 'chicken': 423, 'enjoy': 726, 'cupcakes': 566, 'door': 666, 'large': 1254, 'cares': 378, 'fighting': 826, 'walking': 2352, 'limit': 1299, 'ch': 396, 'annoying': 100, 'price': 1700, 'national': 1494, 'learned': 1272, 'miserable': 1439, 'man': 1375, 'finish': 840, 'harry': 1012, 'potter': 1685, 'exactly': 755, 'posted': 1682, 'hook': 1088, 'hit': 1066, 'city': 444, 'csiprintchick': 564, 'yrs': 2495, 'boy': 293, 'sadly': 1848, 'okay': 1552, 'thinks': 2189, 'pool': 1673, 'alancarr': 54, 'alan': 53, 'present': 1694, 'extremely': 773, 'evil': 752, 'lmao': 1314, 'grad': 955, 'moving': 1472, 'chrisdaughtry': 438, 'information': 1143, 'born': 285, 'death': 609, 'exam': 756, 'ho': 1072, 'blackberry': 253, 'er': 738, 'mee': 1403, 'proud': 1725, 'battery': 203, 'posting': 1683, 'probs': 1710, 'account': 7, 'awwwww': 174, 'porn': 1677, 'stars': 2050, 'sit': 1963, 'jk': 1185, 'bigger': 236, 'tho': 2191, 'fab': 776, 'alyssamilano': 72, 'germany': 917, 'spell': 2031, 'prolly': 1718, 'jake': 1174, 'hes': 1053, 'wouldnt': 2447, 'earlier': 696, 'cook': 514, 'youu': 2492, 'kids': 1221, 'retweet': 1812, 'bag': 187, 'san': 1855, 'place': 1645, 'clue': 464, 'figure': 827, 'wearing': 2378, 'items': 1170, 'line': 1300, 'nerd': 1503, 'books': 280, 'spending': 2034, 'smh': 1984, 'crucifire': 559, 'paul': 1607, 'chest': 420, 'expensive': 769, 'english': 725, 'beat': 214, 'relax': 1787, 'promise': 1720, 'talked': 2143, 'ages': 34, 'sum': 2102, 'busy': 342, 'mondays': 1457, 'action': 13, 'bt': 327, 'supernatural': 2109, 'cries': 555, 'sleepy': 1975, 'ben': 225, 'ashleyltmsyf': 134, 'cookie': 516, 'extra': 772, 'disney': 650, 'missing': 1443, 'ooh': 1562, 'tweeted': 2277, 'follower': 865, 'mtv': 1478, 'woohoo': 2430, 'straight': 2077, 'hows': 1102, 'status': 2057, 'hearing': 1033, 'click': 453, 'yr': 2494, 'fake': 785, 'facebook': 779, 'ryan': 1845, 'chris': 436, 'calling': 360, 'asking': 139, 'wins': 2413, 'kate': 1206, 'wake': 2348, 'row': 1835, 'taylor': 2150, 'coldplay': 469, 'kisses': 1231, 'player': 1654, 'arrived': 127, 'arm': 124, 'worked': 2435, 'workin': 2436, 'txt': 2290, 'exercise': 763, 'shopping': 1929, 'similar': 1950, 'boyfriend': 294, 'ah': 38, 'gutted': 980, 'ka': 1205, 'eating': 705, 'grown': 969, 'major': 1367, 'ahh': 43, 'ring': 1821, 'essay': 742, 'class': 445, 'girls': 927, 'style': 2093, 'possible': 1679, 'eggs': 710, 'bacon': 184, 'jobs': 1187, 'swim': 2129, 'ad': 16, 'true': 2256, 'wanting': 2358, 'interesting': 1151, 'ill': 1128, 'upgrade': 2313, 'water': 2371, 'phones': 1626, 'planned': 1649, 'apps': 119, 'pro': 1705, 'sitting': 1966, 'mark': 1379, 'hero': 1052, 'wrote': 2454, 'fruit': 894, 'asked': 138, 'saying': 1867, 'lately': 1256, 'idiot': 1123, 'umm': 2300, 'explain': 771, 'candy': 371, 'personal': 1619, 'number': 1534, 'cup': 565, 'speaking': 2028, 'form': 877, 'imagine': 1133, 'driving': 683, 'suit': 2101, 'rofl': 1830, 'months': 1460, 'sayin': 1866, 'grrr': 971, 'review': 1813, 'ace': 8, 'sighs': 1945, 'sam': 1854, 'em': 713, 'bottle': 289, 'tryin': 2261, 'holiday': 1076, 'set': 1906, 'tt': 2265, 'itunes': 1171, 'uh': 2297, 'expecting': 768, 'hun': 1112, 'shop': 1928, 'seattle': 1885, 'quiet': 1745, 'wonderful': 2426, 'mention': 1411, 'boring': 284, 'app': 112, 'fri': 888, 'changed': 400, 'young': 2489, 'calls': 361, 'ways': 2375, 'cd': 390, 'study': 2089, 'bio': 243, 'test': 2167, 'mornin': 1463, 'laugh': 1259, 'mac': 1359, 'tuesday': 2266, 'ai': 46, 'writing': 2451, 'nxt': 1536, 'blow': 268, 'anna': 97, 'town': 2238, 'crash': 541, 'tmrw': 2216, 'referring': 1783, 'cancelled': 369, 'chill': 426, 'aint': 48, 'create': 549, 'tweetdeck': 2276, 'launch': 1262, 'member': 1407, 'tree': 2248, 'james': 1176, 'act': 11, 'ball': 189, 'laundry': 1263, 'cleaning': 449, 'hah': 985, 'writer': 2450, 'swift': 2128, 'backstreetboys': 183, 'brazil': 301, 'possibly': 1680, 'repeat': 1796, 'report': 1801, 'tune': 2268, 'gift': 922, 'tip': 2211, 'stick': 2065, 'firefox': 843, 'sunshine': 2107, 'chinese': 429, 'michael': 1421, 'topics': 2231, 'fever': 822, 'older': 1555, 'stole': 2068, 'killed': 1223, 'answer': 102, 'service': 1904, 'nah': 1487, 'ooc': 1561, 'parents': 1597, 'south': 2022, 'iran': 1160, 'ima': 1131, 'everyday': 750, 'texting': 2171, 'boat': 272, 'fb': 806, 'scene': 1871, 'library': 1286, 'cried': 554, 'tshirt': 2264, 'reckon': 1776, 'mmm': 1446, 'ideas': 1122, 'obama': 1539, 'prayers': 1690, 'race': 1751, 'chick': 422, 'grandma': 959, 'background': 182, 'reminds': 1795, 'sf': 1910, 'props': 1724, 'series': 1901, 'plug': 1662, 'checked': 413, 'rate': 1759, 'confirmed': 497, 'exciting': 761, 'shift': 1919, 'stories': 2074, 'mistake': 1444, 'latest': 1258, 'abt': 2, 'players': 1655, 'skills': 1969, 'idk': 1124, 'dads': 580, 'brilliant': 311, 'uploaded': 2315, 'tickets': 2204, 'jump': 1202, 'schedule': 1872, 'daughter': 599, 'afternoon': 30, 'north': 1525, 'west': 2395, 'passed': 1604, 'internet': 1153, 'stayed': 2059, 'pity': 1642, 'thnx': 2190, 'somebody': 1999, 'corner': 523, 'singapore': 1955, 'york': 2488, 'al': 52, 'knowing': 1238, 'th': 2173, 'random': 1757, 'jon': 1196, 'harder': 1010, 'hilarious': 1061, 'plenty': 1660, 'hand': 996, 'bob': 273, 'weak': 2376, 'healthy': 1030, 'fear': 807, 'quit': 1746, 'normal': 1523, 'clock': 456, 'exist': 765, 'jack': 1173, 'sandwich': 1856, 'bread': 302, 'turning': 2271, 'hated': 1015, 'hands': 998, 'obviously': 1541, 'june': 1203, 'bar': 195, 'hayles': 1022, 'wud': 2456, 'thurs': 2200, 'famous': 790, 'takes': 2138, 'ireland': 1162, 'wife': 2402, 'correct': 524, 'loss': 1339, 'truck': 2255, 'feelin': 813, 'bitch': 248, 'macbook': 1360, 'pls': 1661, 'paper': 1596, 'public': 1728, 'woah': 2421, 'luv': 1356, 'heat': 1035, 'surprise': 2116, 'wat': 2366, 'imma': 1134, 'jus': 1204, 'chelseaplayboy': 419, 'strong': 2084, 'tool': 2226, 'bummer': 336, 'pulling': 1730, 'john': 1189, 'apply': 116, 'students': 2087, 'program': 1715, 'lover': 1347, 'tom': 2219, 'wicked': 2400, 'toy': 2239, 'bsb': 326, 'bobby': 274, 'praying': 1691, 'chicago': 421, 'uk': 2298, 'reference': 1782, 'network': 1506, 'private': 1704, 'recommend': 1777, 'pink': 1640, 'grow': 967, 'leaves': 1275, 'spymaster': 2041, 'ends': 722, 'wars': 2362, 'envy': 733, 'bf': 232, 'count': 530, 'bgt': 234, 'links': 1303, 'channel': 403, 'choose': 435, 'outside': 1579, 'nicely': 1511, 'grace': 954, 'touch': 2235, 'meal': 1397, 'posts': 1684, 'billyraycyrus': 241, 'billy': 240, 'effect': 708, 'lang': 1251, 'tons': 2223, 'figured': 828, 'support': 2110, 'lyrics': 1358, 'cos': 526, 'recently': 1774, 'hungry': 1114, 'hahahahaha': 992, 'decision': 613, 'steve': 2064, 'cooler': 520, 'text': 2170, 'watched': 2368, 'travel': 2246, 'session': 1905, 'wishing': 2418, 'user': 2324, 'bother': 288, 'marsiscoming': 1383, 'brianmcnugget': 309, 'matters': 1393, 'final': 832, 'chiniehdiaz': 430, 'difference': 640, 'lo': 1316, 'dark': 591, 'matter': 1392, 'album': 57, 'tony': 2224, 'image': 1132, 'issue': 1166, 'complete': 490, 'ache': 10, 'pre': 1692, 'animals': 96, 'gorgeous': 949, 'runs': 1844, 'simple': 1951, 'picked': 1632, 'net': 1505, 'spam': 2024, 'st': 2044, 'revision': 1814, 'cross': 556, 'starting': 2053, 'comedyqueen': 476, 'gd': 911, 'everytime': 751, 'taken': 2137, 'cats': 386, 'bff': 233, 'direct': 646, 'messages': 1415, 'played': 1653, 'lack': 1244, 'doesnt': 658, 'hd': 1023, 'luckily': 1353, 'section': 1890, 'freakin': 883, 'soul': 2016, 'shoulda': 1934, 'boykillboy': 295, 'floor': 852, 'bird': 244, 'dentist': 624, 'astynes': 143, 'painting': 1592, 'si': 1942, 'games': 906, 'bright': 310, 'record': 1779, 'sushi': 2120, 'salad': 1852, 'server': 1903, 'dick': 634, 'ahead': 42, 'miley': 1427, 'cyrus': 576, 'deserved': 629, 'taste': 2147, 'reasons': 1772, 'dontyouhate': 665, 'boss': 286, 'excellent': 758, 'business': 341, 'bay': 204, 'share': 1914, 'asian': 136, 'helpful': 1049, 'starbucks': 2049, 'double': 667, 'chip': 431, 'notes': 1528, 'tells': 2162, 'hates': 1016, 'yeahh': 2475, 'contact': 507, 'ahaha': 41, 'kick': 1216, 'data': 595, 'biggest': 237, 'chillin': 427, 'aussiecynic': 155, 'basically': 199, 'surgery': 2115, 'total': 2233, 'completely': 491, 'spanish': 2025, 'peanut': 1612, 'butter': 345, 'cookies': 517, 'smiling': 1987, 'xoxo': 2462, 'adding': 22, 'earth': 699, 'wave': 2372, 'community': 484, 'choice': 434, 'twit': 2285, 'paying': 1609, 'recommendation': 1778, 'sort': 2014, 'art': 128, 'rule': 1840, 'allowed': 67, 'yawn': 2471, 'impossible': 1136, 'quiz': 1748, 'woo': 2429, 'hoo': 1087, 'dumb': 690, 'uncle': 2302, 'corruptedangel': 525, 'ahhhh': 45, 'closer': 459, 'properly': 1723, 'secret': 1889, 'hahaa': 987, 'lakers': 1248, 'blood': 266, 'content': 508, 'beauty': 216, 'sms': 1989, 'festival': 821, 'degrees': 618, 'curious': 567, 'details': 632, 'quote': 1750, 'beach': 211, 'tan': 2146, 'quality': 1738, 'jersey': 1181, 'ladies': 1245, 'thunder': 2199, 'lightning': 1291, 'married': 1382, 'realised': 1766, 'angry': 94, 'matt': 1391, 'dating': 598, 'hollywood': 1078, 'color': 471, 'decide': 611, 'accept': 4, 'language': 1252, 'atleast': 147, 'feedback': 811, 'credit': 551, 'eu': 743, 'flying': 857, 'search': 1881, 'horse': 1093, 'strawberry': 2079, 'picking': 1633, 'spelling': 2032, 'gas': 908, 'fat': 799, 'soft': 1995, 'mileycyrus': 1428, 'admit': 24, 'human': 1111, 'packing': 1585, 'dj': 653, 'hee': 1039, 'oops': 1567, 'helps': 1051, 'frm': 893, 'cable': 352, 'named': 1490, 'official': 1545, 'deal': 606, 'stream': 2080, 'vote': 2342, 'conan': 493, 'musical': 1482, 'usa': 2319, 'match': 1387, 'trust': 2258, 'option': 1571, 'happens': 1006, 'fabulous': 777, 'points': 1670, 'terminator': 2165, 'studying': 2090, 'ending': 721, 'spare': 2026, 'moves': 1469, 'bike': 238, 'agreed': 37, 'positive': 1678, 'celebrate': 391, 'jonas': 1197, 'brothers': 323, 'smell': 1982, 'golf': 940, 'lazy': 1268, 'baseball': 197, 'screen': 1876, 'names': 1491, 'kicking': 1218, 'grade': 956, 'dallas': 582, 'awhile': 169, 'questions': 1742, 'addicted': 21, 'tooth': 2229, 'main': 1366, 'street': 2081, 'philly': 1624, 'fit': 845, 'awh': 168, 'lead': 1270, 'entire': 731, 'replying': 1800, 'sports': 2037, 'christmas': 440, 'theme': 2181, 'definately': 616, 'adammshankman': 18, 'training': 2245, 'career': 376, 'health': 1029, 'fashion': 796, 'design': 630, 'spent': 2035, 'rough': 1833, 'tis': 2213, 'reality': 1767, 'texts': 2172, 'hurry': 1115, 'hold': 1073, 'single': 1957, 'heads': 1028, 'film': 831, 'related': 1786, 'survive': 2118, 'general': 913, 'kicked': 1217, 'vid': 2332, 'impressed': 1137, 'products': 1712, 'sooooo': 2010, 'table': 2135, 'learning': 1273, 'yeh': 2478, 'gnight': 934, 'remind': 1792, 'hrs': 1104, 'inside': 1145, 'press': 1695, 'vs': 2345, 'sauce': 1860, 'beer': 219, 'sorted': 2015, 'sending': 1897, 'chriscornell': 437, 'birds': 245, 'grey': 964, 'breaking': 305, 'chelsea': 418, 'teh': 2159, 'trick': 2251, 'finding': 836, 'realise': 1765, 'offer': 1543, 'hawaii': 1021, 'gosh': 950, 'ride': 1818, 'begin': 220, 'customer': 570, 'bills': 239, 'beverleyknight': 231, 'period': 1617, 'dean': 607, 'joke': 1193, 'connect': 502, 'canada': 368, 'online': 1558, 'turns': 2272, 'interview': 1154, 'strange': 2078, 'asap': 131, 'emails': 715, 'hung': 1113, 'aha': 39, 'babies': 179, 'lord': 1335, 'fellow': 819, 'worries': 2442, 'putting': 1737, 'spread': 2039, 'tight': 2205, 'cough': 529, 'faster': 798, 'hahahah': 990, 'hannah': 1002, 'current': 568, 'screwed': 1878, 'yah': 2468, 'cutie': 573, 'nails': 1488, 'perfect': 1615, 'moms': 1455, 'applecored': 115, 'thursday': 2201, 'sux': 2121, 'msn': 1477, 'holidays': 1077, 'vacation': 2329, 'key': 1213, 'pie': 1637, 'mobile': 1449, 'whoa': 2399, 'roll': 1831, 'lesson': 1281, 'crashing': 543, 'blows': 269, 'loser': 1337, 'cali': 357, 'east': 701, 'thread': 2194, 'aswell': 144, 'naw': 1495, 'regret': 1784, 'amandabynes': 74, 'amanda': 73, 'wii': 2404, 'memories': 1408, 'problems': 1709, 'crew': 553, 'clear': 450, 'yup': 2499, 'rainy': 1755, 'dirty': 647, 'handle': 997, 'plays': 1657, 'shout': 1936, 'bing': 242, 'nooo': 1519, 'promote': 1721, 'amazingphil': 78, 'growing': 968, 'laughing': 1261, 'blah': 254, 'heaven': 1036, 'moved': 1468, 'rockin': 1828, 'settle': 1907, 'charge': 406, 'clouds': 461, 'gah': 904, 'amazingphoebe': 79, 'war': 2360, 'pants': 1595, 'kitty': 1233, 'software': 1996, 'pc': 1610, 'switch': 2132, 'pray': 1689, 'dislike': 649, 'diet': 639, 'atl': 146, 'rude': 1837, 'ordered': 1574, 'jesus': 1183, 'homie': 1082, 'hat': 1013, 'hardly': 1011, 'common': 483, 'model': 1451, 'plane': 1648, 'depressing': 627, 'load': 1317, 'toooo': 2228, 'smart': 1981, 'adriennebailon': 26, 'episodes': 737, 'killing': 1225, 'inspiration': 1146, 'sites': 1965, 'tech': 2157, 'waking': 2349, 'aussiemcflyfan': 156, 'professional': 1713, 'actual': 14, 'blocked': 261, 'blonde': 265, 'german': 916, 'youre': 2490, 'ep': 734, 'smoke': 1988, 'flat': 849, 'upset': 2316, 'pet': 1621, 'fo': 860, 'queen': 1740, 'pages': 1587, 'url': 2318, 'view': 2336, 'stoked': 2067, 'cheese': 417, 'fave': 803, 'emily': 716, 'conversation': 512, 'que': 1739, 'watchin': 2369, 'tha': 2174, 'ako': 51, 'ahah': 40, 'freak': 882, 'breaks': 306, 'ali': 62, 'vids': 2335, 'seconds': 1888, 'written': 2452, 'april': 120, 'available': 158, 'neck': 1499, 'bunch': 337, 'dare': 590, 'androidtomato': 88, 'someday': 2000, 'mins': 1435, 'letting': 1284, 'yu': 2496, 'control': 511, 'sense': 1898, 'misses': 1442, 'gotten': 952, 'bah': 188, 'knw': 1241, 'duh': 689, 'swine': 2131, 'piece': 1638, 'grab': 953, 'guessing': 975, 'demi': 623, 'cooking': 518, 'storm': 2075, 'honey': 1086, 'kevin': 1212, 'chatting': 410, 'child': 424, 'talkin': 2144, 'delayed': 619, 'pressure': 1696, 'epic': 735, 'hubby': 1106, 'august': 154, 'finishing': 842, 'continue': 510, 'butadream': 343, 'din': 644, 'tweeps': 2274, 'afraid': 29, 'folks': 862, 'cutting': 574, 'return': 1811, 'minus': 1436, 'legs': 1279, 'ac': 3, 'winner': 2411, 'warm': 2361, 'jst': 1199, 'island': 1164, 'crunchyk': 560, 'dr': 672, 'brand': 300, 'shower': 1938, 'finale': 833, 'block': 260, 'hole': 1075, 'clip': 455, 'oo': 1560, 'paris': 1598, 'throat': 2196, 'mi': 1419, 'andyroddick': 91, 'lem': 1280, 'anoopdoggdesai': 101, 'goodsex': 947, 'wen': 2393, 'future': 903, 'fault': 801, 'obsessed': 1540, 'ily': 1129, 'waves': 2373, 'careful': 377, 'keys': 1215, 'answers': 104, 'sims': 1953, 'shes': 1918, 'taking': 2139, 'arrive': 126, 'insane': 1144, 'annoyed': 99, 'tix': 2215, 'american': 83, 'sucked': 2096, 'couch': 528, 'awards': 163, 'crazytwism': 546, 'xxxx': 2466, 'animal': 95, 'calm': 362, 'grr': 970, 'honestly': 1085, 'excitement': 760, 'bitches': 249, 'kept': 1211, 'cards': 374, 'somethin': 2001, 'trailer': 2243, 'goodness': 945, 'shoulder': 1935, 'buzzedition': 349, 'maths': 1390, 'center': 393, 'simply': 1952, 'classes': 446, 'belly': 224, 'score': 1875, 'tattoo': 2148, 'nose': 1526, 'history': 1065, 'bear': 213, 'sale': 1853, 'knee': 1234, 'smiles': 1986, 'typical': 2293, 'fact': 780, 'spring': 2040, 'hopefully': 1090, 'lives': 1312, 'kings': 1229, 'palm': 1594, 'updating': 2312, 'range': 1758, 'alcohol': 58, 'heading': 1027, 'station': 2056, 'issues': 1167, 'hella': 1045, 'california': 358, 'insurance': 1149, 'starts': 2054, 'consider': 504, 'cloudy': 462, 'brown': 325, 'tiny': 2210, 'bite': 250, 'bella': 223, 'painful': 1590, 'access': 5, 'decent': 610, 'space': 2023, 'tooo': 2227, 'classic': 447, 'george': 915, 'dan': 585, 'diego': 638, 'midnight': 1424, 'fuckin': 898, 'breath': 307, 'drinks': 681, 'peter': 1622, 'bbc': 206, 'hangover': 1001, 'rice': 1815, 'restaurant': 1808, 'situation': 1967, 'massive': 1386, 'tonite': 2222, 'wwwtweeteraddercom': 2457, 'log': 1320, 'answered': 103, 'flylady': 858, 'banana': 191, 'host': 1095, 'oooh': 1564, 'anytime': 107, 'joking': 1195, 'downtown': 671, 'heck': 1038, 'notice': 1530, 'liking': 1297, 'garden': 907, 'cheap': 411, 'avatar': 159, 'microsoft': 1422, 'ouch': 1578, 'results': 1810, 'heyyy': 1056, 'thingy': 2186, 'rob': 1826, 'license': 1287, 'feed': 810, 'eventually': 748, 'stage': 2045, 'market': 1380, 'lights': 1292, 'pair': 1593, 'haveyouever': 1019, 'paint': 1591, 'given': 928, 'snow': 1992, 'ol': 1553, 'holding': 1074, 'mode': 1450, 'wise': 2415, 'fam': 788, 'popular': 1676, 'twitters': 2289, 'international': 1152, 'hehehe': 1043, 'waste': 2365, 'msg': 1476, 'suggestion': 2100, 'follows': 869, 'install': 1147, 'shiny': 1921, 'boom': 281, 'typing': 2294, 'ash': 132, 'attempt': 150, 'toronto': 2232, 'odd': 1542, 'barely': 196, 'jeans': 1180, 'drop': 684, 'weight': 2390, 'delete': 620, 'amandaholden': 75, 'stress': 2082, 'theyre': 2183, 'cavs': 389, 'brings': 313, 'science': 1874, 'blogs': 263, 'grass': 960, 'invited': 1156, 'amen': 81, 'exhausted': 764, 'emo': 717, 'katie': 1207, 'drama': 674, 'print': 1703, 'sadness': 1849, 'marathon': 1378, 'success': 2094, 'fucked': 897, 'nothin': 1529, 'lauren': 1264, 'britney': 315, 'talent': 2140, 'expected': 767, 'clever': 452, 'doubt': 668, 'faith': 784, 'bradie': 297, 'soooooo': 2011, 'hide': 1058, 'virtual': 2338, 'opinion': 1570, 'keyboard': 1214, 'ko': 1242, 'houston': 1101, 'land': 1250, 'hills': 1063, 'angel': 93, 'kitchen': 1232, 'rid': 1817, 'meh': 1406, 'depressed': 626, 'forgotten': 876, 'source': 2021, 'losing': 1338, 'sweetheart': 2126, 'leg': 1278, 'college': 470, 'complain': 488, 'advice': 27, 'ow': 1581, 'ny': 1537, 'ignore': 1126, 'bee': 218, 'bath': 201, 'ew': 753, 'esp': 740, 'flickr': 850, 'crowd': 558, 'client': 454, 'effort': 709, 'standing': 2047, 'magazine': 1363, 'shortly': 1931, 'involved': 1157, 'podcast': 1667, 'fml': 859, 'helping': 1050, 'confusing': 499, 'desk': 631, 'xp': 2463, 'mike': 1425, 'received': 1773, 'pushing': 1735, 'preview': 1698, 'sea': 1880, 'stores': 2073, 'comp': 485, 'wed': 2382, 'september': 1900, 'focus': 861, 'visiting': 2340, 'loud': 1343, 'highly': 1060, 'weekends': 2388, 'susan': 2119, 'forum': 878, 'ooo': 1563, 'alisweeney': 64, 'recording': 1780, 'foot': 871, 'orlando': 1576, 'result': 1809, 'law': 1265, 'lay': 1266, 'feature': 808, 'selling': 1895, 'cont': 506, 'idol': 1125, 'alice': 63, 'noo': 1518, 'avoid': 160, 'parties': 1600, 'bank': 194, 'crystalchappell': 563, 'entry': 732, 'file': 829, 'sisters': 1962, 'button': 346, 'genius': 914, 'useful': 2322, 'allergies': 66, 'riding': 1819, 'parts': 1601, 'os': 1577, 'throw': 2197, 'juice': 1200, 'tweetup': 2281, 'hai': 993, 'audio': 153, 'listened': 1306, 'added': 20, 'ang': 92, 'fancy': 792, 'skin': 1970, 'tag': 2136, 'crush': 561, 'killer': 1224, 'argh': 123, 'process': 1711, 'geek': 912, 'steak': 2061, 'heh': 1041, 'normally': 1524, 'princess': 1702, 'enter': 729, 'asshole': 142, 'italian': 1168, 'eaten': 704, 'acting': 12, 'italy': 1169, 'steal': 2062, 'police': 1671, 'math': 1389, 'butt': 344, 'diversity': 652, 'tend': 2163, 'poo': 1672, 'burn': 339, 'certain': 394, 'football': 872, 'wifi': 2403, 'comic': 478, 'shine': 1920, 'shitty': 1925, 'ummm': 2301, 'prom': 1719, 'reach': 1760, 'complaining': 489, 'performance': 1616, 'headed': 1026, 'di': 633, 'yer': 2481, 'tryna': 2263, 'voted': 2343, 'pure': 1732, 'nightmare': 1514, 'tear': 2155, 'hiya': 1068, 'nom': 1517, 'meaning': 1399, 'personally': 1620, 'outta': 1580, 'babblingbrookie': 176, 'calebftsk': 356, 'competition': 487, 'drag': 673, 'push': 1734, 'based': 198, 'rules': 1841, 'hitting': 1067, 'progress': 1716, 'agentm': 33, 'marketing': 1381, 'teach': 2152, 'cassieventura': 382, 'ruined': 1839, 'jess': 1182, 'charlieskies': 408, 'minds': 1433, 'relaxing': 1788, 'sweden': 2124, 'swimming': 2130, 'shortstack': 1932, 'shake': 1911, 'beth': 229, 'coast': 465, 'hint': 1064, 'events': 747, 'sway': 2122, 'cinema': 443, 'cadistra': 353, 'covered': 536, 'cafe': 354, 'mia': 1420, 'spirit': 2036, 'fox': 880, 'grew': 963, 'brooke': 321, 'entertaining': 730, 'surely': 2114, 'passing': 1605, 'dates': 597, 'guilty': 976, 'mentioned': 1412, 'flash': 848, 'dig': 643, 'kelly': 1210, 'mexican': 1418, 'hr': 1103, 'display': 651, 'tennis': 2164, 'cooked': 515, 'anybody': 105, 'users': 2325, 'photography': 1628, 'brodyjenner': 318, 'naked': 1489, 'dun': 691, 'noundiessunday': 1532, 'pack': 1584, 'ontd': 1559, 'shaunjumpnow': 1917, 'bts': 328, 'sebday': 1886}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=2500, ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79991, 2500)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abt</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>account</th>\n",
       "      <th>ace</th>\n",
       "      <th>aceybongos</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youu</th>\n",
       "      <th>youuu</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yu</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  abt  ac  accept  access  accident  account  ace  \\\n",
       "0     0           0    0   0       0       0         0        0    0   \n",
       "1     0           0    0   0       0       0         0        0    0   \n",
       "2     0           0    0   0       0       0         0        0    0   \n",
       "3     0           0    0   0       0       0         0        0    0   \n",
       "4     0           0    0   0       0       0         0        0    0   \n",
       "\n",
       "   aceybongos  ...  youre  youtube  youu  youuu  yr  yrs  yu  yum  yummy  yup  \n",
       "0           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "1           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "2           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "3           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "4           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "\n",
       "[5 rows x 2500 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_counts = vectorizer.transform(X_train)\n",
    "\n",
    "X_train_vectorized = pd.DataFrame(train_word_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "X_train_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19998, 2500)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abt</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>account</th>\n",
       "      <th>ace</th>\n",
       "      <th>aceybongos</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youu</th>\n",
       "      <th>youuu</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yu</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  abt  ac  accept  access  accident  account  ace  \\\n",
       "0     0           0    0   0       0       0         0        0    0   \n",
       "1     0           0    0   0       0       0         0        0    0   \n",
       "2     0           0    0   0       0       0         0        0    0   \n",
       "3     0           0    0   0       0       0         0        0    0   \n",
       "4     0           0    0   0       0       0         0        0    0   \n",
       "\n",
       "   aceybongos  ...  youre  youtube  youu  youuu  yr  yrs  yu  yum  yummy  yup  \n",
       "0           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "1           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "2           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "3           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "4           0  ...      0        0     0      0   0    0   0    0      0    0  \n",
       "\n",
       "[5 rows x 2500 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #vectorize  X_test, uses ame vocabulary as the training dataset so  just call .transform() on X_test\n",
    "test_word_counts = vectorizer.transform(X_test)\n",
    "\n",
    "X_test_vectorized = pd.DataFrame(test_word_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_test_vectorized.shape)\n",
    "X_test_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EDC\\Anaconda3\\envs\\environ1\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9498193546774012\n",
      "Test Accuracy: 0.7016701670167017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RFC = RandomForestClassifier().fit(X_train_vectorized, y_train)\n",
    "\n",
    "train_predictions = RFC.predict(X_train_vectorized)\n",
    "test_predictions = RFC.predict(X_test_vectorized)\n",
    "\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, train_predictions)}')\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, test_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sorF95UO_uGx"
   },
   "source": [
    "# Part 4 -  Word2Vec\n",
    "\n",
    "1) Fit a Word2Vec model on your cleaned/tokenized twitter dataset. \n",
    "\n",
    "2) Display the 10 words that are most similar to the word \"twitter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYno4d4N-LHR"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v = Word2Vec(df2.SentimentText, min_count=20, window=3, size=300, negative=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('email', 0.7807869911193848),\n",
       " ('facebook', 0.7633020877838135),\n",
       " ('address', 0.7597259879112244),\n",
       " ('list', 0.7535127401351929),\n",
       " ('updates', 0.7489092946052551),\n",
       " ('myspace', 0.7455503940582275),\n",
       " ('account', 0.7440444827079773),\n",
       " ('dm', 0.738918125629425),\n",
       " ('info', 0.7354879379272461),\n",
       " ('page', 0.7271144986152649),\n",
       " ('link', 0.7264727354049683),\n",
       " ('sent', 0.7211235165596008),\n",
       " ('spam', 0.7198559045791626),\n",
       " ('site', 0.7173420190811157),\n",
       " ('others', 0.7164710760116577)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('twitter', topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS42SC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
