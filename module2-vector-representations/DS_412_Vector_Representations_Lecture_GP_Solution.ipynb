{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "py37  (Python3)",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM-KfuCGdQ_9"
      },
      "source": [
        "*Unit 4, Sprint 1, Module 2*\n",
        "\n",
        "---\n",
        "\n",
        "# Vector Representations (Prepare)\n",
        "\n",
        "\n",
        "As we learned yesterday, machines cannot interpret raw text. We need to transform that text into something we/machines can more readily analyze. Yesterday, we did simple counts of counts to summarize the content of Amazon reviews. Today, we'll extend those concepts to talk about vector representations such as Bag of Words (BoW) and word embedding models. We'll use those representations for search, visualization, and prepare for our classification day tomorrow.\n",
        "\n",
        "Processing text data to prepare it for machine learning models often means translating the information from documents into a numerical format. Bag-of-Words approaches (sometimes referred to as Frequency-Based word embeddings) accomplish this by \"vectorizing\" tokenized documents. This is done by representing each document as a row in a DataFrame and creating a column for each unique word in the corpora (group of documents). The presence or lack of a given word in a document is then represented either as a raw count of how many times a given word appears in a document (CountVectorizer) or as that word's TF-IDF score (TfidfVectorizer).\n",
        "\n",
        "On the python side, we will be focusing on `sklearn` and `spacy` today.  \n",
        "\n",
        "## Case Study\n",
        "\n",
        "We're going to pretend we're on the datascience team at the BBC. We want to recommend articles to visitors to on the BBC website based on the article they just read.\n",
        "\n",
        "[BBC data set](http://mlg.ucd.ie/datasets/bbc.html)<br>\n",
        "For today's exercise, we have downloaded the \"raw text files\" from the \"BBC\" data set and focused on the tech articles only\n",
        "\n",
        "## Learning Objectives\n",
        "* <a href=\"#p1\">Part 1</a>: Represent a document as a vector\n",
        "* <a href=\"#p2\">Part 2</a>: Query Documents by Similarity\n",
        "* <a href=\"#p3\">Part 3</a>: Apply word embedding models to create document vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxtT9pdddRAB"
      },
      "source": [
        "### Let's start with an analogy\n",
        "\n",
        "![](https://peterbeshai.com/static/d9c3868cc1becd7648da453597a5d616/36dbb/DER_cube.jpg)\n",
        "\n",
        "Pretend that the objecting floating in the room is our raw text dataset (i.e. a collection of documents).\n",
        "\n",
        "A vectorizer is a mathematical transformation that takes our raw text data and transforms it into a numerical representation (i.e. numbers inside of vectors).\n",
        "\n",
        "Depending on which vectorizer you use, you will be capturing some of the information encoded in the text but not other information.\n",
        "\n",
        "So, as the analogy goes, depending which side of the floating object you stand and shine a light from, you will only see a portion of the information that exists in your text data set. Apply one vectorizer and you'll get word counts but not the contextual meaning; apply another vectorizer and you'll get the contextual meaning of the words but not the counts.\n",
        "\n",
        "**Take Away:** Understand the benefits and limitations of using each of the vectorizers that we'll be learning today.\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmTC1bWMBz02"
      },
      "source": [
        "# 0. Colab notebook setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si_FTZzkeGFD"
      },
      "source": [
        "##0.1 Get `spacy`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMfQKVrneA38",
        "outputId": "aac49c87-e2e7-4653-e76f-b42e5900db9e"
      },
      "source": [
        "%%time\n",
        "# You'll use en_core_web_sm for the sprint challenge due memory constraints on Codegrader\n",
        "#!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Locally (or on colab) let's use en_core_web_lg or en_core_web_md\n",
        "!python -m spacy download en_core_web_md\n",
        "# Also on Colab, need to restart runtime after this step!\n",
        "#      or else Colab won't find spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-py3-none-any.whl size=98051301 sha256=eee82d9b11cb56c5bfaa361e0f920532535aaa283dd70ce0b47b99441884f5dd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q89iomnc/wheels/69/c5/b8/4f1c029d89238734311b3269762ab2ee325a42da2ce8edb997\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "CPU times: user 829 ms, sys: 130 ms, total: 958 ms\n",
            "Wall time: 2min 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRKrvC4feP15"
      },
      "source": [
        "##0.2 Restart the runtime!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eba3NjeAO-Ha"
      },
      "source": [
        "## 0.3 Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XVf_1L3dRAD"
      },
      "source": [
        "\"\"\" Import Statements \"\"\"\n",
        "\n",
        "# Classics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'tagger'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55skIZ7eidH7"
      },
      "source": [
        "##0.4 Clone the git repo\n",
        "so we can access the files in the `/data` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpgi5SBuePAD",
        "outputId": "6fe3613a-3ba6-4fe0-e20a-cbde96dece37"
      },
      "source": [
        "!git clone https://github.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS-Unit-4-Sprint-1-NLP'...\n",
            "remote: Enumerating objects: 1689, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 1689 (delta 88), reused 120 (delta 71), pack-reused 1531\u001b[K\n",
            "Receiving objects: 100% (1689/1689), 59.40 MiB | 23.11 MiB/s, done.\n",
            "Resolving deltas: 100% (257/257), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD4Kv86TjEfJ"
      },
      "source": [
        "## 0.5 Get the BBC tech articles data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v8uWdQRBjF7"
      },
      "source": [
        "Helper function to read articles in `.txt` files in a specified directory and gather them into a big list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m0vfCnqdRAI"
      },
      "source": [
        "import os\n",
        "\n",
        "def gather_data(filefolder):\n",
        "    \"\"\" Produces List of Documents from a Directory\n",
        "\n",
        "    filefolder (str): a path of .txt files\n",
        "\n",
        "    returns list of strings\n",
        "    \"\"\"\n",
        "\n",
        "    data = []\n",
        "\n",
        "    files = os.listdir(filefolder)\n",
        "\n",
        "    for filename in files:\n",
        "\n",
        "        path = os.path.join(filefolder, filename)\n",
        "\n",
        "        if  path[-3:] == 'txt':\n",
        "            with open(path, 'rb') as f:\n",
        "                data.append(f.read())\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSH2TnEnBsK7"
      },
      "source": [
        "Read the articles into a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsYq8x6dRAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654ebca2-ad0d-4faf-b35e-a0e8a9326d72"
      },
      "source": [
        "# locate and get path to the /data folder, using colab's file browser\n",
        "data_path = '/content/DS-Unit-4-Sprint-1-NLP/module2-vector-representations/data'\n",
        "data = gather_data(data_path)\n",
        "print(f'Number of Articles: {len(data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Articles: 401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gx9kYDLCGtN"
      },
      "source": [
        "Articles turn out to be \"byte strings\" so we need to decode them to strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC8NUCwhCY3Z",
        "outputId": "ade703c2-bbca-4b5d-df74-f57c918753c5"
      },
      "source": [
        "print(data[0])\n",
        "print(type(data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"Gritty return for Prince of Persia\\n\\nStill basking in the relatively recent glory of last year's Sands Of Time, the dashing Prince of Persia is back in Warrior Within, and in a more bellicose mood than last time.\\n\\nThis sequel gives the franchise a grim, gritty new look and ramps up the action and violence. As before, you control the super-athletic prince from a third-person perspective. The time-travelling plot hinges on the Dahaka, an all-consuming monster pursuing our hero through the ages. The only way to dispel it is to turn back the clock again and kill the sultry Empress Of Time before she ever creates the Sands of Time that caused the great beast's creation.\\n\\nStudiously structured though this back story is, everything boils down to old-fashioned fantasy gameplay which proves, on the whole, as dependable as it needs to be. Ever since the series' then-groundbreaking beginnings on the Commodore Amiga, Prince of Persia has always been about meticulously-animated acrobatic moves, that provide an energetic blend of leaping preposterously between pieces of scenery and lopping off enemies' body parts.\\n\\nThose flashy moves are back in full evidence, and tremendous fun to perform and perfect. Combining them at speed is the best fun, although getting a handle of doing so takes practice and plenty of skill. Until you reach that point, it is a haphazard business. All too often, you will perform a stunning triple somersault, pirouette off a wall, knock out three enemies in one glorious swoop, before plummeting purposefully over a cliff to your doom. That in turn can mean getting set back an annoyingly long distance, for you can only save at the fountains dotted along the path. The expected fiendish puzzles are all present and correct, but combat is what is really been stepped up, and there is more of it than before. The game's developers have combined acrobatic flair with gruesome slaying techniques in some wonderfully imaginative ways. Slicing foes down the middle is one particularly entertaining method of seeing them off.\\n\\nWarrior Within is a very slick package; the game's intro movie is so phenomenally good that it actually does an ultimate disservice once the game itself commences.\\n\\nIt is on a par with the jaw-dropping opening sequence of Onimusha 3 earlier this year, and when the game begins, it is something of an anti-climax. That said, the graphics are excellent, and indeed among the most striking and satisfying elements of the game. The music is probably the worst aspect - a merit-free heavy metal soundtrack that you will swiftly want to turn off. There is something strangely unsatisfying about the game. Perhaps precisely because its graphics and mechanics are so good that the story and overall experience are not quite as engaging as they should be. Somehow it adds up to less than the sum of its parts, and is more technically impressive than it is outright enjoyable. But that is not to say Warrior Within is anything other than a superb adventure that most will thoroughly enjoy. It just does not quite take the character to the new heights that might have been hoped for.\\n\"\n",
            "<class 'bytes'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubER5c_yPLMG",
        "outputId": "609f42c7-552d-4720-87c3-286dcb027dd7"
      },
      "source": [
        "# decode bytestrings in a corpus to strings\n",
        "# takes a list of documents, i.e a list of strings as input\n",
        "articles = []\n",
        "for article in data:\n",
        "  article = article.decode(\"utf-8\")\n",
        "  articles.append(article)\n",
        "\n",
        "# Preview first article and check data type again\n",
        "data = articles\n",
        "print(data[0])\n",
        "print(type(data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gritty return for Prince of Persia\n",
            "\n",
            "Still basking in the relatively recent glory of last year's Sands Of Time, the dashing Prince of Persia is back in Warrior Within, and in a more bellicose mood than last time.\n",
            "\n",
            "This sequel gives the franchise a grim, gritty new look and ramps up the action and violence. As before, you control the super-athletic prince from a third-person perspective. The time-travelling plot hinges on the Dahaka, an all-consuming monster pursuing our hero through the ages. The only way to dispel it is to turn back the clock again and kill the sultry Empress Of Time before she ever creates the Sands of Time that caused the great beast's creation.\n",
            "\n",
            "Studiously structured though this back story is, everything boils down to old-fashioned fantasy gameplay which proves, on the whole, as dependable as it needs to be. Ever since the series' then-groundbreaking beginnings on the Commodore Amiga, Prince of Persia has always been about meticulously-animated acrobatic moves, that provide an energetic blend of leaping preposterously between pieces of scenery and lopping off enemies' body parts.\n",
            "\n",
            "Those flashy moves are back in full evidence, and tremendous fun to perform and perfect. Combining them at speed is the best fun, although getting a handle of doing so takes practice and plenty of skill. Until you reach that point, it is a haphazard business. All too often, you will perform a stunning triple somersault, pirouette off a wall, knock out three enemies in one glorious swoop, before plummeting purposefully over a cliff to your doom. That in turn can mean getting set back an annoyingly long distance, for you can only save at the fountains dotted along the path. The expected fiendish puzzles are all present and correct, but combat is what is really been stepped up, and there is more of it than before. The game's developers have combined acrobatic flair with gruesome slaying techniques in some wonderfully imaginative ways. Slicing foes down the middle is one particularly entertaining method of seeing them off.\n",
            "\n",
            "Warrior Within is a very slick package; the game's intro movie is so phenomenally good that it actually does an ultimate disservice once the game itself commences.\n",
            "\n",
            "It is on a par with the jaw-dropping opening sequence of Onimusha 3 earlier this year, and when the game begins, it is something of an anti-climax. That said, the graphics are excellent, and indeed among the most striking and satisfying elements of the game. The music is probably the worst aspect - a merit-free heavy metal soundtrack that you will swiftly want to turn off. There is something strangely unsatisfying about the game. Perhaps precisely because its graphics and mechanics are so good that the story and overall experience are not quite as engaging as they should be. Somehow it adds up to less than the sum of its parts, and is more technically impressive than it is outright enjoyable. But that is not to say Warrior Within is anything other than a superb adventure that most will thoroughly enjoy. It just does not quite take the character to the new heights that might have been hoped for.\n",
            "\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CF_285ECuXV"
      },
      "source": [
        "Make a `spacy` tokenizer, as in Module 1<br>\n",
        "Question: why did we use [`.strip()`](https://python-reference.readthedocs.io/en/latest/docs/str/strip.html)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlnxqpI2dRAQ"
      },
      "source": [
        "def tokenize(document):\n",
        "    \"\"\"\n",
        "    Takes a doc (text string) and returns a list of tokens in the form of lemmas.\n",
        "    Filters out Stop words, punctuation, and leading/trailing spaces.\n",
        "    \"\"\"\n",
        "\n",
        "    doc = nlp(document)\n",
        "    # Returns lower cased lemmas without stop words, punctuation, numbers, and empty strings\n",
        "    lemma_list = [token.lemma_.lower().strip() for token in doc if (not token.is_stop)\n",
        "                                                                and (not token.is_punct)\n",
        "                                                                and (not token.is_digit)\n",
        "                                                                and (not token.like_num)\n",
        "                                                                and (token.lemma_.strip()!=\"\")\n",
        "                                                                and (len(token.lemma_.strip())>1)]\n",
        "    return lemma_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('My 3 dogs ate my homework assignments! It cost me $1.5 million.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf_j857lQ5Xa",
        "outputId": "70853a16-aab1-45c9-da0c-9f900741d105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog', 'eat', 'homework', 'assignment', 'cost']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "DKox9ksM2RWM",
        "outputId": "d26fc6c4-2b5b-4f3e-d795-238415690ee8"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Gritty return for Prince of Persia\\n\\nStill basking in the relatively recent glory of last year's Sands Of Time, the dashing Prince of Persia is back in Warrior Within, and in a more bellicose mood than last time.\\n\\nThis sequel gives the franchise a grim, gritty new look and ramps up the action and violence. As before, you control the super-athletic prince from a third-person perspective. The time-travelling plot hinges on the Dahaka, an all-consuming monster pursuing our hero through the ages. The only way to dispel it is to turn back the clock again and kill the sultry Empress Of Time before she ever creates the Sands of Time that caused the great beast's creation.\\n\\nStudiously structured though this back story is, everything boils down to old-fashioned fantasy gameplay which proves, on the whole, as dependable as it needs to be. Ever since the series' then-groundbreaking beginnings on the Commodore Amiga, Prince of Persia has always been about meticulously-animated acrobatic moves, that provide an energetic blend of leaping preposterously between pieces of scenery and lopping off enemies' body parts.\\n\\nThose flashy moves are back in full evidence, and tremendous fun to perform and perfect. Combining them at speed is the best fun, although getting a handle of doing so takes practice and plenty of skill. Until you reach that point, it is a haphazard business. All too often, you will perform a stunning triple somersault, pirouette off a wall, knock out three enemies in one glorious swoop, before plummeting purposefully over a cliff to your doom. That in turn can mean getting set back an annoyingly long distance, for you can only save at the fountains dotted along the path. The expected fiendish puzzles are all present and correct, but combat is what is really been stepped up, and there is more of it than before. The game's developers have combined acrobatic flair with gruesome slaying techniques in some wonderfully imaginative ways. Slicing foes down the middle is one particularly entertaining method of seeing them off.\\n\\nWarrior Within is a very slick package; the game's intro movie is so phenomenally good that it actually does an ultimate disservice once the game itself commences.\\n\\nIt is on a par with the jaw-dropping opening sequence of Onimusha 3 earlier this year, and when the game begins, it is something of an anti-climax. That said, the graphics are excellent, and indeed among the most striking and satisfying elements of the game. The music is probably the worst aspect - a merit-free heavy metal soundtrack that you will swiftly want to turn off. There is something strangely unsatisfying about the game. Perhaps precisely because its graphics and mechanics are so good that the story and overall experience are not quite as engaging as they should be. Somehow it adds up to less than the sum of its parts, and is more technically impressive than it is outright enjoyable. But that is not to say Warrior Within is anything other than a superb adventure that most will thoroughly enjoy. It just does not quite take the character to the new heights that might have been hoped for.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Zl0PeDOigp",
        "outputId": "00a5a231-bb2a-41b8-bc03-a58ab8db8711"
      },
      "source": [
        "tokenize(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gritty',\n",
              " 'return',\n",
              " 'prince',\n",
              " 'persia',\n",
              " 'bask',\n",
              " 'relatively',\n",
              " 'recent',\n",
              " 'glory',\n",
              " 'year',\n",
              " 'sands',\n",
              " 'time',\n",
              " 'dash',\n",
              " 'prince',\n",
              " 'persia',\n",
              " 'warrior',\n",
              " 'bellicose',\n",
              " 'mood',\n",
              " 'time',\n",
              " 'sequel',\n",
              " 'give',\n",
              " 'franchise',\n",
              " 'grim',\n",
              " 'gritty',\n",
              " 'new',\n",
              " 'look',\n",
              " 'ramp',\n",
              " 'action',\n",
              " 'violence',\n",
              " 'control',\n",
              " 'super',\n",
              " 'athletic',\n",
              " 'prince',\n",
              " 'person',\n",
              " 'perspective',\n",
              " 'time',\n",
              " 'travel',\n",
              " 'plot',\n",
              " 'hinge',\n",
              " 'dahaka',\n",
              " 'consume',\n",
              " 'monster',\n",
              " 'pursue',\n",
              " 'hero',\n",
              " 'age',\n",
              " 'way',\n",
              " 'dispel',\n",
              " 'turn',\n",
              " 'clock',\n",
              " 'kill',\n",
              " 'sultry',\n",
              " 'empress',\n",
              " 'time',\n",
              " 'create',\n",
              " 'sands',\n",
              " 'time',\n",
              " 'cause',\n",
              " 'great',\n",
              " 'beast',\n",
              " 'creation',\n",
              " 'studiously',\n",
              " 'structure',\n",
              " 'story',\n",
              " 'boil',\n",
              " 'old',\n",
              " 'fashion',\n",
              " 'fantasy',\n",
              " 'gameplay',\n",
              " 'prove',\n",
              " 'dependable',\n",
              " 'need',\n",
              " 'series',\n",
              " 'groundbreaking',\n",
              " 'beginning',\n",
              " 'commodore',\n",
              " 'amiga',\n",
              " 'prince',\n",
              " 'persia',\n",
              " 'meticulously',\n",
              " 'animate',\n",
              " 'acrobatic',\n",
              " 'move',\n",
              " 'provide',\n",
              " 'energetic',\n",
              " 'blend',\n",
              " 'leap',\n",
              " 'preposterously',\n",
              " 'piece',\n",
              " 'scenery',\n",
              " 'lop',\n",
              " 'enemy',\n",
              " 'body',\n",
              " 'part',\n",
              " 'flashy',\n",
              " 'move',\n",
              " 'evidence',\n",
              " 'tremendous',\n",
              " 'fun',\n",
              " 'perform',\n",
              " 'perfect',\n",
              " 'combining',\n",
              " 'speed',\n",
              " 'well',\n",
              " 'fun',\n",
              " 'get',\n",
              " 'handle',\n",
              " 'take',\n",
              " 'practice',\n",
              " 'plenty',\n",
              " 'skill',\n",
              " 'reach',\n",
              " 'point',\n",
              " 'haphazard',\n",
              " 'business',\n",
              " 'perform',\n",
              " 'stun',\n",
              " 'triple',\n",
              " 'somersault',\n",
              " 'pirouette',\n",
              " 'wall',\n",
              " 'knock',\n",
              " 'enemy',\n",
              " 'glorious',\n",
              " 'swoop',\n",
              " 'plummet',\n",
              " 'purposefully',\n",
              " 'cliff',\n",
              " 'doom',\n",
              " 'turn',\n",
              " 'mean',\n",
              " 'get',\n",
              " 'set',\n",
              " 'annoyingly',\n",
              " 'long',\n",
              " 'distance',\n",
              " 'save',\n",
              " 'fountain',\n",
              " 'dot',\n",
              " 'path',\n",
              " 'expect',\n",
              " 'fiendish',\n",
              " 'puzzle',\n",
              " 'present',\n",
              " 'correct',\n",
              " 'combat',\n",
              " 'step',\n",
              " 'game',\n",
              " 'developer',\n",
              " 'combine',\n",
              " 'acrobatic',\n",
              " 'flair',\n",
              " 'gruesome',\n",
              " 'slay',\n",
              " 'technique',\n",
              " 'wonderfully',\n",
              " 'imaginative',\n",
              " 'way',\n",
              " 'slicing',\n",
              " 'foe',\n",
              " 'middle',\n",
              " 'particularly',\n",
              " 'entertain',\n",
              " 'method',\n",
              " 'see',\n",
              " 'warrior',\n",
              " 'slick',\n",
              " 'package',\n",
              " 'game',\n",
              " 'intro',\n",
              " 'movie',\n",
              " 'phenomenally',\n",
              " 'good',\n",
              " 'actually',\n",
              " 'ultimate',\n",
              " 'disservice',\n",
              " 'game',\n",
              " 'commence',\n",
              " 'par',\n",
              " 'jaw',\n",
              " 'drop',\n",
              " 'open',\n",
              " 'sequence',\n",
              " 'onimusha',\n",
              " 'early',\n",
              " 'year',\n",
              " 'game',\n",
              " 'begin',\n",
              " 'anti',\n",
              " 'climax',\n",
              " 'say',\n",
              " 'graphic',\n",
              " 'excellent',\n",
              " 'strike',\n",
              " 'satisfy',\n",
              " 'element',\n",
              " 'game',\n",
              " 'music',\n",
              " 'probably',\n",
              " 'wrong',\n",
              " 'aspect',\n",
              " 'merit',\n",
              " 'free',\n",
              " 'heavy',\n",
              " 'metal',\n",
              " 'soundtrack',\n",
              " 'swiftly',\n",
              " 'want',\n",
              " 'turn',\n",
              " 'strangely',\n",
              " 'unsatisfying',\n",
              " 'game',\n",
              " 'precisely',\n",
              " 'graphic',\n",
              " 'mechanic',\n",
              " 'good',\n",
              " 'story',\n",
              " 'overall',\n",
              " 'experience',\n",
              " 'engage',\n",
              " 'add',\n",
              " 'sum',\n",
              " 'part',\n",
              " 'technically',\n",
              " 'impressive',\n",
              " 'outright',\n",
              " 'enjoyable',\n",
              " 'warrior',\n",
              " 'superb',\n",
              " 'adventure',\n",
              " 'thoroughly',\n",
              " 'enjoy',\n",
              " 'character',\n",
              " 'new',\n",
              " 'height',\n",
              " 'hope']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvGZ-eiUdRAB"
      },
      "source": [
        "# 1. Represent a document as a vector (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUmQeX5dRAC"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this section, we are going to create Document Term Matrices (DTM). <br>\n",
        "In the DTM, each row represents a document. The columns correspond to the vocabulary words of the entire corpus of documents. <br>\n",
        "Today, we'll learn three methods of computing the value in each cell. <br>\n",
        "* `CountVectorizer` from `sklearn` provides a basic implementation: counts of appearances of words. You could also ignore multiple occurrences of words in a document, and just keep track of whether or not a word occurs in the document via a boolean value.<br>\n",
        "* `TfidfVectorizer` is a more advanced implementation that keeps track of *term-frequency inverse-document frequency* (TF-IDF) instead of integer counts.\n",
        "\n",
        "* Word embeddings, an even more sophisticated method that helps solve the problem of accounting for the context of a word.\n",
        "\n",
        "**Discussion:** Don't we lose all the context and grammar if we do this? So Why does it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "TQQRch8mdRAD"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVIflCt1dRAF"
      },
      "source": [
        "**Warm Up (_3 Minutes_)**\n",
        "\n",
        "Extract the tokens from this sentence using Spacy. Text is from [OpenAI](https://openai.com/blog/better-language-models/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg63BJ6-dRAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c471321f-798c-497c-984f-75a26bdff193"
      },
      "source": [
        "text = \"\"\"\n",
        "GPT-2 displays a broad set of capabilities, including the ability to generate conditional synthetic text samples of unprecedented quality,\n",
        "where we prime the model with an input and have it generate a lengthy continuation. In addition, GPT-2 outperforms other language models\n",
        "trained on specific domains (like Wikipedia, news, or books) without needing to use these domain-specific training datasets. On language\n",
        "tasks like question answering, reading comprehension, summarization, and translation, GPT-2 begins to learn these tasks from the raw text,\n",
        "using no task-specific training data. While scores on these downstream tasks are far from state-of-the-art, they suggest that the tasks\n",
        "can benefit from unsupervised techniques, given sufficient (unlabeled) data and compute.\"\"\"\n",
        "\n",
        "print(f'Number of Words: {len(text.split())}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Words: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9rHYGcKRX-n",
        "outputId": "f1e783e4-cc57-462d-e372-d78c878def40"
      },
      "source": [
        "tokens = tokenize(text)\n",
        "print(f'Number of Words: {len(tokens)}')\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Words: 73\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gpt-2',\n",
              " 'display',\n",
              " 'broad',\n",
              " 'set',\n",
              " 'capability',\n",
              " 'include',\n",
              " 'ability',\n",
              " 'generate',\n",
              " 'conditional',\n",
              " 'synthetic',\n",
              " 'text',\n",
              " 'sample',\n",
              " 'unprecedented',\n",
              " 'quality',\n",
              " 'prime',\n",
              " 'model',\n",
              " 'input',\n",
              " 'generate',\n",
              " 'lengthy',\n",
              " 'continuation',\n",
              " 'addition',\n",
              " 'gpt-2',\n",
              " 'outperform',\n",
              " 'language',\n",
              " 'model',\n",
              " 'train',\n",
              " 'specific',\n",
              " 'domain',\n",
              " 'like',\n",
              " 'wikipedia',\n",
              " 'news',\n",
              " 'book',\n",
              " 'need',\n",
              " 'use',\n",
              " 'domain',\n",
              " 'specific',\n",
              " 'train',\n",
              " 'dataset',\n",
              " 'language',\n",
              " 'task',\n",
              " 'like',\n",
              " 'question',\n",
              " 'answer',\n",
              " 'read',\n",
              " 'comprehension',\n",
              " 'summarization',\n",
              " 'translation',\n",
              " 'gpt-2',\n",
              " 'begin',\n",
              " 'learn',\n",
              " 'task',\n",
              " 'raw',\n",
              " 'text',\n",
              " 'task',\n",
              " 'specific',\n",
              " 'train',\n",
              " 'datum',\n",
              " 'score',\n",
              " 'downstream',\n",
              " 'task',\n",
              " 'far',\n",
              " 'state',\n",
              " 'art',\n",
              " 'suggest',\n",
              " 'task',\n",
              " 'benefit',\n",
              " 'unsupervised',\n",
              " 'technique',\n",
              " 'give',\n",
              " 'sufficient',\n",
              " 'unlabeled',\n",
              " 'datum',\n",
              " 'compute']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kJlWC4BdRAK"
      },
      "source": [
        "-----\n",
        "# 1.1 `CountVectorizer`\n",
        "\n",
        "<img src=\"https://images4.programmersought.com/947/0a/0acb9279d17a1631bcfb154583cca443.JPEG\" width=\"700\" height=\"400\" />\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c6a74f21ed3917ee",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "gRM5YA8KdRAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcaabf8f-3b70-4aee-cc61-cf309e746602"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# list of text documents\n",
        "\n",
        "# create the transformer\n",
        "\n",
        "# build vocab\n",
        "\n",
        "# transform text\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "# a corpus is a collection of text documents\n",
        "corpus = [\"We created a new dataset which emphasizes diversity of content, by scraping content from the Internet.\",\n",
        "          \"In order to preserve document quality, we used only pages which have been curated/filtered by humans—specifically, we used outbound links from Reddit which received at least 3 karma.\",\n",
        "          \"This can be thought of as a heuristic indicator for whether other users found the link interesting (whether educational or funny), leading to higher data quality than other similar datasets, such as CommonCrawl.\"]\n",
        "\n",
        "# create the transformer\n",
        "vect = CountVectorizer()\n",
        "\n",
        "# build vocabulary\n",
        "vect.fit(corpus)\n",
        "\n",
        "# transform text to create the document-term matrix\n",
        "dtm = vect.transform(corpus)\n",
        "dtm\n",
        "# Create a Vocabulary\n",
        "\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x61 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 69 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-93323028a4bfd7e7",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGKln3xLdRAL",
        "outputId": "e4ad08f3-464c-4e67-d22e-d6f1354776ef"
      },
      "source": [
        "# Explore the document-term matrix and get vocabulary\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "print(vect.get_feature_names_out())\n",
        "print(len(vect.get_feature_names_out()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['as' 'at' 'be' 'been' 'by' 'can' 'commoncrawl' 'content' 'created'\n",
            " 'curated' 'data' 'dataset' 'datasets' 'diversity' 'document'\n",
            " 'educational' 'emphasizes' 'filtered' 'for' 'found' 'from' 'funny' 'have'\n",
            " 'heuristic' 'higher' 'humans' 'in' 'indicator' 'interesting' 'internet'\n",
            " 'karma' 'leading' 'least' 'link' 'links' 'new' 'of' 'only' 'or' 'order'\n",
            " 'other' 'outbound' 'pages' 'preserve' 'quality' 'received' 'reddit'\n",
            " 'scraping' 'similar' 'specifically' 'such' 'than' 'the' 'this' 'thought'\n",
            " 'to' 'used' 'users' 'we' 'whether' 'which']\n",
            "61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99utB63ckHZO",
        "outputId": "c1a00f52-36f6-4b23-d449-709dc8e43f66"
      },
      "source": [
        "# explore the document-term matrix and understand it's structure\n",
        "print(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 4)\t1\n",
            "  (0, 7)\t2\n",
            "  (0, 8)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 16)\t1\n",
            "  (0, 20)\t1\n",
            "  (0, 29)\t1\n",
            "  (0, 35)\t1\n",
            "  (0, 36)\t1\n",
            "  (0, 47)\t1\n",
            "  (0, 52)\t1\n",
            "  (0, 58)\t1\n",
            "  (0, 60)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 20)\t1\n",
            "  (1, 22)\t1\n",
            "  (1, 25)\t1\n",
            "  (1, 26)\t1\n",
            "  (1, 30)\t1\n",
            "  :\t:\n",
            "  (2, 10)\t1\n",
            "  (2, 12)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 18)\t1\n",
            "  (2, 19)\t1\n",
            "  (2, 21)\t1\n",
            "  (2, 23)\t1\n",
            "  (2, 24)\t1\n",
            "  (2, 27)\t1\n",
            "  (2, 28)\t1\n",
            "  (2, 31)\t1\n",
            "  (2, 33)\t1\n",
            "  (2, 36)\t1\n",
            "  (2, 38)\t1\n",
            "  (2, 40)\t2\n",
            "  (2, 44)\t1\n",
            "  (2, 48)\t1\n",
            "  (2, 50)\t1\n",
            "  (2, 51)\t1\n",
            "  (2, 52)\t1\n",
            "  (2, 53)\t1\n",
            "  (2, 54)\t1\n",
            "  (2, 55)\t1\n",
            "  (2, 57)\t1\n",
            "  (2, 59)\t2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3TSijzlFmvP",
        "outputId": "b732d947-d36b-4cb2-ef49-d1000f0e79e3"
      },
      "source": [
        "dtm.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
              "        [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 2],\n",
              "        [2, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 2, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBq6oeR-FhIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "1a4648dc-21c6-4f39-f94e-f74fe6441504"
      },
      "source": [
        "# Get Word Counts for each document\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names_out())\n",
        "print(dtm.shape)\n",
        "dtm.head()\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 61)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   as  at  be  been  by  can  commoncrawl  content  created  curated  ...  \\\n",
              "0   0   0   0     0   1    0            0        2        1        0  ...   \n",
              "1   0   1   0     1   1    0            0        0        0        1  ...   \n",
              "2   2   0   1     0   0    1            1        0        0        0  ...   \n",
              "\n",
              "   than  the  this  thought  to  used  users  we  whether  which  \n",
              "0     0    1     0        0   0     0      0   1        0      1  \n",
              "1     0    0     0        0   1     2      0   2        0      2  \n",
              "2     1    1     1        1   1     0      1   0        2      0  \n",
              "\n",
              "[3 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b13bea3-8809-402e-b422-b09bb39ddd7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>as</th>\n",
              "      <th>at</th>\n",
              "      <th>be</th>\n",
              "      <th>been</th>\n",
              "      <th>by</th>\n",
              "      <th>can</th>\n",
              "      <th>commoncrawl</th>\n",
              "      <th>content</th>\n",
              "      <th>created</th>\n",
              "      <th>curated</th>\n",
              "      <th>...</th>\n",
              "      <th>than</th>\n",
              "      <th>the</th>\n",
              "      <th>this</th>\n",
              "      <th>thought</th>\n",
              "      <th>to</th>\n",
              "      <th>used</th>\n",
              "      <th>users</th>\n",
              "      <th>we</th>\n",
              "      <th>whether</th>\n",
              "      <th>which</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b13bea3-8809-402e-b422-b09bb39ddd7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b13bea3-8809-402e-b422-b09bb39ddd7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b13bea3-8809-402e-b422-b09bb39ddd7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJWsLvkXdRAL"
      },
      "source": [
        "**Three Minute Challenge:**\n",
        "* Apply CountVectorizer to our BBC Data\n",
        "* Store results in a dataframe called `dtm`\n",
        "* Extra Challenge - Try to Customize CountVectorizer with Spacy Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3a7cd500efe1978b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "0LQrT4qydRAL",
        "outputId": "65c0c929-a702-4165-f8c2-c1c17309c95e"
      },
      "source": [
        "# Apply CountVectorizer to our Data\n",
        "# Use custom Spacy Vectorizer\n",
        "# BBC articles in `data` variable\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "\n",
        "# Instantiate the CountVectorizer object\n",
        "vect = CountVectorizer()\n",
        "\n",
        "# Learn our Vocab\n",
        "vect.fit(data)\n",
        "\n",
        "# Transform the BBC news articles\n",
        "dtm = vect.transform(data)\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names_out())\n",
        "print(dtm.shape)\n",
        "dtm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(401, 12098)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   00  000  000s  0051  007  01  028  04m  05  0530  ...  zip  zodiac  zombie  \\\n",
              "0   0    0     0     0    0   0    0    0   0     0  ...    0       0       0   \n",
              "1   0    0     0     0    0   0    0    0   0     0  ...    0       0       0   \n",
              "2   0    0     0     0    0   0    0    0   0     0  ...    0       0       0   \n",
              "3   0    4     0     0    0   0    0    0   0     0  ...    0       0       0   \n",
              "4   0    0     0     0    0   0    0    0   0     0  ...    0       0       0   \n",
              "\n",
              "   zombies  zone  zonealarm  zones  zoom  zooms  zurich  \n",
              "0        0     0          0      0     0      0       0  \n",
              "1        0     0          0      0     0      0       0  \n",
              "2        0     0          0      0     0      0       0  \n",
              "3        0     0          0      0     0      0       0  \n",
              "4        0     0          0      0     0      0       0  \n",
              "\n",
              "[5 rows x 12098 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b158a9a-59a0-4401-b58a-4fefa3491523\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>000s</th>\n",
              "      <th>0051</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>028</th>\n",
              "      <th>04m</th>\n",
              "      <th>05</th>\n",
              "      <th>0530</th>\n",
              "      <th>...</th>\n",
              "      <th>zip</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombies</th>\n",
              "      <th>zone</th>\n",
              "      <th>zonealarm</th>\n",
              "      <th>zones</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zooms</th>\n",
              "      <th>zurich</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12098 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b158a9a-59a0-4401-b58a-4fefa3491523')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b158a9a-59a0-4401-b58a-4fefa3491523 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b158a9a-59a0-4401-b58a-4fefa3491523');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "G6JBj-YUdRAM",
        "outputId": "083368ce-b486-464b-ca60-b6e241b92ba2"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "doc_len = [len(doc.split()) for doc in data]\n",
        "sns.displot(doc_len);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYgUj_WcdRAN"
      },
      "source": [
        "#1.2  `TfidfVectorizer`\n",
        "\n",
        "## Term Frequency - Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "![](https://miro.medium.com/max/1404/1*mu6G-cBmWlENS4pWHEnGcg@2x.jpeg)\n",
        "\n",
        "\n",
        "**Term Frequency**: $\\text{tf}_{i,j}$  is the number of times term $i$ appeared in document $j$\n",
        "\n",
        "**Inverse Document Frequency:** A weight penalty for terms that exist in a high fraction of documents.\n",
        "\n",
        "The purpose of TF-IDF is to find what is **unique** to each document. Because of this we will penalize the term frequencies of words that are common across all documents. This effectively upweights terms that are rarer across documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfzMqqbrdRAN"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/Logarithm_plots.png\" width=\"700\" height=\"400\" />\n",
        "\n",
        "It's useful to reference both the algebraic and geometric representations of a single mathematical ideal whenever possible in order to build the fullest understanding possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uysxF1NdRAN"
      },
      "source": [
        "The IDF portion of the TF-IDF equation has been coded up below so that we can play around with the values and get a better understanding of how this portion of the equation works.\n",
        "\n",
        "NOTE: There are other ways to construct the equation for the IDF term; different constructions of the equation serve different purposes and which you ultimately use simply depends on your problem/task. You can check out the [wikipedia article on tfidf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
        "\n",
        "In practice, you usually don't even have to think about the mathematical formulation of the IDF term. You simply import the tfidf vectorizer and use its api. The rare exception to this would if you are working a very particular kind of problem where the open source implementation of tfidf doesn't suit your needs and so then you might consider creating your own equation or using a different one that you read about."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk_AVqh3dRAN"
      },
      "source": [
        "# inverse document frequency score\n",
        "# the plus ones are constants that shift the around the baseline value\n",
        "def idf(n, df):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    n: int\n",
        "        num of docs in corpus\n",
        "\n",
        "    df: int\n",
        "        num of docs that term t (i.e. a token) appears in\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    inverse docuemnt frequency: float\n",
        "    \"\"\"\n",
        "    return np.log(n/df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4e40eb25d7faed91",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1uh6Ab7FdRAO"
      },
      "source": [
        "###BEGIN SOLUTION\n",
        "n = 100 # num of docs in corpus\n",
        "df_range = 100\n",
        "IDF = []\n",
        "DF = []\n",
        "for df in range(1, df_range + 1):\n",
        "    idf_score = idf(n, df)\n",
        "    IDF.append(idf_score)\n",
        "    DF.append(df)\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "qVAUfwlddRAO",
        "outputId": "d0c57106-d688-482e-dc3e-3e0c04c64023"
      },
      "source": [
        "plt.figure()\n",
        "plt.title(\"Inverse Document Frequency Score vs. Document Frequency of Token\")\n",
        "plt.ylabel(\"Inverse Document Frequency Score\")\n",
        "plt.xlabel(\"Document Frequency of Token\")\n",
        "plt.grid()\n",
        "plt.plot(DF, IDF);\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Inverse Document Frequency Score vs. Document Frequency of Token\")\n",
        "plt.ylabel(\"Inverse Document Frequency Score\")\n",
        "plt.xlabel(\"Document Frequency of Token\")\n",
        "plt.xlim(95,100)\n",
        "plt.ylim(0,0.10)\n",
        "plt.grid()\n",
        "plt.plot(DF, IDF);\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-bed0fb42b084357d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7dv3fH2dRAO",
        "outputId": "78bff13c-3601-4258-ec98-5d2b2c280654"
      },
      "source": [
        "# let's work through a couple of examples to help build intuition\n",
        "\n",
        "# imagine the token we are considering is \"purchase\", which rarely appears\n",
        "\n",
        "# imagine the token that we are considering is \"the\", which appears often\n",
        "\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "n = 100 # num of docs in corpus\n",
        "\n",
        "# imagine the token we are considering is \"purchase\"\n",
        "tf = 1\n",
        "df = 20\n",
        "\n",
        "tfidf_score = tf * idf(n, df)\n",
        "print(f'TF-IDF score for \"purchase\": {tfidf_score:.2f}')\n",
        "\n",
        "###END SOLUTION\n",
        "# imagine the token that we are considering is \"the\"\n",
        "tf = 50\n",
        "df = 95\n",
        "\n",
        "tfidf_score = tf * idf(n, df)\n",
        "print(f'TF-IDF score for \"the\": {tfidf_score:.2f}')\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for \"purchase\": 1.61\n",
            "TF-IDF score for \"the\": 2.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQbFzVXAdRAP"
      },
      "source": [
        "Now that we have built some intuition on how TFIDF works, let's use `sklearn`'s `TfidfVectorizer` to vectorize our dataset. <br>\n",
        "Note that `TfidfVectorizer` is used with the same syntax as `CountVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4ccfa3ef2d0404fc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "Lm6FsqHOdRAP",
        "outputId": "409f150a-52dd-4227-fa2c-9e69b7d37251"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "# 1. Instantiate vectorizer object\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "\n",
        "# 2. Create a vocabulary and get word counts per document\n",
        "dtm = tfidf.fit_transform(data)\n",
        "\n",
        "# 3. View term-document matrix as DataFrame\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names_out())\n",
        "print(dtm.shape)\n",
        "dtm.head()\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(401, 1000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        000        10       100   11        12   14   15   18   20  200  ...  \\\n",
              "0  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "1  0.000000  0.000000  0.000000  0.0  0.138567  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "2  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "3  0.095859  0.000000  0.034623  0.0  0.035307  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "4  0.000000  0.025816  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "\n",
              "   worldwide      worm  worth   writing  xbox        xp     yahoo      year  \\\n",
              "0   0.000000  0.000000    0.0  0.000000   0.0  0.000000  0.000000  0.098905   \n",
              "1   0.041438  0.000000    0.0  0.000000   0.0  0.000000  0.000000  0.000000   \n",
              "2   0.000000  0.000000    0.0  0.000000   0.0  0.069278  0.138556  0.028937   \n",
              "3   0.000000  0.100129    0.0  0.085354   0.0  0.000000  0.000000  0.039292   \n",
              "4   0.000000  0.000000    0.0  0.000000   0.0  0.000000  0.000000  0.000000   \n",
              "\n",
              "   years  york  \n",
              "0    0.0   0.0  \n",
              "1    0.0   0.0  \n",
              "2    0.0   0.0  \n",
              "3    0.0   0.0  \n",
              "4    0.0   0.0  \n",
              "\n",
              "[5 rows x 1000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-508cca28-3356-48a8-9c7d-cfb154834475\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>18</th>\n",
              "      <th>20</th>\n",
              "      <th>200</th>\n",
              "      <th>...</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>worm</th>\n",
              "      <th>worth</th>\n",
              "      <th>writing</th>\n",
              "      <th>xbox</th>\n",
              "      <th>xp</th>\n",
              "      <th>yahoo</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>york</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069278</td>\n",
              "      <td>0.138556</td>\n",
              "      <td>0.028937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.095859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035307</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100129</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085354</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039292</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025816</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-508cca28-3356-48a8-9c7d-cfb154834475')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-508cca28-3356-48a8-9c7d-cfb154834475 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-508cca28-3356-48a8-9c7d-cfb154834475');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_VFnOHrMMtT"
      },
      "source": [
        "Now let's get a little fancier with the `TfidfVEctorizer`: we'll use the keywords `ngram_range`, `max_df`, `min_df` and `tokenizer` to accomplish the following:\n",
        "- Build a vocabulary from unigrams and bigrams\n",
        "- Do \"statistical trimming\" by ignoring all terms with document frequency higher than `max_df` and all terms with document frequency lower than `min_df`\n",
        "- Use the `spaCy` tokenizer that we built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0667a7a2ebea2224",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKB5QWy-dRAQ",
        "outputId": "2a080158-62f6-4387-f5d7-274e17211885"
      },
      "source": [
        "%%time\n",
        "# Tuning Parameters\n",
        "\n",
        "# Instantiate vectorizer object\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "\n",
        "# Print word counts\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "# Instantiate vectorizer object (ngram_range includes unigrams and bigrams)\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,2),\n",
        "                        max_df=0.25,            # \"statistical trimming\"\n",
        "                        min_df=5,               # \"statistical trimming\"\n",
        "                        tokenizer=tokenize)     # custom tokenizer\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "dtm = tfidf.fit_transform(data)\n",
        "\n",
        "# Print word counts\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names_out())\n",
        "print(dtm.shape)\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(401, 3414)\n",
            "CPU times: user 11.2 s, sys: 224 ms, total: 11.5 s\n",
            "Wall time: 12.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "z7nLmwWPWW_V",
        "outputId": "2fa5beba-15a5-47f6-a7a3-4fd30e9a2af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   1980s  1990s  1bn  21st  21st century   3d  3d graphic  3d model      3gsm  \\\n",
              "0    0.0    0.0  0.0   0.0           0.0  0.0         0.0       0.0  0.000000   \n",
              "1    0.0    0.0  0.0   0.0           0.0  0.0         0.0       0.0  0.147048   \n",
              "2    0.0    0.0  0.0   0.0           0.0  0.0         0.0       0.0  0.000000   \n",
              "3    0.0    0.0  0.0   0.0           0.0  0.0         0.0       0.0  0.000000   \n",
              "4    0.0    0.0  0.0   0.0           0.0  0.0         0.0       0.0  0.000000   \n",
              "\n",
              "   ability  ...  year use  yen  yes  york  young  young people  youth  zombie  \\\n",
              "0      0.0  ...       0.0  0.0  0.0   0.0    0.0           0.0    0.0     0.0   \n",
              "1      0.0  ...       0.0  0.0  0.0   0.0    0.0           0.0    0.0     0.0   \n",
              "2      0.0  ...       0.0  0.0  0.0   0.0    0.0           0.0    0.0     0.0   \n",
              "3      0.0  ...       0.0  0.0  0.0   0.0    0.0           0.0    0.0     0.0   \n",
              "4      0.0  ...       0.0  0.0  0.0   0.0    0.0           0.0    0.0     0.0   \n",
              "\n",
              "   zone  zoom  \n",
              "0   0.0   0.0  \n",
              "1   0.0   0.0  \n",
              "2   0.0   0.0  \n",
              "3   0.0   0.0  \n",
              "4   0.0   0.0  \n",
              "\n",
              "[5 rows x 3414 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba93e39b-2e04-43d8-968a-2923985b4efd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1980s</th>\n",
              "      <th>1990s</th>\n",
              "      <th>1bn</th>\n",
              "      <th>21st</th>\n",
              "      <th>21st century</th>\n",
              "      <th>3d</th>\n",
              "      <th>3d graphic</th>\n",
              "      <th>3d model</th>\n",
              "      <th>3gsm</th>\n",
              "      <th>ability</th>\n",
              "      <th>...</th>\n",
              "      <th>year use</th>\n",
              "      <th>yen</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>young people</th>\n",
              "      <th>youth</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147048</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3414 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba93e39b-2e04-43d8-968a-2923985b4efd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba93e39b-2e04-43d8-968a-2923985b4efd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba93e39b-2e04-43d8-968a-2923985b4efd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTMPm-hbdRAQ"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "During this module's project assignment, you will transform data science job listings to vector representations for analysis downstream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oddqm9omdRAR"
      },
      "source": [
        "# 2. Query Documents by Similarity (Learn)\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myAGpeGOdRAR"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Have you ever considered how a search bar works in Google? You may just think that search bars simply match your input text against the documents. While there are many different mechanisms for the 'match', one of the most classic is to search by similarity. We will apply two measures of similarity between a document and the input query document: the **Cosine Similarity** between the documents and the **Euclidean distance** between the documents. <br>\n",
        "\n",
        "Cosine Similarity is [more compute intensive](https://stackoverflow.com/questions/28917985/why-cosine-distance-is-much-slower-than-using-euclidean-distance-with-dbscan-alg) than Euclidean distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "GG_E_NYfdRAR"
      },
      "source": [
        "## Follow Along\n",
        "*Cosine similarity* and *nearest-neighbor distance* provide two measures that can be used to gauge the similarity of one word to another. <br>\n",
        "We develop these concepts in this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_vR2dvwdRAS"
      },
      "source": [
        "### 2.1 Cosine Similarity\n",
        "The [`cosine_simlarity`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) between two feature vectors is the dot product of the *normalized* feature vectors. <br>To *normalize* a vector, you simply divide it by its length: thus<br><br>\n",
        "$\\text{cosine_similarity}(\\textbf{u},\\textbf{v})= \\frac{\\textbf{u}}{\\left\\|\\textbf{u}\\right\\|} \\cdot \\frac{\\textbf{v}}{\\left\\|\\textbf{v}\\right\\|}$, <br><br>\n",
        "where $\\left\\|\\textbf{u}\\right\\|$ is the length of the vector $\\textbf{u}$<br><br>\n",
        "\n",
        "$\\textbf{cosine_similarity}$ is in the interval $[0, 1]$, <br><br>\n",
        "The larger the $\\textbf{cosine_similarity}$, the more similar the words are, and vice-versa.<br><br>\n",
        "\n",
        "`cosine_similarity` takes as input the document-term matrix <br>\n",
        "and creates a **similarity matrix** in which the rows and columns represent documents <br>\n",
        "and entry ($i, j$) is the cosine similarity between documents $i$ and $j$.<br><br>\n",
        "\n",
        "Let's compute the **similarity matrix** for the BBC tech articles corpus<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-76ce78f9798d38bc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PunUo9xdRAS",
        "outputId": "9901eb80-9d60-438b-c5cb-df502efa354e"
      },
      "source": [
        "%%time\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calculate Distance of TF-IDF Vectors\n",
        "\n",
        "# Turn it into a DataFrame\n",
        "\n",
        "# Our Similarity Matrix is ? size\n",
        "\n",
        "# Each row is the similarity of one document to all other documents (including itself)\n",
        "\n",
        "# Grab the row and pick off the indicies of the most/least similar docs\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "\n",
        "# Calculate Distance of TF-IDF Vectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# similarity matrix\n",
        "dist_matrix  = cosine_similarity(dtm)\n",
        "\n",
        "# Turn it into a DataFrame\n",
        "df = pd.DataFrame(dist_matrix)\n",
        "\n",
        "# Size of the Similarity Matrix\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(401, 401)\n",
            "CPU times: user 43.9 ms, sys: 7.94 ms, total: 51.9 ms\n",
            "Wall time: 35.8 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "IBCTZau_XHmd",
        "outputId": "1a9d7974-a956-4355-e59c-6f40928f7c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  1.000000  0.016067  0.015989  0.025683  0.032193  0.023704  0.033760   \n",
              "1  0.016067  1.000000  0.023260  0.016695  0.039893  0.017457  0.039402   \n",
              "2  0.015989  0.023260  1.000000  0.031790  0.007501  0.018103  0.008338   \n",
              "3  0.025683  0.016695  0.031790  1.000000  0.015908  0.256085  0.032331   \n",
              "4  0.032193  0.039893  0.007501  0.015908  1.000000  0.043868  0.040920   \n",
              "\n",
              "        7         8         9    ...       391       392       393       394  \\\n",
              "0  0.021995  0.026383  0.049187  ...  0.008670  0.009243  0.024090  0.033433   \n",
              "1  0.165408  0.013130  0.051468  ...  0.031619  0.011540  0.058845  0.022672   \n",
              "2  0.014406  0.016178  0.042799  ...  0.123156  0.055875  0.038877  0.045984   \n",
              "3  0.023293  0.135566  0.038473  ...  0.033523  0.007416  0.011638  0.019607   \n",
              "4  0.077494  0.027457  0.041498  ...  0.092405  0.022786  0.034364  0.012604   \n",
              "\n",
              "        395       396       397       398       399       400  \n",
              "0  0.027126  0.015106  0.041041  0.029460  0.024958  0.015939  \n",
              "1  0.009041  0.282936  0.017852  0.034298  0.147939  0.015862  \n",
              "2  0.001263  0.056932  0.022799  0.015254  0.008424  0.007005  \n",
              "3  0.016432  0.020670  0.039178  0.028354  0.031022  0.022114  \n",
              "4  0.039734  0.035444  0.025315  0.034352  0.027414  0.042343  \n",
              "\n",
              "[5 rows x 401 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a8b3c93-8685-411f-83b7-05bfc05c77e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.016067</td>\n",
              "      <td>0.015989</td>\n",
              "      <td>0.025683</td>\n",
              "      <td>0.032193</td>\n",
              "      <td>0.023704</td>\n",
              "      <td>0.033760</td>\n",
              "      <td>0.021995</td>\n",
              "      <td>0.026383</td>\n",
              "      <td>0.049187</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008670</td>\n",
              "      <td>0.009243</td>\n",
              "      <td>0.024090</td>\n",
              "      <td>0.033433</td>\n",
              "      <td>0.027126</td>\n",
              "      <td>0.015106</td>\n",
              "      <td>0.041041</td>\n",
              "      <td>0.029460</td>\n",
              "      <td>0.024958</td>\n",
              "      <td>0.015939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.016067</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.023260</td>\n",
              "      <td>0.016695</td>\n",
              "      <td>0.039893</td>\n",
              "      <td>0.017457</td>\n",
              "      <td>0.039402</td>\n",
              "      <td>0.165408</td>\n",
              "      <td>0.013130</td>\n",
              "      <td>0.051468</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031619</td>\n",
              "      <td>0.011540</td>\n",
              "      <td>0.058845</td>\n",
              "      <td>0.022672</td>\n",
              "      <td>0.009041</td>\n",
              "      <td>0.282936</td>\n",
              "      <td>0.017852</td>\n",
              "      <td>0.034298</td>\n",
              "      <td>0.147939</td>\n",
              "      <td>0.015862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.015989</td>\n",
              "      <td>0.023260</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.031790</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.018103</td>\n",
              "      <td>0.008338</td>\n",
              "      <td>0.014406</td>\n",
              "      <td>0.016178</td>\n",
              "      <td>0.042799</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123156</td>\n",
              "      <td>0.055875</td>\n",
              "      <td>0.038877</td>\n",
              "      <td>0.045984</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.056932</td>\n",
              "      <td>0.022799</td>\n",
              "      <td>0.015254</td>\n",
              "      <td>0.008424</td>\n",
              "      <td>0.007005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.025683</td>\n",
              "      <td>0.016695</td>\n",
              "      <td>0.031790</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015908</td>\n",
              "      <td>0.256085</td>\n",
              "      <td>0.032331</td>\n",
              "      <td>0.023293</td>\n",
              "      <td>0.135566</td>\n",
              "      <td>0.038473</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033523</td>\n",
              "      <td>0.007416</td>\n",
              "      <td>0.011638</td>\n",
              "      <td>0.019607</td>\n",
              "      <td>0.016432</td>\n",
              "      <td>0.020670</td>\n",
              "      <td>0.039178</td>\n",
              "      <td>0.028354</td>\n",
              "      <td>0.031022</td>\n",
              "      <td>0.022114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.032193</td>\n",
              "      <td>0.039893</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.015908</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043868</td>\n",
              "      <td>0.040920</td>\n",
              "      <td>0.077494</td>\n",
              "      <td>0.027457</td>\n",
              "      <td>0.041498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.092405</td>\n",
              "      <td>0.022786</td>\n",
              "      <td>0.034364</td>\n",
              "      <td>0.012604</td>\n",
              "      <td>0.039734</td>\n",
              "      <td>0.035444</td>\n",
              "      <td>0.025315</td>\n",
              "      <td>0.034352</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.042343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 401 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a8b3c93-8685-411f-83b7-05bfc05c77e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a8b3c93-8685-411f-83b7-05bfc05c77e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a8b3c93-8685-411f-83b7-05bfc05c77e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDtkkqU8Qx25",
        "outputId": "1c3a398a-3783-42ec-81b9-11b0a6a9b1fc"
      },
      "source": [
        "# Each row is the similarity of one document to all other documents (including itself)\n",
        "df.iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1.000000\n",
              "1      0.016067\n",
              "2      0.015989\n",
              "3      0.025683\n",
              "4      0.032193\n",
              "         ...   \n",
              "396    0.015106\n",
              "397    0.041041\n",
              "398    0.029460\n",
              "399    0.024958\n",
              "400    0.015939\n",
              "Name: 0, Length: 401, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFV_5FzLijNo"
      },
      "source": [
        "### Find the most similar documents to the first document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW0zaZkFQtgS",
        "outputId": "7294cd73-0f8e-4c63-d845-c959fd33be28"
      },
      "source": [
        "# Grab the first row and return the indices of the 10 most similar docs\n",
        "print(df[0].sort_values(ascending=False)[:10])\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      1.000000\n",
            "321    0.186694\n",
            "368    0.159529\n",
            "21     0.157939\n",
            "259    0.155921\n",
            "180    0.140828\n",
            "165    0.140828\n",
            "99     0.136790\n",
            "161    0.126301\n",
            "200    0.119302\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msStkSPqdRAS"
      },
      "source": [
        "### 2.2 K Nearest Neighbors Search (kNN)\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/753/0*jqxx3-dJqFjXD6FA\" width=\"600\" height=\"400\" />\n",
        "\n",
        "\n",
        "Nearest Neighbor models are distance based algorithms. They store your training set in memory.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD4Oru_DlAhu"
      },
      "source": [
        "### `scikit-learn`'s `NearestNeighbors` class\n",
        "computes distances between all pairs of data points, <br>\n",
        "and returns the result in the form of a similarity matrix. <br>\n",
        "Entry $(i,j)$ in the similarity matrix records the similarity of data points $i$ and $j$.<br>\n",
        "\n",
        "Below is an example using `NearestNeighbors` to find the most similar documents to a given documentL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eac83ba5d76f6bf2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaF7cC7jdRAS",
        "outputId": "d9f59923-02c6-4f03-f5d5-126004c4c875"
      },
      "source": [
        "%%time\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Instantiate the nearest neighbors model\n",
        "nn = NearestNeighbors()\n",
        "\n",
        "# fit to our document term matrix (dtm is a dataframe in this case)\n",
        "nn.fit(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 39.9 ms, sys: 945 µs, total: 40.9 ms\n",
            "Wall time: 74.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPbW_1sum9NP"
      },
      "source": [
        "Find the 5 most similar documents to a query document; here we will choose the first document as our query document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krvdbifUpi4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a327d43c-c1ad-41f6-bbbd-3a2bf5b2500c"
      },
      "source": [
        "# sample a doc from a dtm to use as our query point\n",
        "doc_index = 0\n",
        "query_doc = dtm.values[0]\n",
        "\n",
        "# Query Using the kneighbors method\n",
        "# NOTE: nn counts the original document as one of the neighbors, so if we want 5 nearest neighbors, we should set n_neightbors=6\n",
        "neigh_dist, neigh_index = nn.kneighbors([query_doc], n_neighbors=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SUrN_YrvPsK",
        "outputId": "b196ec8b-99f8-449e-a0d7-e239e26ef01c"
      },
      "source": [
        "# nearest neighbor search returns the same documents as cosine similarity!\n",
        "print(neigh_index)\n",
        "print(neigh_dist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0 321 368  21 259 165]]\n",
            "[[0.         1.27538699 1.29651156 1.29773696 1.29929143 1.31085658]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "6whC43iwp2LC",
        "outputId": "054eb596-52c5-49d5-ad34-ae474de8159d"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Gritty return for Prince of Persia\\n\\nStill basking in the relatively recent glory of last year's Sands Of Time, the dashing Prince of Persia is back in Warrior Within, and in a more bellicose mood than last time.\\n\\nThis sequel gives the franchise a grim, gritty new look and ramps up the action and violence. As before, you control the super-athletic prince from a third-person perspective. The time-travelling plot hinges on the Dahaka, an all-consuming monster pursuing our hero through the ages. The only way to dispel it is to turn back the clock again and kill the sultry Empress Of Time before she ever creates the Sands of Time that caused the great beast's creation.\\n\\nStudiously structured though this back story is, everything boils down to old-fashioned fantasy gameplay which proves, on the whole, as dependable as it needs to be. Ever since the series' then-groundbreaking beginnings on the Commodore Amiga, Prince of Persia has always been about meticulously-animated acrobatic moves, that provide an energetic blend of leaping preposterously between pieces of scenery and lopping off enemies' body parts.\\n\\nThose flashy moves are back in full evidence, and tremendous fun to perform and perfect. Combining them at speed is the best fun, although getting a handle of doing so takes practice and plenty of skill. Until you reach that point, it is a haphazard business. All too often, you will perform a stunning triple somersault, pirouette off a wall, knock out three enemies in one glorious swoop, before plummeting purposefully over a cliff to your doom. That in turn can mean getting set back an annoyingly long distance, for you can only save at the fountains dotted along the path. The expected fiendish puzzles are all present and correct, but combat is what is really been stepped up, and there is more of it than before. The game's developers have combined acrobatic flair with gruesome slaying techniques in some wonderfully imaginative ways. Slicing foes down the middle is one particularly entertaining method of seeing them off.\\n\\nWarrior Within is a very slick package; the game's intro movie is so phenomenally good that it actually does an ultimate disservice once the game itself commences.\\n\\nIt is on a par with the jaw-dropping opening sequence of Onimusha 3 earlier this year, and when the game begins, it is something of an anti-climax. That said, the graphics are excellent, and indeed among the most striking and satisfying elements of the game. The music is probably the worst aspect - a merit-free heavy metal soundtrack that you will swiftly want to turn off. There is something strangely unsatisfying about the game. Perhaps precisely because its graphics and mechanics are so good that the story and overall experience are not quite as engaging as they should be. Somehow it adds up to less than the sum of its parts, and is more technically impressive than it is outright enjoyable. But that is not to say Warrior Within is anything other than a superb adventure that most will thoroughly enjoy. It just does not quite take the character to the new heights that might have been hoped for.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "PDM_NrH7IBr8",
        "outputId": "e6624d7f-3872-4b9b-b825-ed686dda8646"
      },
      "source": [
        "data[321]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Bond game fails to shake or stir\\n\\nFor gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\\n\\nAdopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\\n\\nRogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\\n\\nRecent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\\n\\nBy far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\\n\\nThere is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\\n\\nGoldenEye: Rogue Agent is out now\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which words do these two documents have in common?"
      ],
      "metadata": {
        "id": "GJvImw9sYxQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shared_words(s1, s2):\n",
        "  res = []\n",
        "  l_s1, l_s2 = set(s1.split()), set(s2.split())\n",
        "  for ss1 in l_s1:\n",
        "    if ss1 in l_s2: res.append(ss1)\n",
        "  return res\n",
        "\n",
        "doc1_tokens = tokenize(data[0])\n",
        "doc2_tokens = tokenize(data[321])\n",
        "shared_words(' '.join(doc1_tokens), ' '.join(doc2_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlxQ968QYtrm",
        "outputId": "59c8fbe2-7a68-4c2e-efff-cad8a01b3447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mean',\n",
              " 'plummet',\n",
              " 'sequel',\n",
              " 'distance',\n",
              " 'character',\n",
              " 'franchise',\n",
              " 'see',\n",
              " 'element',\n",
              " 'year',\n",
              " 'enemy',\n",
              " 'good',\n",
              " 'add',\n",
              " 'hope',\n",
              " 'fashion',\n",
              " 'kill',\n",
              " 'blend',\n",
              " 'combine',\n",
              " 'time',\n",
              " 'satisfy',\n",
              " 'give',\n",
              " 'beast',\n",
              " 'game',\n",
              " 'dot',\n",
              " 'dash',\n",
              " 'return',\n",
              " 'need',\n",
              " 'save',\n",
              " 'fun',\n",
              " 'probably',\n",
              " 'point',\n",
              " 'recent',\n",
              " 'gameplay',\n",
              " 'old',\n",
              " 'flair',\n",
              " 'story',\n",
              " 'action',\n",
              " 'new']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhG-KESidGIn"
      },
      "source": [
        "### Exercise:\n",
        "Search the BBC dataset for documents most similar to a random query doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouWYmCawdRAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d586e4a6-08b7-4a30-914f-7ce0c4362731"
      },
      "source": [
        "rndm_tech_article = [ \"\"\"\n",
        "Blockchain technology encompasses so much more than just cryptocurrencies these days. And while these currencies are by far blockchain’s most famous use case, the potential for blockchain far, far exceeds a straightforward transfer of value.\n",
        "The gaming industry, for example, has always been fairly controversial due to a range of issues. Many players feel particularly worried about the protection of their data, fraudulent activities, high fees, and most of all, unfair and hidden odds.\n",
        "In these cases, P2P doesn’t just mean peer-to-peer; it means player-to-player. As with the other P2P industries that blockchain is disrupting, such as FinTech, there are already plenty of ways in which blockchain technology is being applied to resolve these issues and many more of the challenges faced by the gaming industry. Here are just a few.\n",
        "Reducing fraud.\n",
        "\n",
        "The gaming industry suffers a lot from online fraud. One of the main advantages of blockchain technology is that it enables highly secure data encryption. What’s more, all of it is entirely accessible and transparent to the player. In other words, blockchain is a for game changer for venues such as online casinos, lotteries, and virtually anything which relies on random number generation.\n",
        "On top of this, hackers will have particularly hard time, if it is even possible, to destroy a decentralized blockchain network, making sure gamer data stays safe. This is an inherent feature of distributed ledger technology whereby nodes in the ledger maintain the distributed databases in a shared manner, and each node has the complete information in the entire database.\n",
        "\"\"\"]\n",
        "\n",
        "\n",
        "# transform the rndm_tech_article to get its document vector\n",
        "doc_tfidf = tfidf.transform(rndm_tech_article)\n",
        "doc_tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x3414 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 61 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use k Nearest Neighbors to find the most similar documents in our document term matrix to the query\n",
        "neigh_dist, neigh_index = nn.kneighbors(doc_tfidf.todense(), n_neighbors=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhimOi_-aGzh",
        "outputId": "45c05f28-a261-4896-ade3-af94befccfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neigh_dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFtq_ax5aHZI",
        "outputId": "e1064ee9-b079-4266-d79f-54e320adf9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.29226145, 1.29239791, 1.30792013, 1.31386713, 1.31544344,\n",
              "        1.31607063]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neigh_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqzlKVZEaTQw",
        "outputId": "70302486-ad63-436d-98f4-c58fa83fb583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[267,   9, 305,  34, 258, 279]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[267]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "poDvsBX2akjy",
        "outputId": "10d6e44c-9f44-4db5-cefe-1c489c706aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Peer-to-peer nets \\'here to stay\\'\\n\\nPeer-to-peer (P2P) networks are here to stay, and are on the verge of being exploited by commercial media firms, says a panel of industry experts.\\n\\nOnce several high-profile legal cases against file-sharers are resolved this year, firms will be very keen to try and make money from P2P technology. The expert panel probed the future of P2P at the Consumer Electronics Show in Las Vegas earlier in January. The first convictions for P2P piracy were handed out in the US in January. William Trowbridge and Michael Chicoine pleaded guilty to charges that they infringed copyright by illegally sharing music, movies and software. Since the first successful file-sharing network Napster was forced to close down, the entertainment industry has been nervous and critical of P2P technology, blaming it for falling sales and piracy. But that is going to change very soon, according to the panel.\\n\\nThe music and film industries have started some big legal cases against owners of legitimate P2P networks - which are not illegal in themselves - and of individuals accused of distributing pirated content over networks. But they have slowly realised that P2P is a good way to distribute content, said Travis Kalanick, founder and chairman of P2P network Red Swoosh, and soon they are all going to want a slice of it. They are just waiting to come up with \"business models\" that work for them, which includes digital rights management and copy-protection standards.\\n\\nBut, until the legal actions are resolved, experimentation with P2P cannot not happen, said Michael Weiss, president of StreamCast Networks. Remembering the furore around VCRs when they first came out, Mr Weiss said: \"Old media always tries to stop new media. \"When they can\\'t stop it, they try to control it. Then they figure out how to make money and they always make a lot of money.\" Once the courts decided that the VCR in itself was not an illegal technology, the film studios turned it into an extremely lucrative business. In August 2004, the San Francisco-based US Court of Appeals ruled in favour of Grokster and StreamCast, two file-sharing networks. The court said they were essentially in the same position that Sony was in the 1980s VCR battle, and said that the networks themselves could not be deemed as illegal.\\n\\nP2P networks usually do not rely on dedicated servers for the transfer of files. Instead it uses direct connections between computers - or clients. There are now many different types of P2P systems than work in different ways. P2P nets can be used to share any kind of file, like photos, free software, licensed music and any other digital content. The BBC has already decided to embrace the technology. It aims to offer most of its own programmes for download this year and it will use P2P technology to distribute them. The files would be locked seven days after a programme aired making rights management easier to control. But the technology is still demonised and misunderstood by many. The global entertainment industry says more than 2.6 billion copyrighted music files are downloaded every month, and about half a million films are downloaded a day. Legal music download services, like Apple iTunes, Napster, have rushed into the music marketplace to try and lure file-sharers away from free content. Sales of legally-downloaded songs grew tenfold in 2004, with 200 million tracks bought online in the US and Europe in 12 months, the IFPI reported this week. But such download services are very different from P2P networks, not least because of the financial aspect.\\n\\nThere are several money-spinning models that could turn P2P into a golden egg for commercial entertainment companies. Paid-for-pass-along, in which firms receive money each time a file is shared, along with various DRM solutions and advertiser-based options are all being considered. \"We see there are going to be different models for commoditising P2P,\" said Marc Morgenstern, vice president of anti-piracy firm Overpeer.\\n\\n\"Consumers are hungry for it and we will discover new models together,\" agreed Mr Morgenstern. But many net users will continue to ignore the entertainment industry\\'s potential controlling grip on content and P2P technology by continuing to use it for their own creations. Unsigned bands, for example, use P2P networks to distribute their music effectively, which also draws the attention of record companies looking for new artists to sign. \"Increasingly, what you are seeing on P2P is consumer-created content,\" said Derek Broes, from Microsoft. \"They will probably play an increasing role in helping P2P spread,\" he said. Looking into P2P\\'s future, file sharing is just the beginning for P2P networks, as far as Mr Broes is concerned. \"Once some of these issues are resolved, you are going to see aggressive movement to protect content, but also in ways that are unimaginable now,\" he said. \"File-sharing is the tip of the iceberg.\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1_tokens = tokenize(rndm_tech_article[0])\n",
        "doc2_tokens = tokenize(data[267])\n",
        "shared_words(' '.join(doc1_tokens), ' '.join(doc2_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahhuYL0GaXK9",
        "outputId": "0b21a84c-83c1-4569-a024-ab16d1b7c01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lot',\n",
              " 'stay',\n",
              " 'p2p',\n",
              " 'online',\n",
              " 'potential',\n",
              " 'share',\n",
              " 'example',\n",
              " 'technology',\n",
              " 'rely',\n",
              " 'issue',\n",
              " 'network',\n",
              " 'protection',\n",
              " 'industry',\n",
              " 'far',\n",
              " 'high',\n",
              " 'distribute',\n",
              " 'time',\n",
              " 'day',\n",
              " 'resolve',\n",
              " 'transfer',\n",
              " 'use',\n",
              " 'case',\n",
              " 'make',\n",
              " 'way',\n",
              " 'peer']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaSuFg0ldRAT"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "In the module project assignment, you will apply one of these search techniques to retrieve documents related to a query document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ugKeF8odRAT"
      },
      "source": [
        "# 3. Apply word embedding models to create document vectors (Learn)\n",
        "<a id=\"p3\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5wmBPMUdRAU"
      },
      "source": [
        "## Overview\n",
        "### Bag of Words (BoW) models lose information about context\n",
        "\n",
        "One of the limitations of Bag-of-Words approaches is that any information about the context surrounding that word is lost. This also means that with bag-of-words approaches often the only tools that we have for identifying words with similar usage or meaning and subsequently consolidating them into a single vector is through the processes of stemming and lemmatization which tend to be quite limited at consolidating words unless the two words are very close in their spelling or in their root parts-of-speech.\n",
        "\n",
        "### Embedding approaches preserve more textual context\n",
        "Word2Vec is an increasingly popular word embedding technique. Like Bag-of-words it learns a real-value vector representation for a predefined fixed-size vocabulary that is generated from a corpus of text. However, in contrast to BoW, Word2Vec approaches are much more capable of accounting for textual context, and are better at discovering words with similar meanings or usages (semantic or syntactic similarity).\n",
        "\n",
        "##3.1 Word2Vec Intuition\n",
        "Reference: [Deep NLP: Word Vectors with Word2Vec](https://medium.com/deep-learning-demystified/deep-nlp-word-vectors-with-word2vec-d62cb29b40b3)\n",
        "### The Distribution Hypothesis\n",
        "\n",
        "In order to understand how Word2Vec preserves textual context we have to understand what's called the [Distribution Hypothesis](https://en.wikipedia.org/wiki/Distributional_semantics). The Distribution Hypothesis operates under the assumption that words that have similar contexts will have similar meanings. Practically speaking, this means that if two words are found to have similar words both to the right and to the left of them throughout the corpora then those words have the same context and are assumed to have the same meaning.\n",
        "\n",
        "> \"You shall know a word by the company it keeps\" - John Firth\n",
        "\n",
        "This means that we let the usage of a word define its meaning and its \"similarity\" to other words. In the following example, which words would you say have a similar meaning?\n",
        "\n",
        "**Sentence 1**: Traffic was light today\n",
        "\n",
        "**Sentence 2**: Traffic was heavy yesterday\n",
        "\n",
        "**Sentence 3**: Prediction is that traffic will be smooth-flowing tomorrow since it is a national holiday\n",
        "\n",
        "What words in the above sentences seem to have a similar meaning if all you knew about them was the context in which they appeared above?\n",
        "\n",
        "Lets take a look at how this might work in action, the following example is simplified, but will give you an idea of the intuition for how this works.\n",
        "\n",
        "#### Corpora:\n",
        "\n",
        "1) \"It was the sunniest of days.\"\n",
        "\n",
        "2) \"It was the rainiest of days.\"\n",
        "\n",
        "#### Vocabulary:\n",
        "\n",
        "{\"it\": 1, \"was\": 2, \"the\": 3, \"of\": 4, \"days\": 5, \"sunniest\": 6, \"rainiest\": 7}\n",
        "\n",
        "### Vectorization\n",
        "\n",
        "|       doc   | START_was | it_the | was_sunniest | the_of | sunniest_days | of_it | days_was | it_the | was_rainiest | rainiest_days | of_END |\n",
        "|----------|-----------|--------|--------------|--------|---------------|-------|----------|--------|-------------|--------------|--------|\n",
        "| it       | 1         | 0      | 0            | 0      | 0             | 0     | 1        | 0      | 0           | 0            | 0      |\n",
        "| was      | 0         | 1      | 0            | 0      | 0             | 0     | 0        | 1      | 0           | 0            | 0      |\n",
        "| the      | 0         | 0      | 1            | 0      | 0             | 0     | 0        | 0      | 1           | 0            | 0      |\n",
        "| sunniest | 0         | 0      | 0            | 1      | 0             | 0     | 0        | 0      | 0           | 0            | 0      |\n",
        "| of       | 0         | 0      | 0            | 0      | 1             | 0     | 0        | 0      | 0           | 1            | 0      |\n",
        "| days     | 0         | 0      | 0            | 0      | 0             | 0     | 0        | 0      | 0           | 0            | 1      |\n",
        "| rainiest  | 0         | 0      | 0            | 1      | 0             | 0     | 0        | 0      | 0           | 0            | 0      |\n",
        "\n",
        "Each column vector represents the word's context -in this case defined by the words to the left and right of the center word. How far we look to the left and right of a given word is referred to as our \"window of context.\" Each row vector represents the the different usages of a given word. Word2Vec can consider a larger context than only words that are immediately to the left and right of a given word, but we're going to keep our window of context small for this example. What's most important is that this vectorization has translated our documents from a text representation to a numeric one in a way that preserves information about the underlying context.\n",
        "\n",
        "We can see that words that have a similar context will have similar row-vector representations, but before looking that more in-depth, lets simplify our vectorization slightly. You'll notice that we're repeating the column-vector \"it_the\" twice. Lets combine those into a single vector by adding them element-wise.\n",
        "\n",
        "|       *   | START_was | it_the | was_sunniest | the_of | sunniest_days | of_it | days_was | was_rainiest | rainiest_days | of_END |\n",
        "|----------|-----------|--------|--------------|--------|---------------|-------|----------|-------------|--------------|--------|\n",
        "| it       | 1         | 0      | 0            | 0      | 0             | 0     | 1        | 0           | 0            | 0      |\n",
        "| was      | 0         | 2      | 0            | 0      | 0             | 0     | 0        | 0           | 0            | 0      |\n",
        "| the      | 0         | 0      | 1            | 0      | 0             | 0     | 0        | 1           | 0            | 0      |\n",
        "| sunniest | 0         | 0      | 0            | 1      | 0             | 0     | 0        | 0           | 0            | 0      |\n",
        "| of       | 0         | 0      | 0            | 0      | 1             | 0     | 0        | 0           | 1            | 0      |\n",
        "| days     | 0         | 0      | 0            | 0      | 0             | 0     | 0        | 0           | 0            | 1      |\n",
        "| rainiest  | 0         | 0      | 0            | 1      | 0             | 0     | 0        | 0           | 0            | 0      |\n",
        "\n",
        "Now, can you spot which words have a similar row-vector representation? Hint: Look for values that are repeated in a given column. Each column represents the context that word was found in. If there are multiple words that share a context then those words are understood to have a closer meaning with each other than with other words in the text.\n",
        "\n",
        "Lets look specifically at the words sunniest and rainiest. You'll notice that these two words have exactly the same 10-dimensional vector representation. Based on this very small corpora of text we would conclude that these two words have relatd meanings because they share the same usage. Is this a good assumption? Well, they are both referring to the weather outside so that's better than nothing. You could imagine that as our corpora grows larger we will be exposed a greater number of contexts and the Distribution Hypothesis assumption will improve.\n",
        "\n",
        "##3.2 Word2Vec Variants\n",
        "\n",
        "###3.2.1 Skip-Gram\n",
        "\n",
        "The Skip-Gram method predicts the neighbors’ of a word given a center word. In the skip-gram model, we take a center word and a window of context (neighbors) words to train the model and then predict context words out to some window size for each center word.\n",
        "\n",
        "This notion of “context” or “neighboring” words is best described by considering a center word and a window of words around it.\n",
        "\n",
        "For example, if we consider the sentence **“The speedy Porsche drove past the elegant Rolls-Royce”** and a window size of 2, we’d have the following pairs for the skip-gram model:\n",
        "\n",
        "**Text:**\n",
        "**The**\tspeedy\tPorsche\tdrove\tpast\tthe\telegant\tRolls-Royce\n",
        "\n",
        "*Training Sample with window of 2*: (the, speedy), (the, Porsche)\n",
        "\n",
        "**Text:**\n",
        "The\t**speedy**\tPorsche\tdrove\tpast\tthe\telegant\tRolls-Royce\n",
        "\n",
        "*Training Sample with window of 2*: (speedy, the), (speedy, Porsche), (speedy, drove)\n",
        "\n",
        "**Text:**\n",
        "The\tspeedy\t**Porsche**\tdrove\tpast\tthe\telegant\tRolls-Royce\n",
        "\n",
        "*Training Sample with window of 2*: (Porsche, the), (Porsche, speedy), (Porsche, drove), (Porsche, past)\n",
        "\n",
        "**Text:**\n",
        "The\tspeedy\tPorsche\t**drove**\tpast\tthe\telegant\tRolls-Royce\n",
        "\n",
        "*Training Sample with window of 2*: (drove, speedy), (drove, Porsche), (drove, past), (drove, the)\n",
        "\n",
        "The **Skip-gram model** is going to output a probability distribution i.e. the probability of a word appearing in context given a center word and we are going to select the vector representation that maximizes the probability.\n",
        "\n",
        "With CountVectorizer and TF-IDF the best we could do for context was to look at common bi-grams and tri-grams (n-grams). Well, skip-grams go far beyond that and give our model much stronger contextual information.\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/c7mwy6dk9k99bgh/Image%202%20-%20SkipGrams.jpg?raw=1)\n",
        "\n",
        "###3.2.2 Continuous Bag of Words\n",
        "\n",
        "This model takes thes opposite approach from the skip-gram model in that it tries to predict a center word based on the neighboring words. In the case of the CBOW model, we input the context words within the window (such as “the”, “Porsche”, “drove”) and aim to predict the target or center word “speedy” (the input to the prediction pipeline is reversed as compared to the SkipGram model).\n",
        "\n",
        "A graphical depiction of the input to output prediction pipeline for both variants of the Word2vec model is attached. The graphical depiction will help crystallize the difference between SkipGrams and Continuous Bag of Words.\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/k3ddmbtd52wq2li/Image%203%20-%20CBOW%20Model.jpg?raw=1)\n",
        "\n",
        "###3.2.3 Notes on Word Embeddings:\n",
        "\n",
        "1) Word2Vec is useful for topic-modeling, because each word vector contains information about related context words.\n",
        "\n",
        "2) Word2Vec can result in really large and complex vectorizations. In fact, you need Deep Neural Networks to train your Word2Vec models from scratch, but we can use helpful pretrained embeddings to do really cool things!\n",
        "Let's take a look at how to work with these word vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbCusle-77J4"
      },
      "source": [
        "## 3.3 Spacy word embeddings\n",
        "#### `spacy` provides pretrained Word2Vec models.\n",
        "\n",
        "We will use their `en_core_web_md` model, which has 300-dimensional word embeddings for 20,000 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-08acf3f0c46d7591",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfaoM_g7dRAU",
        "outputId": "83bd6870-537b-48c9-d670-e39d986dd200"
      },
      "source": [
        "# Process a text\n",
        "#nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "doc = nlp(\"bananas\")\n",
        "\n",
        "# Get the vector for the token \"bananas\"\n",
        "bananas_vector = doc.vector\n",
        "\n",
        "# 300-dim vector\n",
        "print(len(bananas_vector))\n",
        "print(bananas_vector)\n",
        "\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "[-2.2009e-01 -3.0322e-02 -7.9859e-02 -4.6279e-01 -3.8600e-01  3.6962e-01\n",
            " -7.7178e-01 -1.1529e-01  3.3601e-02  5.6573e-01 -2.4001e-01  4.1833e-01\n",
            "  1.5049e-01  3.5621e-01 -2.1508e-01 -4.2743e-01  8.1400e-02  3.3916e-01\n",
            "  2.1637e-01  1.4792e-01  4.5811e-01  2.0966e-01 -3.5706e-01  2.3800e-01\n",
            "  2.7971e-02 -8.4538e-01  4.1917e-01 -3.9181e-01  4.0434e-04 -1.0662e+00\n",
            "  1.4591e-01  1.4643e-03  5.1277e-01  2.6072e-01  8.3785e-02  3.0340e-01\n",
            "  1.8579e-01  5.9999e-02 -4.0270e-01  5.0888e-01 -1.1358e-01 -2.8854e-01\n",
            " -2.7068e-01  1.1017e-02 -2.2217e-01  6.9076e-01  3.6459e-02  3.0394e-01\n",
            "  5.6989e-02  2.2733e-01 -9.9473e-02  1.5165e-01  1.3540e-01 -2.4965e-01\n",
            "  9.8078e-01 -8.0492e-01  1.9326e-01  3.1128e-01  5.5390e-02 -4.2423e-01\n",
            " -1.4082e-02  1.2708e-01  1.8868e-01  5.9777e-02 -2.2215e-01 -8.3950e-01\n",
            "  9.1987e-02  1.0180e-01 -3.1299e-01  5.5083e-01 -3.0717e-01  4.4201e-01\n",
            "  1.2666e-01  3.7643e-01  3.2333e-01  9.5673e-02  2.5083e-01 -6.4049e-02\n",
            "  4.2143e-01 -1.9375e-01  3.8026e-01  7.0883e-03 -2.0371e-01  1.5402e-01\n",
            " -3.7877e-03 -2.9396e-01  9.6518e-01  2.0068e-01 -5.6572e-01 -2.2581e-01\n",
            "  3.2251e-01 -3.4634e-01  2.7064e-01 -2.0687e-01 -4.7229e-01  3.1704e-01\n",
            " -3.4665e-01 -2.5188e-01 -1.1201e-01 -3.3937e-01  3.1518e-01 -3.2221e-01\n",
            " -2.4530e-01 -7.1571e-02 -4.3971e-01 -1.2070e+00  3.3365e-01 -5.8208e-02\n",
            "  8.0899e-01  4.2335e-01  3.8678e-01 -6.0797e-01 -7.3760e-01 -2.0547e-01\n",
            " -1.7499e-01 -3.7842e-03  2.1930e-01 -5.2486e-02  3.4869e-01  4.3852e-01\n",
            " -3.4471e-01  2.8910e-01  7.2554e-02 -4.8625e-01 -3.8390e-01 -4.4760e-01\n",
            "  4.3278e-01 -2.7128e-03 -9.0067e-01 -3.0819e-02 -3.8630e-01 -8.0798e-02\n",
            " -1.6243e-01  2.8830e-01 -2.6349e-01  1.7628e-01  3.5958e-01  5.7672e-01\n",
            " -5.4624e-01  3.8555e-02 -2.0182e+00  3.2916e-01  3.4672e-01  1.5398e-01\n",
            " -4.3446e-01 -4.1428e-02 -6.9588e-02  5.1513e-01 -1.3489e-01 -5.7239e-02\n",
            "  4.9241e-01  1.8643e-01  3.8596e-01 -3.7329e-02 -5.4216e-01 -1.8152e-01\n",
            "  4.3110e-01 -4.6967e-01  6.6801e-02  5.0323e-01 -2.4059e-01  3.6742e-01\n",
            "  2.9300e-01 -8.7883e-02 -4.7940e-01 -4.3431e-02 -2.6137e-01 -6.2658e-01\n",
            "  1.1446e-01  2.7682e-01  3.4800e-01  5.0018e-01  1.4269e-01 -3.3545e-01\n",
            " -3.9712e-01 -3.3121e-01 -3.4434e-01 -4.1627e-01 -3.5707e-03 -6.2350e-01\n",
            "  3.7794e-01 -1.6765e-01 -4.1954e-01 -3.3134e-01  3.1232e-01 -3.9494e-01\n",
            " -4.6921e-03 -4.8884e-01 -2.2059e-02 -2.6174e-01  1.7937e-01  3.6628e-01\n",
            "  5.8971e-02 -3.5991e-01 -4.4393e-01 -1.1890e-01  3.3487e-01  3.6505e-02\n",
            " -3.2788e-01  3.3425e-01 -5.6361e-01 -1.1190e-01  5.3770e-01  2.0311e-01\n",
            "  1.5110e-01  1.0623e-02  3.3401e-01  4.6084e-01  5.6293e-01 -7.5432e-02\n",
            "  5.4813e-01  1.9395e-01 -2.6265e-01 -3.1699e-01 -8.1778e-01  5.8169e-02\n",
            " -5.7866e-02 -1.1781e-01 -5.8742e-02 -1.4092e-01 -9.9394e-01 -9.4532e-02\n",
            "  2.3503e-01 -4.9027e-01  8.5832e-01  1.1540e-01 -1.5049e-01  1.9065e-01\n",
            " -2.6705e-01  2.5326e-01 -6.7579e-01 -1.0633e-02 -5.5158e-02 -3.1004e-01\n",
            " -5.8036e-02 -1.7200e-01  1.3298e-01 -3.2899e-01 -7.5481e-02  2.9425e-02\n",
            " -3.2949e-01 -1.8691e-01 -9.5323e-01 -3.5468e-01 -3.3162e-01  5.6441e-02\n",
            "  2.1790e-02  1.7182e-01 -4.4267e-01  6.9765e-01 -2.6876e-01  1.1659e-01\n",
            " -1.6584e-01  3.8296e-01  2.9109e-01  3.6318e-01  3.6961e-01  1.6305e-01\n",
            "  1.8152e-01  2.2453e-01  3.9866e-02 -3.7607e-02 -3.6089e-01  7.0818e-02\n",
            " -2.1509e-01  3.6551e-01 -5.1603e-01 -5.8102e-03 -4.8320e-01 -2.5068e-01\n",
            " -5.2062e-02 -2.0828e-01  2.9060e-01  2.2084e-02 -6.8123e-01  4.2063e-01\n",
            "  9.5973e-02  8.1720e-01 -1.5241e-01  6.2994e-01  2.6449e-01 -1.3516e-01\n",
            "  3.2450e-01  3.0503e-01  1.2357e-01  1.5107e-01  2.8327e-01 -3.3838e-01\n",
            "  4.6106e-02 -1.2361e-01  1.4516e-01 -2.7947e-02  2.6231e-02 -5.9591e-01\n",
            " -4.4183e-01  7.8440e-01 -3.4375e-02 -1.3928e+00  3.5248e-01  6.5220e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apple = nlp('apple')\n",
        "banana = nlp('banana')\n",
        "gravity = nlp('gravity')\n",
        "\n",
        "print(f'Apple -> Banana similarity: {apple.similarity(banana)}')\n",
        "print(f'Apple -> Gravity similarity: {apple.similarity(gravity)}')\n",
        "print(f'Banana -> Gravity similarity: {banana.similarity(gravity)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXD2u3DKa3ZH",
        "outputId": "ecf204fa-c237-4470-923b-2695b034d300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple -> Banana similarity: 0.5831844567891399\n",
            "Apple -> Gravity similarity: 0.1461313454554943\n",
            "Banana -> Gravity similarity: 0.11432135235050715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD1qE_vCHWuG"
      },
      "source": [
        "### Spacy Document vectors\n",
        "\n",
        "From spacy we can get word2vec embeddings for each word in a document<br>\n",
        "We can create a document vector by averaging all the word vectors in that doc<br>\n",
        "We can calculate the similarity between documents now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vkq3tlyL2Xp"
      },
      "source": [
        "doc1 = nlp(\"On a hot summer day, it's good to drink water.\")\n",
        "doc2 = nlp(\"There are lots of cold drinks in the refrigerator.\")\n",
        "doc3 = nlp(\"cosine distance measures similarity\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM5RbtPfL38t",
        "outputId": "233f99fc-bebf-4a42-8ac4-ac805368a611"
      },
      "source": [
        "len(doc1.vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz5eGGl5MKxx",
        "outputId": "da507966-9270-4931-c387-0e210aa122f0"
      },
      "source": [
        "type(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4a00f1280d6a3a32",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXNDY_VadRAV",
        "outputId": "5c7787d6-23e6-4ee1-b4dc-86f0f70b71b6"
      },
      "source": [
        "\n",
        "### BEGIN SOLUTION\n",
        "# Get the similarity of doc1 and doc2\n",
        "similarity = doc1.similarity(doc2)\n",
        "print(similarity)\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8838439897643992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plyigAgONqJ5",
        "outputId": "6521e739-0f85-4011-912c-df9fc91d29f0"
      },
      "source": [
        "doc3.similarity(doc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3532817580631088"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbXwpFEvcdQG",
        "outputId": "abf82740-d4a9-42bc-93f8-44e504c4486b"
      },
      "source": [
        "doc3.similarity(doc1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3225841257225828"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBwRFUIhzH79"
      },
      "source": [
        "## Challenge: can we make a \"thesaurus\"?<br>\n",
        "Given a query word, do you think we could find good synonyms  <br>\n",
        "by doing a nearest neighbor search on the `spacy` word embeddings?<br>\n",
        "Let's give it a try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93PNwg0ODA5k"
      },
      "source": [
        "First, get the embeddings for the vocabulary words and make a document-term matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKtrMIBTe4Ja",
        "outputId": "e196c08e-8243-4556-9560-5fde45e3c308"
      },
      "source": [
        "%%time\n",
        "vocab = list(nlp.vocab.strings)\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1493734\n",
            "CPU times: user 1.69 s, sys: 64.1 ms, total: 1.76 s\n",
            "Wall time: 1.76 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhvStTRcYt70",
        "outputId": "4012fef6-e03c-4d79-9830-9823f3f723ab"
      },
      "source": [
        "# eliminate duplicates due to mixing upper and lower case\n",
        "vocab =[word.lower() for word in vocab]\n",
        "vocab = list(set(lower_vocab))\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "770783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYsIXtUlZobh",
        "outputId": "15a9c76d-6ea0-4392-ccdb-53d40dfc60e0"
      },
      "source": [
        "%%time\n",
        "word_vectors = [nlp.vocab.get_vector(word) for word in vocab]\n",
        "word_vectors = np.asarray(word_vectors)\n",
        "print(word_vectors.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(770783, 300)\n",
            "CPU times: user 14.9 s, sys: 54.4 ms, total: 15 s\n",
            "Wall time: 14.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJuBDt0PEh3G"
      },
      "source": [
        "Fit a nearest-neighbors model to the document-term matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB3pAOhmto8W",
        "outputId": "81e59b91-5c1f-4741-8e07-c038a22e7250"
      },
      "source": [
        "%%time\n",
        "nn = NearestNeighbors(n_neighbors=10, algorithm='auto')\n",
        "\n",
        "# fit to the document-term matrix of all the vocabulary words\n",
        "nn.fit(word_vectors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 264 ms, sys: 1.8 ms, total: 265 ms\n",
            "Wall time: 219 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdrcAOcfChy0"
      },
      "source": [
        "Choose a query word, for which you want to find synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pBxmi4O5rhp",
        "outputId": "a7f40bd3-0a0e-4c9d-c887-a0371e2d4135"
      },
      "source": [
        "query_word = 'marvelous'\n",
        "query_vector = nlp.vocab.get_vector(query_word)[None,:]\n",
        "query_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRbtlDz0EI6Q"
      },
      "source": [
        "Find the nearest neighbors to the query, from spacy's vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plA09PgS68Sc",
        "outputId": "3c4022f3-7011-40fc-a23b-c1fbb39723eb"
      },
      "source": [
        "neigh_dist, neigh_index = nn.kneighbors(query_vector, n_neighbors=20)\n",
        "[vocab[int(index)] for index in neigh_index[0]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wondeful',\n",
              " 'wonderul',\n",
              " 'wonderful',\n",
              " 'marvelous',\n",
              " 'wonderfull',\n",
              " 'fantastic',\n",
              " 'fantasic',\n",
              " 'fab',\n",
              " 'fabulous',\n",
              " 'fantabulous',\n",
              " 'loverly',\n",
              " 'lovely',\n",
              " 'great',\n",
              " 'amazing',\n",
              " 'amzing',\n",
              " 'all-around',\n",
              " 'terrific',\n",
              " 'delightful',\n",
              " 'bewitching',\n",
              " 'beatiful']"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JftffA2DK2Y"
      },
      "source": [
        "## Can we visualize word vectors?\n",
        "\n",
        "300 dimensional word vectors are difficult (impossible) to visualize! <br>\n",
        "However, we can use Principal Components Analysis (PCA) to reduce their dimensionality. <br>\n",
        "\n",
        "PCA is one of the most important techniques in machine learning, and indeed in all of mathematics! PCA transforms the feature vectors of a data set to their \"Principal Components\", which are ranked in order of their importance in describing the data set. By eliminating the less important Principal Components, we can reduce the dimensionality of the data set, at the cost of losing some information.\n",
        "\n",
        "If you're interested to explore this topic in greater depth, here are a couple of references:\n",
        "- One of the best brief introductions to the mathematics of PCA is [Daniela Witten's tweetstorm](https://twitter.com/womeninstat/status/1285610321747611653?lang=en)\n",
        "- For a more in-depth, but still understandable exposition of PCA, watch the Statquest video [Principal Component Analysis (PCA), Step-by-Step](https://youtu.be/FgakZw6K1QQ) from Josh Starmer.\n",
        "\n",
        "Now let's use PCA to reduce our 300-dimensional word vectors down to two dimensions, so that we can visualize them in a plane. Of course, in the process we lose a lot of information, but these 2D word vectors still pack a surprising amount of information!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c54d3921b438215d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNGfmJ13dRAV",
        "outputId": "266d981a-98d5-48e1-ed0f-aab438467fde"
      },
      "source": [
        "# import the PCA module from sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def get_word_vectors(words):\n",
        "    # converts a list of words into their word vectors\n",
        "    return [nlp(word).vector for word in words]\n",
        "\n",
        "words = ['machine learning', 'man', 'woman',  'king', 'queen',\n",
        "         'artificial intelligence', 'nurse', 'doctor',\n",
        "         'data', 'science',\n",
        "         'concrete', 'wood',\n",
        "         'marble', 'design',\n",
        "         'color', 'font']\n",
        "\n",
        "word_vectors = get_word_vectors(words)\n",
        "\n",
        "\n",
        "# intialise pca model and tell it to project data down onto 2 dimensions\n",
        "\n",
        "# fit the pca model to our 300D data, this will work out which is the best\n",
        "# way to project the data down that will best maintain the relative distances\n",
        "# between data points. It will store these intructioons on how to transform the data.\n",
        "\n",
        "# Tell our (fitted) pca model to transform our 300D data down onto 2D using the\n",
        "# instructions it learnt during the fit phase.\n",
        "\n",
        "# let's look at our new 2D word vectors\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "\n",
        "# intialise pca model and tell it to project data down onto 2 dimensions\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# fit the pca model to our 300D data, this will work out which is the best\n",
        "# way to project the data down that will best maintain the relative distances\n",
        "# between data points. It will store these intructioons on how to transform the data.\n",
        "pca.fit(word_vectors)\n",
        "\n",
        "# Tell our (fitted) pca model to transform our 300D data down onto 2D using the\n",
        "# instructions it learnt during the fit phase.\n",
        "word_vecs_2d = pca.transform(word_vectors)\n",
        "\n",
        "# the fit and transform operations could also be done in one step\n",
        "#word_vecs_2d = pca.fit.transform(word_vectors)\n",
        "\n",
        "# let's look at our new 2D word vectors\n",
        "word_vecs_2d\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.41618712,  1.26197946],\n",
              "       [ 2.18589198, -0.71261883],\n",
              "       [ 3.31224199, -0.63002031],\n",
              "       [ 1.59658923, -3.92203056],\n",
              "       [ 1.85318628, -3.63087635],\n",
              "       [-0.44013359,  1.74871011],\n",
              "       [ 4.43418803,  1.1308269 ],\n",
              "       [ 3.83412466,  1.27867761],\n",
              "       [-1.18444862,  4.02456793],\n",
              "       [ 0.29446239,  2.77555674],\n",
              "       [-2.87613195, -0.30775046],\n",
              "       [-2.84180888, -2.66241824],\n",
              "       [-3.03420388, -3.43600248],\n",
              "       [-2.43581889,  1.23093633],\n",
              "       [-2.24288034,  0.69948326],\n",
              "       [-2.03907129,  1.15097888]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "mjxAfKfodRAV",
        "outputId": "529be6ba-2178-4264-c377-10aeed4fc674"
      },
      "source": [
        "# create a nice big plot\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "# plot the scatter plot of where the words will be\n",
        "plt.scatter(word_vecs_2d[:,0], word_vecs_2d[:,1])\n",
        "\n",
        "# for each word and coordinate pair: draw the text on the plot\n",
        "for word, coord in zip(words, word_vecs_2d):\n",
        "    x, y = coord\n",
        "    plt.text(x, y, word, size= 15)\n",
        "\n",
        "# show the plot\n",
        "plt.grid();\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruZeW9_ZDACQ"
      },
      "source": [
        "### Spend a few minutes exploring the magic of word vectors!\n",
        "Create your own `words` list and run it through the code in the above two cells. <br>\n",
        "Perhaps include clusters of words that have similar meanings or that might <br>reveal implicit gender bias or some other kind of bias. What did you find out?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uAb_h7ldRAW"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will extract word embeddings from documents using Spacy's pre-trained model in the upcoming module project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUWsVDc4dRAW"
      },
      "source": [
        "## King - Man + Woman = Queen\n",
        "\n",
        "Check out [**The amazing power of word vectors**](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/), which explores the above equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEkjvdD5dRAW"
      },
      "source": [
        "# Sources\n",
        "\n",
        "* Spacy 101 - https://course.spacy.io\n",
        "* NLTK Book - https://www.nltk.org/book/\n",
        "* An Introduction to Information Retrieval - https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf"
      ]
    }
  ]
}