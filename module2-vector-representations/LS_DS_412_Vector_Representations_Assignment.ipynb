{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Optional:* Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# come back to scrape later, time allowing\n",
    "\n",
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"<div><div>Job Requirements:</div><ul><li><p>\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\\\n</li><li><p>Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\\\nApply Now</div></div></div></div></div></div></div><div></div>\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][0]\n",
    "# very ugly -- in particular, all the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(df['description'][0])\n",
    "\n",
    "soup.get_text()\n",
    "\n",
    "# remaining garbage: initial b\" and abundant \\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1           1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2           2  b'As a Data Scientist you will be working on c...   \n",
       "3           3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4           4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda d: BeautifulSoup(d).get_text())\n",
    "\n",
    "df.head()\n",
    "\n",
    "# good starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Job Requirements: Conceptual understanding in ...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Job Description  As a Data Scientist 1, you wi...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As a Data Scientist you will be working on con...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>$4,969 - $6,756 a monthContractUnder the gener...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Location: USA \\xe2\\x80\\x93 multiple locations ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  Job Requirements: Conceptual understanding in ...   \n",
       "1           1  Job Description  As a Data Scientist 1, you wi...   \n",
       "2           2  As a Data Scientist you will be working on con...   \n",
       "3           3  $4,969 - $6,756 a monthContractUnder the gener...   \n",
       "4           4  Location: USA \\xe2\\x80\\x93 multiple locations ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a description string and return it with the obvious garbage removed\n",
    "def cut_the_crap(description):\n",
    "    d2 = description.replace('\\\\n', ' ')\n",
    "    d3 = d2.replace('b\"', \"\")\n",
    "    d4 = d3.replace(\"b'\", \"\")\n",
    "    return d4\n",
    "\n",
    "df['description'] = df['description'].apply(cut_the_crap)\n",
    "\n",
    "df.head()\n",
    "# much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "# load it up\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Job Requirements: Conceptual understanding in ...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>[job, requirement, conceptual, understanding, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Job Description  As a Data Scientist 1, you wi...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>[job, description,  , Data, Scientist, 1, help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As a Data Scientist you will be working on con...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>[Data, scientist, work, consult, business, res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>$4,969 - $6,756 a monthContractUnder the gener...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[$, 4,969, $, 6,756, monthcontractunder, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Location: USA \\xe2\\x80\\x93 multiple locations ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[location, USA, \\xe2\\x80\\x93, multiple, locati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  Job Requirements: Conceptual understanding in ...   \n",
       "1           1  Job Description  As a Data Scientist 1, you wi...   \n",
       "2           2  As a Data Scientist you will be working on con...   \n",
       "3           3  $4,969 - $6,756 a monthContractUnder the gener...   \n",
       "4           4  Location: USA \\xe2\\x80\\x93 multiple locations ...   \n",
       "\n",
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [job, requirement, conceptual, understanding, ...  \n",
       "1  [job, description,  , Data, Scientist, 1, help...  \n",
       "2  [Data, scientist, work, consult, business, res...  \n",
       "3  [$, 4,969, $, 6,756, monthcontractunder, gener...  \n",
       "4  [location, USA, \\xe2\\x80\\x93, multiple, locati...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new column for lemmas\n",
    "\n",
    "df['lemmas'] = df['description'].apply(lambda t: [token.lemma_ for token in nlp(t) if (token.is_stop != True) and (token.is_punct != True)])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "# create transformer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# count vectorizer wants a list of strings where each string is a separate document\n",
    "lem_list = []\n",
    "\n",
    "# iterate through each set of lemmas and turn them into an acceptable document for vect\n",
    "for lemma in df['lemmas']:\n",
    "    lem = ' '.join(lemma)\n",
    "    lem_list.append(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to lemmas \n",
    "vect.fit(lem_list)\n",
    "\n",
    "dtm = vect.transform(lem_list)\n",
    "\n",
    "# print(vect.get_feature_names())\n",
    "\n",
    "# I'm seeing a lot of room for improvement in lemmatization, but it looks reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     00  000  02115  03  0305  0356  04  062  06366  08  ...  zero  zeus  zf  \\\n",
      "0     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "1     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "2     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "3     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "4     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "5     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "6     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "7     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "8     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "9     0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "10    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "11    0    2      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "12    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "13    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "14    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "15    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "16    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "17    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "18    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "19    0    2      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "20    0    2      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "21    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "22    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "23    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "24    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "25    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "26    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "27    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "28    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "29    0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "..   ..  ...    ...  ..   ...   ...  ..  ...    ...  ..  ...   ...   ...  ..   \n",
      "396   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "397   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "398   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "399   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "400   0    0      0   0     0     0   0    0      0   0  ...     0     0   8   \n",
      "401   0    1      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "402   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "403   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "404   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "405   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "406   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "407   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "408   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "409   0    1      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "410   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "411   0    0      0   0     1     0   0    0      0   0  ...     0     0   0   \n",
      "412   0    1      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "413   0    2      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "414   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "415   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "416   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "417   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "418   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "419   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "420   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "421   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "422   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "423   0    2      0   0     0     0   0    0      0   0  ...     1     0   0   \n",
      "424   0    0      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "425   0    1      0   0     0     0   0    0      0   0  ...     0     0   0   \n",
      "\n",
      "     zheng  zillow  zogsports  zone  zoom  zuckerberg  zurich  \n",
      "0        0       0          0     0     0           0       0  \n",
      "1        0       0          0     0     0           0       0  \n",
      "2        0       0          0     0     0           0       0  \n",
      "3        1       0          0     0     0           0       0  \n",
      "4        0       0          0     0     0           0       0  \n",
      "5        0       0          0     0     0           0       0  \n",
      "6        0       0          0     0     0           0       0  \n",
      "7        0       0          0     0     0           0       0  \n",
      "8        0       0          0     0     0           0       0  \n",
      "9        0       0          0     0     0           0       0  \n",
      "10       0       0          0     0     0           0       0  \n",
      "11       0       0          0     0     0           0       0  \n",
      "12       0       0          0     0     0           0       0  \n",
      "13       0       0          0     0     0           0       0  \n",
      "14       0       0          0     0     0           0       0  \n",
      "15       0       0          0     0     0           0       0  \n",
      "16       0       0          0     0     0           0       0  \n",
      "17       0       0          0     0     0           0       0  \n",
      "18       0       0          0     0     0           0       0  \n",
      "19       0       0          0     0     0           0       0  \n",
      "20       0       0          0     0     0           0       0  \n",
      "21       0       0          0     0     0           0       0  \n",
      "22       0       0          0     0     0           0       0  \n",
      "23       0       0          0     0     0           0       0  \n",
      "24       0       0          0     0     0           0       0  \n",
      "25       0       0          0     0     0           0       0  \n",
      "26       0       0          0     0     0           0       0  \n",
      "27       0       0          0     0     0           0       0  \n",
      "28       0       0          0     0     0           0       0  \n",
      "29       0       0          0     0     0           0       0  \n",
      "..     ...     ...        ...   ...   ...         ...     ...  \n",
      "396      0       0          0     0     0           0       0  \n",
      "397      0       0          0     0     0           0       0  \n",
      "398      0       0          0     0     0           0       0  \n",
      "399      0       0          0     0     0           0       0  \n",
      "400      0       0          0     0     0           0       0  \n",
      "401      0       0          0     0     0           0       0  \n",
      "402      0       0          0     0     0           0       0  \n",
      "403      0       0          0     0     0           0       0  \n",
      "404      0       0          0     0     0           0       0  \n",
      "405      0       0          0     0     0           0       0  \n",
      "406      0       0          0     0     0           0       0  \n",
      "407      0       0          0     0     0           0       0  \n",
      "408      0       0          0     0     0           0       0  \n",
      "409      0       0          0     0     0           0       0  \n",
      "410      0       0          0     0     0           0       0  \n",
      "411      0       0          0     0     0           0       0  \n",
      "412      0       0          0     0     0           0       0  \n",
      "413      0       0          0     0     0           0       0  \n",
      "414      0       0          0     0     0           0       0  \n",
      "415      0       0          0     0     0           0       0  \n",
      "416      0       0          0     0     0           0       0  \n",
      "417      0       0          0     0     0           0       0  \n",
      "418      0       0          0     0     0           0       0  \n",
      "419      0       0          0     0     0           0       0  \n",
      "420      0       0          0     0     0           0       0  \n",
      "421      0       0          0     0     0           0       0  \n",
      "422      0       0          0     0     0           0       0  \n",
      "423      0       0          0     0     0           0       0  \n",
      "424      0       0          0     0     0           0       0  \n",
      "425      0       0          0     0     0           0       0  \n",
      "\n",
      "[426 rows x 7089 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "# put a pin in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>2019</th>\n",
       "      <th>25</th>\n",
       "      <th>3rd</th>\n",
       "      <th>40</th>\n",
       "      <th>...</th>\n",
       "      <th>x99ve</th>\n",
       "      <th>x9cbig</th>\n",
       "      <th>x9d</th>\n",
       "      <th>xa6</th>\n",
       "      <th>xae</th>\n",
       "      <th>xc2</th>\n",
       "      <th>xe2</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176321</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106363</td>\n",
       "      <td>0.111158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10  100   12   15   20  2019   25  3rd   40  ...  x99ve  x9cbig  x9d  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0     0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0     0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0     0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0     0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0     0.0  0.0   \n",
       "\n",
       "        xa6  xae       xc2       xe2      year  years  york  \n",
       "0  0.000000  0.0  0.182325  0.000000  0.000000    0.0   0.0  \n",
       "1  0.135938  0.0  0.000000  0.176321  0.023034    0.0   0.0  \n",
       "2  0.000000  0.0  0.000000  0.000000  0.000000    0.0   0.0  \n",
       "3  0.000000  0.0  0.000000  0.000000  0.035105    0.0   0.0  \n",
       "4  0.000000  0.0  0.000000  0.106363  0.111158    0.0   0.0  \n",
       "\n",
       "[5 rows x 1441 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=0.025, max_df=.98)\n",
    "\n",
    "dtm = tfidf.fit_transform(lem_list)\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make and fit model\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.248946  , 1.25100532, 1.25330489, 1.25377596]]),\n",
       " array([[  0, 294, 276, 393, 366]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results for first document\n",
    "nn.kneighbors([dtm.iloc[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Requirements: Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role) Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL/Hive or similar programming language Must show past work via GitHub, Kaggle or any other published article Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field. Apply Now\"\n",
      "Data science encompasses the computational and statistical skills required to use data in support of scientific enquiry and sound business decision-making. We are looking to hire candidates to work on challenging data science problems across our oil & gas businesses, including exploration, production, refining, chemicals, retail and corporate services. Job Role Responsibilities Apply statistical analysis, pattern recognition, and machine learning \\xe2\\x80\\x93 along with domain knowledge and subject-specific models \\xe2\\x80\\x93 to solve science, engineering, and commercial problems. Contribute to all stages of data science or decision modeling projects, including problem formulation, solution development, and product deployment: Translate business-relevant scientific, engineering, and commercial problems into questions that may be addressed using data science. Design experiments and/or run simulations to generate new data in support of analytic studies. Retrieve and combine data from databases, data historians, and/or data lakes; there is a strong emphasis on programming, particularly using scripting languages. Perform exploratory data analysis for quality control and improved understanding. Rigorously and reproducibly build, analyze, and compare statistical and/or machine learning models. Contextualize the results and synthesize them with existing knowledge and/or domain-specific models. Deploy data-analytic products to end-users and/or document data-analytic results in technical reports. Job Requirements PhD or MS (exceptional BS candidates will be considered) in one of the following disciplines: Engineering/Sciences, Mathematics, Statistics or Computer Science with significant experience in data analytics. Experience in Python, Scala, Java, C, C++ or R is required Knowledge of statistics, linear algebra, multiple variable calculus, Fourier analysis or machine learning Experience using one or more of the following software packages: scikit-learn, numpy, pandas, jupyter, matplotlib, scipy, nltk, spacy, keras, tensorflow Experience solving problems using one or more of the following techniques: Regression, Support Vector Machines, Decision trees, random forest, Boosting, PCA, KMeans Experience in using SQL/No SQL databases is an advantage Experience working in Linux and in a High Performance Computing environment is an advantage  Alternate Location: United States : Baytown, Texas || United States : Clinton, New Jersey || United States : Hugoton, Kansas  ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.  Nearest Major Market: Houston  Job Segment: Database, Scientific, Engineer, SQL, Java, Technology, Engineering'\n"
     ]
    }
   ],
   "source": [
    "# check whether the comparison looks good\n",
    "print(df.iloc[0]['description'])\n",
    "print(df.iloc[366]['description'])\n",
    "# seems fine! not wildly wrong, at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.33833328, 1.34383729, 1.34555003, 1.34555003, 1.34555003]]),\n",
       " array([[300, 284, 164, 375, 296]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make up a job description and see what real ones match\n",
    "dream = [\"opportunities for mentorship. fluent in Python and experienced in SQL\"]\n",
    "\n",
    "new = tfidf.transform(dream)\n",
    "\n",
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Description We are looking for an experienced Data Scientist to join Vudu\\xe2\\x80\\x99s growing Analytics team in Sunnyvale, CA and lead our efforts at modeling and researching consumer behavior. You will be leading our efforts around content recommendation, personalization, response modeling, churn analysis, A/B testing and much more. Sounds exciting? Here is more:  Who you are:  \\xef\\x83\\x98 End-to-End model development: Build prediction models from the ground up, from data exploration through feature generation and into model construction and optimization. \\xef\\x83\\x98 Mine Vudu (and other) data and deploy statistical modeling to gain robust insights into how consumers make entertainment choices. \\xef\\x83\\x98 Run exploratory analyses into ambiguous problems and define metrics to build a quantitative understanding of our business. \\xef\\x83\\x98 Lead collaboration with teams across the company: Product, marketing, Content and Engineering. \\xef\\x83\\x98 Do whatever it takes to deliver business value with data, be it building a data pipeline, a report, a dashboard or a predictive model. \\xef\\x83\\x98 Communicate key results to senior management in verbal, visual, and written media. #LI-AB1 Minimum Qualifications \\xef\\x83\\x98 PhD or MS degree in Computer Science/Engineering, Operations Research, Statistics, Mathematics, Electrical Engineering or related quantitative field \\xef\\x83\\x98 3+ years of hands-on experience with Python or R and the supporting analysis libraries / ecosystem. \\xef\\x83\\x98 Proven track record of practicing data science at scale. \\xef\\x83\\x98 Great communication skills. \\xef\\x83\\x98 Expertise in practical aspects of applied machine learning. \\xef\\x83\\x98 Expertise in various aspects of data engineering (SQL, Hadoop, Spark etc.) \\xef\\x83\\x98 Delivery-oriented approach - ability to get things done within a strict time frame / ability to juggle multiple assignments. Additional Preferred Qualifications  Company Summary The Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the world\\xe2\\x80\\x99s largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission. Position Summary We are looking for an experienced Data Scientist to join Vudu\\xe2\\x80\\x99s growing Analytics team in Sunnyvale, CA and lead our efforts at modeling and researching consumer behavior. You will be leading our efforts around content recommendation, personalization, response modeling, churn analysis, A/B testing and much more. Sounds exciting? Here is more:  Who you are:  \\xef\\x83\\x98 End-to-End model development: Build prediction models from the ground up, from data exploration through feature generation and into model construction and optimization. \\xef\\x83\\x98 Mine Vudu (and other) data and deploy statistical modeling to gain robust insights into how consumers make entertainment choices. \\xef\\x83\\x98 Run exploratory analyses into ambiguous problems and define metrics to build a quantitative understanding of our business. \\xef\\x83\\x98 Lead collaboration with teams across the company: Product, marketing, Content and Engineering. \\xef\\x83\\x98 Do whatever it takes to deliver business value with data, be it building a data pipeline, a report, a dashboard or a predictive model. \\xef\\x83\\x98 Communicate key results to senior management in verbal, visual, and written media.'\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print(df.iloc[375]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
