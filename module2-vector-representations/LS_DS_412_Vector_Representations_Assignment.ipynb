{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Optional:* Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__(convert_charrefs=False)\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def handle_entityref(self, name):\n",
    "        self.fed.append('&%s;' % name)\n",
    "\n",
    "    def handle_charref(self, name):\n",
    "        self.fed.append('&#%s;' % name)\n",
    "\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "\n",
    "def _strip_once(value):\n",
    "    s = MLStripper()\n",
    "    s.feed(value)\n",
    "    s.close()\n",
    "    return s.get_data()\n",
    "def strip_tags(value):\n",
    "    \"\"\"Return the given HTML with all tags stripped.\"\"\"\n",
    "    # Note: in typical case this loop executes _strip_once once. Loop condition\n",
    "    # is redundant, but helps to reduce number of executions of _strip_once.\n",
    "    value = str(value)\n",
    "    while '<' in value and '>' in value:\n",
    "        new_value = _strip_once(value)\n",
    "        if value.count('<') == new_value.count('<'):\n",
    "            # _strip_once wasn't able to detect more tags.\n",
    "            break\n",
    "        value = new_value\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(strip_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "def tokenize(text):\n",
    "    doc =nlp(text)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['description'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['description'] = df['description'].apply(lambda x: re.sub(r'\\\\x..', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "vect = CountVectorizer(stop_words='english', analyzer='word')\n",
    "vect.fit(df['description'])\n",
    "\n",
    "sparse_dtm = vect.transform((df['description']))\n",
    "\n",
    "dtm = pd.DataFrame(sparse_dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zfs</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02115  03  0356  04  062  06366  08  10  ...  zero  zeus  zf  zfs  \\\n",
       "0   0    0      0   0     0   0    0      0   0   0  ...     0     0   0    0   \n",
       "1   0    0      0   0     0   0    0      0   0   0  ...     0     0   0    0   \n",
       "2   0    0      0   0     0   0    0      0   0   0  ...     0     0   0    0   \n",
       "3   0    0      0   0     0   0    0      0   0   0  ...     0     0   0    0   \n",
       "4   0    0      0   0     0   0    0      0   0   0  ...     0     0   0    0   \n",
       "\n",
       "   zheng  zillow  zones  zoom  zuckerberg  zurich  \n",
       "0      0       0      0     0           0       0  \n",
       "1      0       0      0     0           0       0  \n",
       "2      0       0      0     0           0       0  \n",
       "3      1       0      0     0           0       0  \n",
       "4      0       0      0     0           0       0  \n",
       "\n",
       "[5 rows x 9860 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data          4394\n",
       "experience    1238\n",
       "business      1198\n",
       "work           978\n",
       "team           958\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top 10 words')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "dtm.sum().sort_values(ascending=False).head(10).sort_values(ascending=True).plot.barh()\n",
    "plt.title('Top 10 words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zfs</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  02115   03  0356   04  062  06366   08   10  ...  zero  zeus  \\\n",
       "0  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "    zf  zfs     zheng  zillow  zones  zoom  zuckerberg  zurich  \n",
       "0  0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "1  0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "2  0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "3  0.0  0.0  0.104418     0.0    0.0   0.0         0.0     0.0  \n",
       "4  0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 9860 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "sparse = tfidf.fit_transform(df['description'])\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(sparse.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "# Instantiate\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# Fit on TF-IDF Vectors\n",
    "nn  = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = '''\n",
    "Python Data Engineer\n",
    "\n",
    "Work on a team to build products using data science,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.19869598, 1.19905483, 1.19905483, 1.20629532, 1.22432133]]),\n",
       " array([[217,  33, 378, 261, 216]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tfidf.transform([description])\n",
    "\n",
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Senior Business Intelligence Data Engineer\\\\nRocky Hill, CT\\\\n\\\\n\\\\n\\\\nJob Description\\\\n\\\\nOverview\\\\nAxians redtoo recently brought its almost 30 years of experience in IT and consulting solutions to the Axians family. As both strategic advisors and a full-service IT provider, our customers\\\\' core businesses benefit through our optimization of their business processes and effectively implementing their technology investment.\\\\n\\\\nWe are seeking Senior Business Intelligence Data Engineer to join our client.\\\\n\\\\nPosition Overview\\\\nOur client is looking for an awesome Data/Business Intelligence Engineer to join our growing team of Data warehouse. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.\\\\n\\\\nThe person will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout the ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our companys data architecture to support our next generation of products and data initiatives.\\\\n\\\\nResponsibilities:\\\\nExperience with integration of data from multiple data sources\\\\nStrong knowledge of data cleaning and various ETL techniques and frameworks\\\\nAssemble large, complex data sets that meet functional / non-functional business requirements.\\\\nHands on development of Tableau dashboards using multiple data sources\\\\nCreate and maintain optimal data pipeline architecture especially around accounting and financial systems\\\\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\\\\nConceptualize and design the best fit solution against desired requirements for data delivery\\\\nSelect the right visualization to use based on relevant data type and create visually smart dashboards implementing Tableau best practices\\\\nPublish automated, interactive dashboards to end-consumers using Tableau Server\\\\nConduct periodic tuning of Tableau Server dashboards to minimize the data and render refresh cycles to optimize the end-user experience\\\\nWork with stakeholders including the Managers, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\\\\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\\\\nWork with data and analytics experts to strive for greater functionality in our data systems.\\\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\\\nDesired Skills and Experience:\\\\nAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\\\\nExperience of 5+ years in Business Intelligence and Data Visualization tools and techniques with Tableau\\\\nWe are looking for a candidate with 10+ years of experience in a Data Engineer or Business Intelligence role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:\\\\nExperience with relational SQL databases, including SQL server and Postgres.\\\\nExperience with AWS cloud services: EC2, EMR, RDS, Redshift\\\\nExperience with Tableau or comparable experience with other BI visualization tool such as Qlikview or Domo\\\\nExperience with any object-oriented/object function scripting languages: C#, Python, Java, C++, Scala, etc.\\\\nNice to have experience with big data tools: Hadoop, Spark, Kafka, etc.\\\\nExperience building and optimizing big data data pipelines, architectures and data sets.\\\\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\\\\nExperience scheduling/automating scripts\\\\nStrong analytic skills related to working with structured and unstructured datasets.\\\\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management.\\\\nA successful history of manipulating, processing and extracting value from large disconnected datasets.\\\\nExperience working with financial and accounting systems is preferred. Specific experience with Intacct accounting system is a plus.\\\\nExperience supporting and working with cross-functional teams in a dynamic environment\\\\nPotential for up to a 10% bonus.\\\\n\\\\nBenefits Overview\\\\nCompetitive salary and benefits packages'\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matching description\n",
    "df.description[217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "from requests_html import HTMLSession\n",
    "from multiprocessing.dummy import Pool\n",
    "from itertools import chain\n",
    "\n",
    "class IndeedJobListings:\n",
    "    '''\n",
    "    Multi-theaded Indeed Job Listings Crawler\n",
    "    Usage:\n",
    "    listings = IndeedJobListings('Data Scientist', 'Seattle, WA')\n",
    "    descriptions = listings.get_descriptions(pages=10)\n",
    "    '''\n",
    "    def __init__(self, search_keyword, location, threads=12):\n",
    "        self.threads = threads\n",
    "        self.base_url = 'https://www.indeed.com'\n",
    "        self.query_url = f'{self.base_url}/jobs?' +\\\n",
    "        urlencode({'q': search_keyword, 'l': location})\n",
    "        self.session = HTMLSession()\n",
    "    \n",
    "    def _get_posting_urls(self, url):\n",
    "        doc = self.session.get(url)\n",
    "        posting_urls = [f'{self.base_url}{e.attrs[\"href\"]}' for e in doc.html.find('.jobtitle.turnstileLink')]\n",
    "        return posting_urls\n",
    "\n",
    "    def _get_description_text(self, url):\n",
    "        doc = self.session.get(url)\n",
    "        description_text = doc.html.find('#jobDescriptionText')[0].text\n",
    "        return description_text\n",
    "                        \n",
    "    def get_descriptions(self, pages=1):\n",
    "        list_urls = [self.query_url] + [f'{self.query_url}&start={x*10}'\n",
    "                                        for x in range(1, pages)]\n",
    "        p = Pool(self.threads)\n",
    "        post_urls = chain(*p.map(self._get_posting_urls, list_urls))\n",
    "        descriptions = p.map(self._get_description_text, post_urls)\n",
    "        return descriptions\n",
    "\n",
    "\n",
    "listings = IndeedJobListings('Data Scientist', 'Seattle, WA')\n",
    "descriptions = listings.get_descriptions(pages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summary\\nPosted: Feb 7, 2019\\nWeekly Hours: 40\\nRole Number: 200020558\\nWe are searching for engineers with a real passion for using machine learning to build intelligent applications. In this highly accomplished, deeply technical and close-knit team of data scientists and machine learning engineers, you will craft tools that are used by millions of people. You will have a chance to design and implement new machine learning algorithms and techniques and collaborate with the most innovative product development teams in the world. Our team researches new machine learning algorithms, models and techniques that will power amazingly intelligent user experiences. We are looking for new ambitious members to join our research ML group. In this role, you will design new models and algorithms, and actively engage with the academic community by publishing your work and participating in academic efforts. You will also have the opportunity to contribute to every cool project around Apple, and use your data science, machine learning and artificial intelligence skills to transfer your ideas into solutions for some of the most challenging technical problems in the next generation of products that will delight millions of people.\\nKey Qualifications\\nStrong academic and publication record\\nDeep technical skills in machine learning, deep learning, computer vision, natural language processing, or artificial intelligence\\nA passion for creating innovative techniques and making these methods robust and scalable\\nAbility to explain and present deep technical ideas\\nCreative, collaborative, & innovation focused\\nDescription\\nAs a member of the ML Research team, you will design and evaluate new algorithms, models and methods that will impact Apple and the broad ML community. You will also collaborate with teams across Apple, who are building the newest, most compelling intelligent applications in the world. You will also be a trusted advisor for best practice machine learning development. • Your responsibilities include: • Researching, developing and implementing the most innovative machine learning, artificial intelligence, computer vision and NLP techniques • Publishing papers, software and creating presentations • Transferring machine learning solutions to data scientists and engineers on product teams • Providing technical guidance to product teams on the choice of machine learning approaches appropriate for a task • Providing architectural guidance on transitioning prototypes to high-performance production models • Providing feedback on tools and new features needed back to platform development teams\\nEducation & Experience\\nPhD in Machine learning, Statistics, Computer Science, Physics, or related field or MS in related field with a strong academic track record • 3+ years of research experience in academia or industry',\n",
       " \"Looking for a company that inspires passion, courage and imagination, where you can help shape the future of global commerce? We're looking for talented data scientists to join our ambitious and inclusive team at eBay.\\nHere are some of the problems we are working on:\\nUsing machine learning to determine delivery dates for eBay purchases\\nImproving how fast delivery impacts product search and seller conversions\\nLeveraging similarities and differences between carriers and markets around the world to improve deliveries for eBay customers\\nWe are passionate about building amazing platforms that support the growth of eBay's market share, and we are looking for top-notch data scientists who want to build scalable, business critical systems.\\nResponsibilities\\nYou will be directly responsible for improving eBay's shipping science in markets around the world\\nDesign and implement end to end solutions using machine learning and AI, improving efficiency and user experience for buyers and sellers.\\nConduct experiments and evaluate the performance of the models, investigate false positive/false negatives and implement continuous improvements to retail standards.\\nCollaborate with other researchers, engineers, and product teams to develop strategic and tactical enhancements to our shipping and trust platforms.\\nCommunicate your methodology and results to a community of researchers, developers, analysts, and product managers working on a number of related technologies.\\nWork with data scientists, engineers, and cross functional teams to produce end-to-end production-ready solutions.\\nMaintain responsibility for quality, performance, scalability, and reliability.\\nEstimate effort, build research and development plans, and prioritize work according to the needs of the business.\\nExperience\\nStrong mathematical, statistical, and scientific modeling skills.\\nExperience in predictive analytics, statistical modeling and coding.\\nProficiency in SQL and handling large datasets.\\nProficiency in Python or R.\\nFamiliarity with Hadoop is a must.\\nStrong interpersonal skills and an appreciation of diversity in teamwork\\nThis website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies\\nView our privacy policy\\nView our accessibility info\\neBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.\\nFor more information see:\\nEEO is the Law Poster\\nEEO is the Law Poster Supplement\",\n",
       " \"Summary\\nPosted: Jun 7, 2019\\nWeekly Hours: 40\\nRole Number: 200067029\\nPlay a part in the ongoing revolution in human-computer interaction. Give to a product that is redefining mobile computing. Build groundbreaking technology for large scale systems, spoken language, big data, natural language processing, and artificial intelligence. And work with the people who built the intelligent assistant that helps millions of people get things done — just by asking. Join the Siri team at Apple.\\nKey Qualifications\\nExpertise in natural language processing and machine learning, such as classification, feature engineering, information extraction, structured prediction, clustering, semi-supervised learning, topic modeling, and ranking.\\nProficiency in data science and analytics, including statistical analyses and A/B testing.\\nExperience designing, conducting, analyzing, and interpreting experiments and investigations.\\nStrong programming skills, expert knowledge of algorithms and data structures (Python, Java, or equivalent).\\nPrior experience and continued interest in mentorship and technical development of junior data scientists.\\nExperience with human-labeled data collection, ideally in the domain of linguistic annotation, and practical implementation of item response theory.\\nExcellent problem solving, critical thinking, creativity, organizational, design, and interpersonal skills; ability to work well with all levels of engineers. Confirmed ability to handle multiple projects with strict deadlines.\\nAbility to apply Big Data tools (MapReduce, Hadoop, Hive and/or Pig, Spark) to large quantities of textual data is desired.\\nDescription\\nThe goal of the Siri Machine Learning & Natural Language team is to take Siri to the next level of intelligence and accuracy using advanced statistical techniques. The Senior Data Scientist role employs a spectrum of approaches for improving Siri. At one end, this position involves deriving key insights from large amounts of usage data to suggest new features and fundamental improvements to the user experience. At the other end is work on core machine learning algorithms and systems that are part of Siri’s ability to understand and respond to requests. Ability to draw on and develop a wide variety of skills is necessary in all aspects of the Senior Data Scientist role. This role also involves technical leadership and mentorship of data scientists and machine learning engineers. Growing teams, both through recruiting and technical skills development, is an essential responsibility of the Senior Data Scientist role. This is an unusual opportunity that sits at the cutting-edge of data science and machine learning, and your work will have a huge impact on hundreds of millions of users across the globe. Furthermore, you’ll be instrumental to developing & growing a team of data scientists, and have the opportunity to set technical direction and establish team culture.\\nEDUCATION & EXPERIENCE Master's or PhD in Computer Science or a data-driven physical science, or equivalent, plus 3 or more years of relevant industry experience.\\nEducation & Experience\\nMaster's or PhD in Computer Science or a data-driven physical science, or equivalent, plus 3 or more years of relevant industry experience.\",\n",
       " 'Summary\\nPosted: Jun 20, 2019\\nWeekly Hours: 40\\nRole Number: 200026732\\nWe are looking for applied scientists with a passion for using machine learning to transform in-the-wild sensing data from the most worn wearables into intelligent health experiences. You will join a close-knit team of highly accomplished and deeply technical researchers and engineers focused on delivering groundbreaking machine learning technologies to the health space. As a member of this team, you will use your practical knowledge and experience with data science, machine learning, and artificial intelligence techniques to tackle important technical problems to deliver the next generation of Apple health experiences. You will play a key role in defining, designing, implementing, and evaluating new machine learning models and algorithms for significant problems involving unusual data and objectives. In this role, you will collaborate with highly innovative product teams across Apple, and see projects through to deployment on 1 billion Apple devices worldwide. YOUR RESPONSIBILITIES INCLUDE: - Investigating innovative machine learning, artificial intelligence, statistics, computer vision, and NLP techniques for rare health data challenges - Designing and implementing production-ready machine learning pipelines - Co-developing machine learning solutions with data scientists and engineers on product teams across Apple - Providing technical mentorship on transitioning prototypes to high-performance production models\\nKey Qualifications\\n2-5 years of practical experience applying ML to solve real-world problems\\nExpertise in at least one area of machine learning, artificial intelligence, or statistics (e.g., health, time series, causal inference, probabilistic modeling, reinforcement learning, optimization, NLP)\\nStrong interest in applying machine learning to health related problems and data\\nAbility to distill vague product experiences into concrete problem definitions\\nA passion for making methods robust and scalable\\nExperience using Python, R, C/C++, or other programming language for machine learning\\nDescription\\nPREFERRED QUALIFICATIONS: - 5+ years of practical experience applying ML to tackle real-world problems, especially in the health domain - Proficiency training large scale models using modern machine learning packages (e.g. TensorFlow, PyTorch, autograd), and experience with data analysis stacks (such as numpy, scipy, pandas, etc.) - Strong fundamentals in problem solving, algorithm design, and model building - Passion for creating new technologies with high product impact - Excellent verbal and written communication and presentation skills\\nEducation & Experience\\nMS or PhD in Computer Science, Machine Learning, AI, Statistics, Mathematics, or related quantitative field',\n",
       " 'Summary\\nPosted: May 29, 2019\\nWeekly Hours: 40\\nRole Number: 200060291\\nAt the Siri International team within Apple we bring the Siri intelligent assistant to our customers worldwide in over 40 languages and dialects. Join us, and tackle some of the most challenging problems in natural language processing and large scale applied machine learning. You will build cutting edge natural language understanding technologies and deploy them on a global scale. Your work will advance and shape the future vision of our multi-lingual, multi-cultural Siri assistant, and Search applications used by millions across the world\\nKey Qualifications\\nExtensive track record of scientific research in NLP and Machine Learning, or similar experience in developing language technologies for shipping products.\\nStrong coding and software engineering skills in a mainstream programming language, such as Python, Java, C/C++.\\nFamiliarity with NLP/ML tools and packages like Caffe, pyTorch, TensorFlow, Weka, scikit-learn, nltk, etc.\\nPractical experience building production quality applications related to natural language processing and machine learning.\\nIn-depth knowledge of machine learning algorithms and ability to apply them in data driven natural language processing systems.\\nAbility to quickly prototype ideas / solutions, perform critical analysis, and use creative approaches for solving complex problems.\\nAttention to detail and excellent communication skills.\\nDescription\\nWe are looking for a highly motivated technologist with a strong background in Natural Language Processing and Machine Learning research. The ideal candidate will have a strong track record of taking research ideas to real-world applications. In this position you will apply your problem solving skills to challenges and opportunities within Siri International, which involves development of large-scale language technologies for many natural languages worldwide. The primary responsibility of this role is to conduct research and develop innovative machine learning, artificial intelligence and NLP solutions for multi-lingual conversational agents. You will have the opportunity to investigate cutting edge research methods that will improve customer experience of our products and enable our engineers to scale these technologies across a variety of natural languages. You will also provide technical leadership and experiment-driven insights for engineering teams on their machine learning modeling and data decisions. You will play a central role in defining the future technical directions of Siri International through quick prototyping, critical analysis and development of core multi-lingual NLP technologies.\\nEducation & Experience\\n* PhD in Machine Learning, Statistics, Computer Science, Mathematics or related field with specialization in natural language processing and/or machine learning, OR * Masters degree in a related field with a strong academic/industrial track record. * Hands-on research experience in an academic or industrial setting.',\n",
       " \"Description:\\nAs part of a small, passionate and accomplished team of experts, you will lead efforts to identify, capture, develop, and demonstrate technologies in the area of machine learning and data science to support Blue Origin’s vision of enabling a future where millions of people are living and working in space. You will lead small and multi-disciplinary teams to identify, prioritize, and execute industry-shaping technology projects across the product lifecycle while working with internal and external customers and partners.\\nYou will help develop a long range technology and innovation roadmap, ensure your efforts support the company vision, and incorporate or evolve projects into major development programs as needed. You should be adept at managing to a plan and a budget in a small team, comfortable adjusting it in response to evolving requirements or external constraints, and prioritizing technology investment all the while infusing and facilitating creativity and innovation. This position will directly impact the history of space exploration and will require your dedicated commitment and detailed attention towards safe and repeatable human spaceflight.\\nWhile in this role, you will leverage your extensive experience in machine learning and data science to accelerate and innovate across business areas to drive improvements in the way we design, build, and operate our vehicles, launch systems, and business. The ideal candidate will have direct experience in the applied development and implementation of machine learning and deep learning techniques, artificial intelligence, operational research, semantic analysis, statistical methods or other advanced processing techniques.\\nResponsibilities:\\nDefine and manage a portfolio of technologies including capture, execution and infusion into major development programs\\nPrepare and manage design/technology reviews\\nDevelop strategic plans and technology roadmaps to meet internal and external customer needs in the areas of machine learning and data science\\nProject engineering, including tracking, reporting, and communication of status as well as definition and management of technical tasks, critical path items, and risks/opportunities\\nDevelop project plans, budgets, and schedules, both from internally derived goals and constraints and from customer contracts and statements-of-work\\nIdentify staffing needs and resources priorities\\nBudget management and tracking\\nDefine and capture new Research & Development (R&D) business, including supporting proposals to the U.S. Government\\nSupport the business development activities to tailor capabilities to meet emerging needs\\nParticipate in conferences and customer meetings as a representative of Blue Origin\\nEstablish, coordinate, and mature academic and research partnerships\\nQualifications:\\nMinimum of a M.S. degree Electrical or Aerospace Engineering, Computer Science, Applied Mathematics, Physical Sciences or related technical field\\n15+ years industry experience, 5+ in progressive project management roles\\nDemonstrated technical expertise in machine learning techniques, probabilistic reasoning, adaptive control, data science, and/or optimization\\nScientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field\\nDemonstrated ability to perform both theoretical (e.g., modeling, simulation, analysis, design) and applied (implementation, testing, and validation) development of advanced algorithms and data processing techniques\\nDemonstrated experience leading and managing small teams on fast-paced projects\\nDemonstrated software development experience\\nLeadership and management experience as well as a history of mentoring\\nProject management skills\\nExcellent written and verbal communication skills\\nMust be a U.S. citizen or permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum\\nDesired:\\nPh.D. in Electrical or Aerospace Engineering, Computer Science, Applied Mathematics, Statistics or related technical field\\nExperience across multiple portions of the product life cycle (concept definition through operations and use)\\nFamiliarity with applying machine learning techniques to real-time, safety-critical systems\\nSpecific experience leading Research & Development (R&D) projects\\nExperience with proposal leadership or support (technical/management volumes, basis-of-estimate development, etc.)\\nExperience working with and proposing to U.S. Government research agencies (e.g. NASA, AFRL, DARPA)\\nExperience with human spaceflight\\nFamiliarity with autonomous systems, business intelligence, or generative design\\nExperience developing requirements, defining subsystem interfaces (both in-house and between external partners/suppliers), and other systems engineering products and practices\\nAbility to obtain and retain a security clearance\\nBWKS\\nBlue Origin offers a phenomenal work environment and awesome culture with competitive compensation, benefits, 401K, and relocation.\\n\\nBlue Origin is an equal opportunity employer . In addition to EEO being the law, it is a policy that is fully consistent with Blue's principles. All qualified applicants will receive consideration for employment without regard to status as a protected veteran or a qualified individual with a disability, or other protected status such as race, religion, color, national origin, sex, sexual orientation, gender identity, genetic information, pregnancy or age. Blue Origin prohibits any form of workplace harassment.\",\n",
       " 'Our client is an Amazing company in Redmond, WA looking for a High-Performance Computing Statistical Programmer.\\nResponsibilities:\\nAssist in development and deployment of statistical and platform code on high-performance computing systems. Ideal candidate will have experience reviewing and debugging large code bases, will possess a background in quantitative methods and/or computer science, and has proven capabilities in translating requirements into efficient code. Role involves working closely with data scientists and software engineers in development, testing and deployment of a large statistical system for production-grade analysis and prediction, so experience working in an interdisciplinary team with a strong attention to detail is a plus.\\nStrong background and experience with statistical methods, data analysis and machine learning is a plus.\\nRequired Skills:\\nDeep experience with the R statistical programming language, including dplyr and associated packages.\\n5+ years of coding experience – (1,000 or more lines of code)\\nSolid foundational understanding of computer science (e.g., functional programming) and software engineering practices.\\nExperience with large-scale parallel computing, especially Spark/SparkR and DataBricks (or similar) required.\\nPrior experience using git as a shared code repository for large projects.\\nExperience with Azure or similar cloud solutions preferred.\\nBackground and experience with statistical methods, data analysis and machine learning is a plus.\\nA Bachelor’s degree or higher is required for this role\\nStatus: Long Term contract\\nLocation: Redmond, WA\\nJob Id : MS1816\\nSince 2000, Akvelon has specialized in placing top software engineering talent at Fortune 500 Companies and start-ups alike. We were ranked in Comparably’s 2018 list of Top 15 Best Companies in Seattle, and were voted one of the Puget Sound Business Journal’s fastest growing companies for several years.\\nAkvelon is an Equal Opportunity Employer - All qualified applicants will receive consideration. We do not discriminate on the basis of race, color, religion, gender, national origin, age, disability, veteran status, or any other factor determined to be unlawful under applicable law.\\nJob Types: Full-time, Contract\\nExperience:\\nlarge-scale parallel computing: 1 year (Preferred)',\n",
       " 'One of our top consulting clients is looking to hire Data Scientists to long term 12+ Month projects in the Seattle area. US Citizen and Green card candidates are preferred\\n\\nThis role requires an in-depth understanding of statistics, as well as basic programming and data management skills. Success will require strong statistical problem-solving skills and the ability to leverage cutting-edge big data technologies.\\n\\nQualifications:\\nGood Knowledge of SQL (3+ years) creating advanced queries in a high impact role.\\nMust have experience with Web Analytics.\\nKnowledge of Statistics and Machine Learning techniques.\\nMasters in Stats, computer science or related field\\nKnowledge of R or Python (3+ years)\\nKnowledge of C# (at least 1 year)\\nExperience building data pipelines\\nA portfolio of NLP projects to showcase and discuss\\nExperience in marketing analytics, attribution modeling, or click-stream data analysis\\nWorking in Hadoop, Redshift, or Spark\\nTranslating business and product questions into analytics projects\\nDeveloping production grade solution is a huge plus',\n",
       " \"Primary Skills: Data Scientist, Quantitative, Data Modeling\\nDuration: 9+ Months\\nTax Term : W2\\n\\nJob Description:\\nProvides quantitative support, business understanding and a strategic perspective.\\nResponsible for understanding the current data model and presenting an improved data model proposal.\\nResponsible for implementing the improved data model proposal in a Mathematical Modeling Language,\\nTo follow up with any questions, please contact Dipak at 408-907-3213.\\n\\nAkraya is an award-winning IT staffing firm and the staffing partner of choice for many leading companies across the US. We offer comprehensive benefits including Health Insurance (medical, dental, and vision), Cafeteria Plan (HSA, FSA, and dependent care), 401(k) (enrollment subject to eligibility), and Sick Pay (varies based on city and state laws).\\nIf this position is not quite what you're looking for, visit akraya.com and submit a copy of your resume. We will get to work finding you a job that is a better fit at one of our many amazing clients.\\n\\nAkraya is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Akraya is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.\",\n",
       " 'Data Scientists at Microsoft help to improve the quality of experiences on our devices and services. We are looking for highly motivated and passionate Data Scientists to apply rigorous scientific methodology and algorithms to data in order to improve Microsoft’s devices, operating systems, and services. As a Data Scientist, you will provide unique insight into business and customer scenarios that cut across organizational boundaries and lead the growth of a data-driven culture within Microsoft.\\n\\n\\nDo you want to work on a meaningful and impactful project and make a difference?\\nAre you willing to learn from others and open to new ideas?\\nDo you want to support others to succeed and operate in a highly-collaborative and global environment?\\nIf this sounds like you, Microsoft would like to invite you to come join us as you are, where you can find more than just a job.\\nRead on to learn more about opportunities and apply online!\\nResponsibilities\\nAs a Data Scientist, you will formulate approaches to solve problems using well-defined algorithms and data sources. You will incorporate an understanding of product functionality and customer perspective to provide context for those problems. You will use data exploration techniques to discover new questions or opportunities within your problem area and propose applicability and limitations of the data. Successful Data Scientists will interpret the results of their analysis, validate their approach, and learn to monitor, analyze, and iterate to continuously improve.\\n\\n\\nYou will engage with peer stakeholders to produce clear, compelling, actionable insights that influence product and service improvements that will impact millions of customers. As a Data Scientist, you will also engage in the peer review process and act on feedback while learning innovative methods, algorithms, and tools to increase the impact and applicability of your results.\\nQualifications\\nCurrently has or is in the process of obtaining their BA/BS or Masters in Computer Science, Mathematics, Economics, Statistics, Applied Sciences like Biostatistics, Physics, Chemistry, Computational Neurology\\nSome Engineering experience and or project course work using large data systems on SQL, Hadoop, etc.\\nProficiency using one or more programming or scripting language to work with data such as: Python, Perl, or C#.\\nSome experience and or project course work performing data analysis and applying statistics working with tools such as: Excel, R, MATLAB, AMPL, or SAS.\\nSome experience and or project course work with product and service telemetry systems.\\nSome A/B Testing or experimentation (this can be from conducting real life science experiments, hypothesis testing in stats etc.) Not required but ideal.\\nSome experience or course work applying basic ML to a type of data and or used algorithms to conduct experiments on data. Machine Learning strongly encouraged.\\nPassion to learn from your peers, manager, and other stakeholders in the Data Science domain.\\nAbility to interact with peers and stakeholders to drive product and business impact.\\nStrong interpersonal and communications skills.\\n\\n\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.',\n",
       " 'Now Brewing – Decision Scientist, Data Visualization! #tobeapartner\\n\\nFrom the beginning, Starbucks set out to be a different kind of company. One that not only celebrated coffee and its rich tradition, but that also brought a feeling of connection. We are known for developing and supporting partners who share this passion and are guided by their service to others.\\n\\nAs a Starbucks Decision Scientist on the Data Visualization team, you will proficiently guide in the application of research, statistics, experimental design, synthesize, analyze, and implement and deploy models, dashboards, and storytelling presentations that support Starbucks Global lines of business. You will drive and evaluate new methods and introduce novel visualization and presentation paradigms to communicate discoveries.\\n\\n\\n\\nLeveraging your previous experience, we will enable you to:\\n\\n\\n\\nIdentify and understand business problems from strategy through operational impacts. Identify business problems to solve that have the most value to organization. Works with business stakeholders to identify and clarify core problems and questions of interest.\\n\\n\\n\\nApprove analytic validation and application of data transformations, algorithms, etc. to accurately represent the model and rule intent and promote recommendations into business processes, with a penchant for scalability into other business functions or congruent problem sets.\\n\\n\\n\\nUnderstand decision sciences, advanced analytics, data visualization, and how to evangelize the craft to both business partners and Analytics and Insights peers.\\n\\n\\n\\nEstablish brand and team as subject matter experts in data visualization across departments.\\n\\n\\n\\nWe’d love to hear from people with:\\n\\n\\n\\nAdvanced proficiency w/ Tableau, D3, Looker, or Power BI\\n\\n\\n\\nProficiency with SQL, SAS, Python or R\\n\\n\\n\\nBusiness experience with statistics (descriptive, regression, etc.)\\n\\n\\n\\nBusiness experience with using data to drive decision\\n\\n\\n\\nBusiness experience using data visualization to enable self-service and drive key behavioral changes in the business\\n\\n\\n\\nKnowledge guiding change management programs and training\\n\\n\\n\\nRetail, customer loyalty, or eCommerce experience preferred\\n\\n\\n\\n\\n\\nLet us give you the opportunity to be part of something bigger than yourself. It’s time for you to #beapartner. Apply today!\\n\\n\\n\\n\\nStarbucks and its brands are an equal opportunity employer of all qualified individuals.\\n\\nWe are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.\\n\\nQualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at 206-318-0660 or via email at applicantaccommodation@starbucks.com',\n",
       " 'Now Brewing – Decision Scientist, Applied Analytics,Product! #tobeapartner\\n\\nFrom the beginning, Starbucks set out to be a different kind of company. One that not only celebrated coffee and its rich tradition, but that also brought a feeling of connection. We are known for developing and supporting partners who share this passion and are guided by their service to others.\\n\\nAs a Starbucks Decision Scientist, you will support the marketing and product organization in their efforts to delight our customers by providing them with the by providing them with the right communication and product at the right time right communication at the right time. You will leverage your analytical chops to support the further development of our Starbucks Rewards program, as well as understand how new and limited products are performing, and how to best market new products.\\n\\nLeveraging your previous experience, we will enable you to:\\nCollaborate with business partners to define business questions and translate unstructured strategic questions into a structured analysis plan\\nDesign & implement measurement plans to ensure that the methodology matches the use case, that the recommendations and conclusions are appropriately contextualized\\nAnalyze and explore data via a variety of statistical and descriptive techniques to generate actionable insights\\nCreate dashboards that surface impactful KPIs to business users and empower them to make day-to-day data-driven decisions\\n\\nWe’d love to hear from people with:\\nDemonstrated experience with SQL, PowerPoint\\nHigh proficiency with Python or R; familiarity with both\\nWorking knowledge of statistics (descriptive, regression, etc.)\\nBusiness experience with data visualization tools (e.g., Tableau)\\nRetail, customer loyalty, marketing or eCommerce experience preferred\\n\\n\\n\\nLet us give you the opportunity to be part of something bigger than yourself. It’s time for you to #beapartner. Apply today!\\n\\n\\n\\nStarbucks and its brands are an equal opportunity employer of all qualified individuals.\\n\\nWe are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.\\n\\nQualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at 206-318-0660 or via email at applicantaccommodation@starbucks.com',\n",
       " 'Now Brewing – data scientist! #tobeapartner\\nFrom the beginning, Starbucks set out to be a different kind of company. One that not only\\ncelebrated coffee and the rich tradition, but that also brought a feeling of connection. We are known for developing extraordinary leaders who share this passion and are guided by their service to others.\\n\\n\\nAre you a data scientist who thinks like a business owner? Are you passionate about solving business problems by designing optimal experiments and deploying solutions at scale using 1st, 2nd, and 3rd party customer data in a next generation analytics infrastructure to help Starbucks optimize digital engagements with our 75M customers?\\n\\n\\nIf you answered “yes” to the questions above, please come and join our Data Science team. You will help optimize app-level product recommendations, digital menu board content, voice-order recommendations, drive-thru personalized menu board content, 1-1 and in-store marketing via personalized content on order labels and POS systems.\\n\\n\\nAs a data scientist, your responsibilities and job functions will include…\\n\\n\\nData Preparation:\\nUnder direction of more senior data scientists, execute extraction and synthesis of data from Azure: data lake storage (ADLS), blob storage, SQL DW, SQL Server; and legacy systems: Oracle and its companion data lake storage\\nUnder direction of more senior data scientists, process 1st 2nd, and 3rd party customer data in next generation privacy compliant infrastructure\\nBusiness Understanding & Provide Optimal Solutions:\\nHas minimal understanding of Starbucks business, and business acument in general. Requires mentoring and guidance\\nMachine Learning and Data Product Dev and Deployment:\\nUnder direction of more senior data scientists, contribute to AI and Machine Learning models in batch, real-time\\nDevelop data pipelines and scalable Restful APIs to create and enable analytical applications\\nStatistics and Model Development and Deployment:\\nLeverage the latest cloud technologies, existing and immerging statistical and machine learning techniques to identify data patterns and trends to solve business problems\\nWith support from more senior data and decision scientists, build and deploy customer segments to facilitate optimal marketing targeting within channels\\nVia a \"feature factory\" approach, build large numbers of weak learners in a Customer 360 framework\\nInsights Operationalization:\\nUnder the guidance of more senior data scientists, create clear and concise packaging and presentation of data products and insights to business stakeholders, leaders and the broader analytics community\\nData Science Evangelism:\\nWith support from more senior data scientists, establish and foster close collaboration between data and decision scientists, engineers, business and leadership teams to align on technical roadmaps for innovation\\nEstablish brand and team as subject matter experts and trusted advisors for Analytics across departments\\nProject & Work Management:\\nActively participate in an Agile team structure designed to create a bias for action (fail fast/often)\\nUtilize Wiki and GitHub to share standards and code\\nPresent code to team for review compared to Best Practice\\nActively participate in Agile-related meetings: stand-ups, sprint planning, retrospectives, showcases\\nParticipate in Microsoft Azure and other trainings\\n\\n\\nWe’d love to hear from people with:\\nEducation: Min BS/BA with concentration in quantitative discipline - Stats, Math, Comp Sci, Engineering, Econ or similar discipline\\n1+ years’ professional data science experience\\nDemonstrated experience with one programming language such as Scala, Java, C++, C#\\nDemonstrated experience with scripting languages such as Unix Shell (ksh, csh, bash, sh), PowerShell, ARM\\nDemonstrated experience with cloud tech for data and analytics solutions (Azure, AWS)\\nDemonstrated experience building and deploying AI / Machine Learning solutions, at scale\\nDemonstrated familiarity with Web application security, SSL OAuth\\nDemonstrated self-sufficiency with R or Python (or equivalent)\\nRetail, customer loyalty, or eCommerce experience preferred\\n\\n\\nJoin us and be part of something bigger. Apply today!\\n\\n\\nStarbucks and its brands are an equal opportunity employer of all qualified individuals, including minorities, women, veterans and individuals with disabilities. Starbucks will consider for employment qualified applicants with criminal histories in a manner consistent with all federal, state, and local ordinances.',\n",
       " 'Organization and Job ID\\nJob ID: 309505\\nDirectorate: National Security Directorate\\nDivision: Computing & Analytics\\nGroup: Applied Statistics & Computational Modeling\\nJob Description\\nThis position is for a Scientist in Data Science and Mathematical Statistics who will provide scientific and technical research within the National Security Directorate (NSD) supporting the data analytics capabilities of the Computational Analytics Division. The Scientist will define and carry out the application of existing methodologies and original research in data science and mathematical statistics, including statistical methods in experimental design, machine learning, and data modeling to recognize patterns, characterize uncertainty, and develop predictive models using structured and unstructured data. The Scientist will produce solutions driven by domain science and mathematical statistical science from complex and high-dimensional datasets and design, develop, and evaluate advanced algorithms that lead to optimal value extraction from data. In addition to technical research this position expects participation and career development in task management, proposal writing, business development, and publishing.\\nOperating on the data-information-knowledge continuum, staff at PNNL emply diverse methods to confront significant problems of national interest – from distilling distributed data into knowledge that supports decision processes to enabling resilient technologies that enhance computing at extreme scales. Our research portfolio – spanning from basic to applied – includes statistical modeling and experimental design, applied statistics, applied mathematics, machine learning, operations research, optimization, and other advanced statistical and mathematical domains.\\nComputing researchers and practitioners work side by side to apply advanced theories, methods, algorithms, models, evaluation tools and testbeds, and computational-based solutions to address complex scientific challenges affecting energy, biological sciences, the environment, and national security. Core domain knowledge is beneficial, such as in the nuclear, biological, energy, materials, or chemical science spaces.\\nMinimum Qualifications\\nBS with at least 2 years experience, MS, or PhD\\nExperience in domain science, particularly energy, nuclear, materials science\\nPreferred Qualifications\\nPosition requires a degree in statistics, mathematics, or closely related fields with experience involving increasing levels of scientific research, task management, and programmatic responsibility\\nPosition requires ability to apply theories and develop technical approaches with minimal oversight\\nPosition requires the ability to effectively team with scientists and engineers to develop creative solutions to complex problems\\nEqual Employment Opportunity\\nBattelle Memorial Institute (BMI) at Pacific Northwest National Laboratory (PNNL) is an Affirmative Action/Equal Opportunity Employer and supports diversity in the workplace. All employment decisions are made without regard to race, color, religion, sex, national origin, age, disability, veteran status, marital or family status, sexual orientation, gender identity, or genetic information. All BMI staff must be able to demonstrate the legal right to work in the United States. BMI is an E-Verify employer. Learn more at jobs.pnnl.gov.\\nDirectorate: National Security Dir\\nJob Category: Scientists/Scientific Support\\nGroup: Appld Stats & Computa Modeling\\nOpening Date: 2019-06-25\\nClosing Date: 2019-09-23',\n",
       " \"This position is part of the Global Payment and Fraud team. This is the business team responsible for Global Payment and Fraud strategy and execution at Starbucks. Millions of times a day customers interact with Starbucks payment systems across physical and digital platforms and customers expect to securely and seamlessly interact with Starbucks payment systems. Your role is to create tools and perform analytics that provide actionable insights that enable ongoing business optimization and innovation for Starbucks Fraud and Payment.\\n\\n\\nYou’ll be deeply embedded in the business where the output of your efforts will immediately improve Starbucks. You’ll help Starbucks figure out how we can make sure that we’re always reliable for our customers in an ever more complex environment. You'll build powerful new self-service tools to make it faster and easier to for your internal customers to act. Finally, you'll build tools that make it possible for us to find and fix problems quickly and efficiently.\\n\\n\\nWe are a fast-paced environment, using agile methodology and tailoring our designs and implementation to the maturity of the business. Currently we code in both Oracle PL/SQL and Microsoft BI platforms (SQL Server/Azure) and utilize Tableau as a visualization layer. This is always subject to change as new technologies emerge. Our supportive team culture encourages innovation and we expect developers and management alike to take a high level of ownership for the product vision, technical architecture and project delivery.\\nResponsibilities:\\nDevelop a solid understanding of all the transaction management systems Starbucks utilizes to manage our global business including our Digital Stored Value Card program, Digital Payments as well as our physical Point of Sale. This role will need to understand the end to end Financial and Workflow systems/processes, back-end logging structure and the impacts on/relationship to the operational effectiveness and efficiency of the organizations\\nWork with cross-functional teams of Product Owners, Operators, Data Scientists and technical source system teams to understand data as well as business performance drivers and architect data visualization tools to enable continuous improvement\\nCreate reporting artifacts tailored to varying customers from executive to operator\\nRaise the analytics bar by acting as a subject matter expert to business and technical teammates and enable self-service analytics\\nWork through the entire Software Development Life Cycle with little supervision\\nResponsible for calibration efforts and testing of tools to insure highest levels of accuracy and dependability along with documentation and user training in support of self-service analytics\\nWork with teammates to evaluate reporting requests, assess feasibility, develop prototypes, and implement a production/delivery plan in conjunction with Starbucks technology as required\\nUtilize troubleshooting and advanced problem-solving skills to provide advanced support to systems developed by others.\\nUtilize a variety of technologies including SQL Server, Oracle, Azure, AWS or other as needed\\nFacilitate changes into production environment through appropriate teams via established change management processes\\nParticipate in large-scale Starbucks international system implementations requiring fraud or payment capabilities and integration with our global data architecture supporting fraud and payments\\nDevelop ad-hoc BI solutions as needed to solve emerging and complex business problems\\n\\n\\nQualifications\\n\\n\\nExperience and education requirements:\\nBachelor's degree in computer engineering, electronics, business administration, communication and/or statistical analysis with data mining or related field or the foreign equivalent or relevant work experience.\\nMaster's degree preferred.\\nFunctional and technical skill requirements:\\nMust be comfortable with writing SQL and have working knowledge of ETL processes used to streamline and automate the collection of data from source systems.\\nExperience developing Business Intelligence solutions using Microsoft BI Stack - SQL Server, SSAS, SSRS, SSIS, Azure a plus with specific focus on data visualization tools like Tableau\\nExperience performing Relational and Dimensional Data Modeling for data warehouse, data mart or decision support systems also a plus\\nOther Qualifications:\\nExcellent analytic, troubleshooting and problem solving skills, with proven ability to quickly understand a problem, determine significance of issue and identify a solution.\\nExperience working with payment data and specifically supporting payment operations analytics tools a significant plus\\nFocus on delivering results, and work ethic based on a strong desire to exceed expectations.\\nDemonstrated understanding of financial database structure and design principles.\\nStrong interpersonal skills, including written and oral communication skills.\\nAbility to work within a team environment, networking and collaborating cross-functionally.\\nAbility to remain flexible in a fast paced and rapidly changing environment.\\nCommitment to continued improvement, and demonstrated ability to innovate\\n\\nStarbucks and its brands are an equal opportunity employer of all qualified individuals.\\n\\nWe are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.\\n\\nQualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at 206-318-0660 or via email at applicantaccommodation@starbucks.com\",\n",
       " 'Masters with two years of experience or a Bachelors with five years of experience.\\nExperience in SQL, R, Python, or another scripting language; command line usage\\nTrack record of diving into data to discover hidden patterns and of conducting error/deviation analysis\\nKnowledge of various machine learning techniques and key parameters that affect their performance\\nExperience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations\\nEvidence of using of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects\\nExcellent written and verbal communication skills for both technical and non-technical audiences\\n\\n\\nAmazon delights millions of customers around the world. Meet the behind the scenes team that enables our Human Resource and Operations Leaders to make informed decisions. The Amazon PeopleInsight team builds reporting and analytics tools for our teams that fulfill customer promise every day. Whether it is Fulfillment Center team that delivers your Prime order in two days, our Amazon Locker team that lets you pick up your package anytime that is convenient for you, our Prime Now team getting you lunch in under an hour, or one of many more, the PeopleInsight group is there providing people metrics along the employee lifecycle for our global operations businesses. The PeopleInsight team is a collaborative group of Business Analysts, Business Intelligence Engineers, Data Engineers, Data Scientists, Product Managers, and Program Managers dedicated to empowering leaders and enabling action through data and science. We deliver workforce, associate experience, and leadership insights so Amazon leaders can focus their efforts in ways that will engage, retain and grow their associates.\\n\\nWe are now recruiting for an exceptional Data Scientist, Worldwide Operations\\n\\nThe ideal candidate will be:\\n\\nA Well-Rounded Athlete –Like a true athlete, you understand that we succeed or fail as a team. You are always ready to step up beyond your core responsibilities and go the extra mile for the project and your team. You nimbly overcome barriers to deliver the best products more quickly than expected.\\nA Perpetual Student – You seek knowledge and insight. You challenge yourself to turn moments into master’s classes. Whether closing a gap, developing a new skill, or staying ahead of your industry, you revel in the joy of learning and growing.\\nA Skilled Communicator – You excel when interacting with business and technical partners whether you are chatting, sending a written message, or conducting a presentation.\\nA Trusted Advisor – You work closely with stakeholders to define key business needs and deliver on commitments. You enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format.\\nAn Inventor at Heart – You innovate on behalf of your customer by proactively implementing improvements, enhancements, and customizations. Your customers marvel at your creative solutions to challenges they had not yet identified.\\nA Fearless Explorer – You are drawn to take on the hardest problems, navigate ambiguity, and battle skepticism. You never settle, even in the face of overwhelming obstacles.\\n\\nRoles and Responsibilities\\nSuccess in this role will include influencing within your team and mentoring peers. The problems you will consider will be difficult to solve and often require a range of data science methodologies combined with subject matter expertise. You will need to be capable of gathering and using complex data set across domains. You will deliver artifacts on medium size projects, define the methodology, and own the analysis. Your findings will affect important business decisions. Solutions are testable and reproducible. You will create documents and share findings in line with scientific best practices for both technical and nontechnical audiences.\\n\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age.\\n\\n\\nExperience in one or more natural language processing topics: tagging, syntactic parsing, word sense disambiguation, topic modeling; contextual text mining, and application of deep learning to NLP\\nPrevious experience in a ML or data scientist role with a large technology company',\n",
       " \"The Challenge:\\nThe Adobe Digital Video and Audio (DVA) Data Science team is seeking an experienced data science/analytics professional to help drive a culture of evidence-based decision-making. We support a fantastic product suite including Premiere Pro, Premiere Rush, After Effects, Audition, and Character Animator: products that are used by creative professionals and hobbyists around the world to create rich video, audio, and animation content across a variety of media channels.\\nWe are a diverse group of data professionals drawing from a broad spectrum of disciplines including applied math, quantitative finance, cognitive neuroscience, and software engineering. We believe that there isn't just one path to success in data science and look forward to what unique skills and experiences you can bring to the team.\\nAs a Data Science Analyst, you will partner with Product Managers and Software Engineers to make informed decisions about their products through insights gleaned from statistical analysis and experimentation. Are you passionate about statistical thinking and helping people improve the decisions they make? Are you self-motivated with strong interpersonal, communication, and collaboration skills? Are you a problem solver who generates actionable solutions through a combination of technical skills and business acumen? We invite you to apply today!\\nWhat You'll Do:\\nPerform regular ad-hoc data querying and analysis to better understand customer behaviors including acquisition, engagement, conversion, and retention\\nDesign, implement, and analyze results from A/B/n experiments\\nUse the appropriate statistical tools to analyze data and minimize bias\\nBuild dashboards to enable self-service data consumption for key collaborators\\nWork with engineering teams to understand existing product instrumentation and bridge gaps in data streams\\nPartner with data engineers to optimize scheduled jobs for regular reporting and build custom data sets for tailored needs\\nAdvocate for data-forward thinking within product management and engineering teams\\nWhat You'll Need to Succeed:\\n3+ years of professional experience in data science/analytics\\nBS or MS degree in an analytical discipline: statistics, applied mathematics, computer science, engineering, economics, etc.\\nExperience translating business questions into data analytics approaches\\nStrong proficiency in querying and manipulating large datasets using SQL-like languages (Hive, Spark, etc.)\\nExperience designing and analyzing A/B/n experiments, using appropriate statistical techniques to mitigate bias and interpret statistical significance\\nFamiliarity with descriptive and inferential statistics (e.g. t-test, chi-square, ANOVA, correlation, regression, etc.) to understand usage behaviors and generate hypotheses\\nExperience creating data visualizations and storytelling to effectively communicate analysis results to both technical and non-technical audiences\\nKnowledge of relevant tools in this field such as Hive, Tableau, Excel (Charting and PivotTables), and PowerBI\\nExperience with R and/or Python is a plus\\nAt Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists . You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely.\\nIf you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.\\nAdobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, religion, age , sexual orientation, gender identity, disability or veteran status.\",\n",
       " \"Summary\\nPosted: May 28, 2019\\nWeekly Hours: 40\\nRole Number: 200062665\\nMachine Learning has already made a deep impact in Apple’s front-line products, such as Siri. Machine learning engineer at Siri's Natural Language team are taking this a step further by redefining artificial intelligence, and creating groundbreaking technology for natural language understanding, machine learning, and conversational AI systems. Come join the Siri’s Natural Language team, and work with the people who created the intelligent assistant that helps millions of people get things done — just by asking.\\nKey Qualifications\\nStrong programming and software engineering skills (Java, C++, Scala, Python or equivalent)\\nExpertise in various facets of machine learning such as classification, feature engineering, information extraction, structured prediction, clustering, semi-supervised learning, topic modeling and ranking.\\nPrior experience with applying Big Data (MapReduce, Hadoop, Hive and/or Pig, Spark) tools to large quantities of textual data is a plus\\nHardworking, self-starter, proven ability to manage multiple projects to strict deadlines.\\nExcellent communication skills and ability to interact with all levels of engineers\\nDescription\\nThe goal of the Siri Machine Learning & Natural Language team is to take Siri to the next level of intelligence and accuracy using advanced Machine Learning and statistical techniques. Engineers in this team work on a wide spectrum of approaches to improving Siri. You would work on core machine learning algorithms and models that are part of Siri’s ability to understand and respond to requests. You would also work on building scalable distributed systems to deliver these models to Siri’s users. This position involves a wide variety of skills and innovation. This is a unique opportunity that sits at the cutting-edge of machine learning and software. You should be passionate about creating phenomenal products.\\nEducation & Experience\\nBachelor's in Computer Science or equivalent Masters or PhD preferred\\nAdditional Requirements\\nJava, C++, Machine Learning, Ranking, Conversational AI, Natural Language Understanding,\",\n",
       " \"Hi,\\nHope you are doing well.\\n**This is Nasim Shah from Tredence. We have an exciting opportunity for those who are passionate about Data Analytics. We are looking for Data Scientist in Seattle, WA. for our company (Tredence). Please find the Job Description below:\\nAbout Us:\\nTredence is a global analytics services and solutions company. Our capabilities range from Data Visualization, Data Management to Advanced analytics, Big Data and Machine Learning. Our uniqueness is in bringing the right mix of technology and business analytics to create sustainable white-box solutions that are transitioned to our clients at the end of the engagement. We do this cost effectively using a global execution model leveraging our clients' existing technology and data assets. We also come in with strong IP and pre-built analytics solutions in data mining, business intelligence and Big Data.\\n(Permanent Position) **\\nJob Responsibilities:\\nLead and manage independently the onsite-offshore relation, at the same time adding value to the client.\\nEngage with clients and business partners to understand their requirement, identify their challenges.\\nProvide clear business context and deliver actionable insights and recommendations, by designing analytical solutions and frameworks, in collaboration with the off-shore team in India.\\nPut together a solution architecture that is scalable, reusable, efficient and effective\\nPresent results, insights and recommendations to senior management with an emphasis on the “now what”, i.e. business impact.\\nBuild engaging rapport with client leadership through relevant conversations and genuine business recommendations that impact the growth and profitability of the organization.\\nBuild and grow the organization through pre-sales, operations and training enablement.\\n**Skills and Qualifications:\\n3 to 5 years of database experience with advanced SQL skills\\nStrong business skills, strong SQL, customer/marketing analytics experience.\\nSQL - Advanced HIVE SQL (incl. window functions, advanced aggregations etc)\\nPython Scripting (re-usable classes, functions)\\nStatistics – In addition to what we current have also add - understanding of test /control analysis, confidence intervals, bootstrap\\nAbility to research and manipulate complex and large data sets (both distributed and non-distributed)\\nAbility to solve complex business problem through a blend of logical and creative thinking – mental ambidexterity\\nStrong communication skills with excellent ability to synthesize complex information\\nWorking experience in retail, e-commerce, merchandising, marketing will be an added advantage bachelor’s in engineering, or Masters in Statistics / Economics / Business Administration\\nRegards\\n**Nasim Shah\\nAssociate Manager US Recruitment | TREDENCE | Connect the Dots | www.tredence.com\\nDirect: 408-831-3758\\nFollow us on | F* | t* | in\\nInc.5000 for the 3rd consecutive year | Economic Times Bootstrap Champ-2018\\nJob Type: Full-time\\nSalary: $100,000.00 to $130,000.00 /year\\nExperience:\\nData analytics: 3 years (Preferred)\\nEducation:\\nBachelor's (Preferred)\\nAdditional Compensation:\\nOther forms\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "env-unit4",
   "language": "python",
   "name": "env-unit4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
