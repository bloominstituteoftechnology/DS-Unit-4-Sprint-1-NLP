{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "##### Your Code Here #####\n",
    "jobs = pd.read_csv('./data/job_listings.csv')\n",
    "\n",
    "jobs.head()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      b\"<div><div>Job Requirements:</div><ul><li><p>...\n",
       "1      b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...\n",
       "2      b'<div><p>As a Data Scientist you will be work...\n",
       "3      b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "4      b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...\n",
       "                             ...                        \n",
       "421    b\"<b>About Us:</b><br/>\\nWant to be part of a ...\n",
       "422    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "423    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "424    b\"<p></p><div><p>SENIOR DATA SCIENTIST</p><p>\\...\n",
       "425    b'<div></div><div><div><div><div><p>Cerner Int...\n",
       "Name: description, Length: 426, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = jobs['description'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    b\"Job Requirements:\\nConceptual understanding ...\n",
       "1    b'Job Description\\n\\nAs a Data Scientist 1, yo...\n",
       "2    b'As a Data Scientist you will be working on c...\n",
       "3    b'$4,969 - $6,756 a monthContractUnder the gen...\n",
       "4    b'Location: USA \\xe2\\x80\\x93 multiple location...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "# NLP Libraries\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "def cleaning(text):\n",
    "    clean = re.sub(r\"[.,!?']\", r\"/1\", text)\n",
    "    clean = re.sub(\"[^a-zA-Z]+\", r\" \", text)\n",
    "    clean = clean.lower()\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b job requirements nconceptual understanding in machine learning models like nai xc xa ve bayes k means svm apriori linear logistic regression neural random forests decision trees k nn along with hands on experience in at least of them nintermediate to expert level coding skills in python r ability to write functions clean and efficient data manipulation are mandatory for this role nexposure to packages like numpy scipy pandas matplotlib etc in python or ggplot dplyr tidyr in r nability to communicate model findings to both technical and non technical stake holders nhands on experience in sql hive or similar programming language nmust show past work via github kaggle or any other published article nmaster s degree in statistics mathematics computer science or any other quant specific field napply now '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a cleaner version of the text column\n",
    "cleaner = clean_text.apply(cleaning)\n",
    "cleaner[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      b job requirements nconceptual understanding i...\n",
       "1      b job description n nas a data scientist you w...\n",
       "2      b as a data scientist you will be working on c...\n",
       "3      b a monthcontractunder the general supervision...\n",
       "4      b location usa xe x x multiple locations n yea...\n",
       "                             ...                        \n",
       "421    b about us nwant to be part of a fantastic and...\n",
       "422    b internshipat uber we ignite opportunity by s...\n",
       "423    b a yeara million people a year die in car col...\n",
       "424    b senior data scientist njob description n nab...\n",
       "425    b cerner intelligence is a new innovative orga...\n",
       "Name: description, Length: 426, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['b', 'k', 'nn', 'xc', 'xa', 'x', 've', 's', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(cleaner, batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())\n",
    "   \n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "cleanest = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'requirements',\n",
       " 'nconceptual',\n",
       " 'understanding',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'models',\n",
       " 'like',\n",
       " 'nai',\n",
       " 'bayes',\n",
       " 'means',\n",
       " 'svm',\n",
       " 'apriori',\n",
       " 'linear',\n",
       " 'logistic',\n",
       " 'regression',\n",
       " 'neural',\n",
       " 'random',\n",
       " 'forests',\n",
       " 'decision',\n",
       " 'trees',\n",
       " 'hands',\n",
       " 'experience',\n",
       " 'nintermediate',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'coding',\n",
       " 'skills',\n",
       " 'python',\n",
       " 'r',\n",
       " 'ability',\n",
       " 'write',\n",
       " 'functions',\n",
       " 'clean',\n",
       " 'efficient',\n",
       " 'data',\n",
       " 'manipulation',\n",
       " 'mandatory',\n",
       " 'role',\n",
       " 'nexposure',\n",
       " 'packages',\n",
       " 'like',\n",
       " 'numpy',\n",
       " 'scipy',\n",
       " 'pandas',\n",
       " 'matplotlib',\n",
       " 'etc',\n",
       " 'python',\n",
       " 'ggplot',\n",
       " 'dplyr',\n",
       " 'tidyr',\n",
       " 'r',\n",
       " 'nability',\n",
       " 'communicate',\n",
       " 'model',\n",
       " 'findings',\n",
       " 'technical',\n",
       " 'non',\n",
       " 'technical',\n",
       " 'stake',\n",
       " 'holders',\n",
       " 'nhands',\n",
       " 'experience',\n",
       " 'sql',\n",
       " 'hive',\n",
       " 'similar',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'nmust',\n",
       " 'past',\n",
       " 'work',\n",
       " 'github',\n",
       " 'kaggle',\n",
       " 'published',\n",
       " 'article',\n",
       " 'nmaster',\n",
       " 'degree',\n",
       " 'statistics',\n",
       " 'mathematics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'quant',\n",
       " 'specific',\n",
       " 'field',\n",
       " 'napply']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Tokenizer(Vocab vocab, rules=None, prefix_search=None, suffix_search=None, infix_finditer=None, token_match=None)\n",
       "Segment text, and create Doc objects with the discovered segment\n",
       "    boundaries.\n",
       "\n",
       "    DOCS: https://spacy.io/api/tokenizer\n",
       "    \n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Create a `Tokenizer`, to create `Doc` objects given unicode text.\n",
       "\n",
       "vocab (Vocab): A storage container for lexical types.\n",
       "rules (dict): Exceptions and special-cases for the tokenizer.\n",
       "prefix_search (callable): A function matching the signature of\n",
       "    `re.compile(string).search` to match prefixes.\n",
       "suffix_search (callable): A function matching the signature of\n",
       "    `re.compile(string).search` to match suffixes.\n",
       "`infix_finditer` (callable): A function matching the signature of\n",
       "    `re.compile(string).finditer` to find infixes.\n",
       "token_match (callable): A boolean function matching strings to be\n",
       "    recognised as tokens.\n",
       "RETURNS (Tokenizer): The newly constructed object.\n",
       "\n",
       "EXAMPLE:\n",
       "    >>> tokenizer = Tokenizer(nlp.vocab)\n",
       "    >>> tokenizer = English().Defaults.create_tokenizer(nlp)\n",
       "\n",
       "DOCS: https://spacy.io/api/tokenizer#init\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\timro\\anaconda3\\envs\\nlp-s1\\lib\\site-packages\\spacy\\tokenizer.cp37-win_amd64.pyd\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tokenizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "#adding to the stop words \n",
    "from sklearn.feature_extraction import text \n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(['b', 'k', 'nn', 'xc', 'xa', 'x', 've', 's', 'b', 'xe'])\n",
    "\n",
    "vect = CountVectorizer(stop_words=stop_words, max_features=1000)\n",
    "\n",
    "#Learn our Vocab\n",
    "vect.fit(cleaner)\n",
    "\n",
    "# Get sparse dtm\n",
    "dtm = vect.transform(cleaner)\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>accommodations</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieve</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>www</th>\n",
       "      <th>xae</th>\n",
       "      <th>xb</th>\n",
       "      <th>xbb</th>\n",
       "      <th>xef</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abilities  ability  able  academic  access  accommodation  \\\n",
       "0            0        1     0         0       0              0   \n",
       "1            0        1     0         0       0              0   \n",
       "2            0        0     0         0       0              0   \n",
       "3            0        0     0         0       0              0   \n",
       "4            0        0     0         0       0              0   \n",
       "..         ...      ...   ...       ...     ...            ...   \n",
       "421          0        2     0         0       0              0   \n",
       "422          0        0     0         0       0              0   \n",
       "423          0        0     0         0       0              0   \n",
       "424          0        0     2         0       0              0   \n",
       "425          0        0     0         0       0              0   \n",
       "\n",
       "     accommodations  accuracy  achieve  acquisition  ...  writing  written  \\\n",
       "0                 0         0        0            0  ...        0        0   \n",
       "1                 0         1        0            0  ...        2        1   \n",
       "2                 0         0        0            0  ...        0        0   \n",
       "3                 0         0        0            0  ...        0        0   \n",
       "4                 0         0        0            0  ...        0        0   \n",
       "..              ...       ...      ...          ...  ...      ...      ...   \n",
       "421               0         0        0            0  ...        0        0   \n",
       "422               0         0        0            0  ...        1        0   \n",
       "423               0         0        0            0  ...        1        0   \n",
       "424               0         0        0            0  ...        0        0   \n",
       "425               0         0        1            0  ...        0        0   \n",
       "\n",
       "     www  xae  xb  xbb  xef  year  years  york  \n",
       "0      0    0   0    0    0     0      0     0  \n",
       "1      0    0   0    0    0     1      0     0  \n",
       "2      0    0   0    0    0     0      0     0  \n",
       "3      0    0   0    0    0     1      0     0  \n",
       "4      0    0   0    0    0     0      1     0  \n",
       "..   ...  ...  ..  ...  ...   ...    ...   ...  \n",
       "421    1    0   0    0    0     2      3     1  \n",
       "422    0    0   0    0    0     0      0     0  \n",
       "423    0    0   0    0    0     1      0     0  \n",
       "424    0    0   0    0    0     0      1     0  \n",
       "425    0    0   0    0    0     0      2     0  \n",
       "\n",
       "[426 rows x 1000 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAKrCAYAAADlINv4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiE0lEQVR4nO3de/xtdV3n8fdHwLyDyhkfBtRxlMkhe3QRUbMaRwtRS2hS0y5iYzGNljUzVjg1Wl4m1MrJytRRBirzbmpYGV5IxQscREAg9IzgKFmSoGU+vKDf+WN/D2wPv/P5ncvvcuQ8n4/H7/Fbe+21115r77X3fv3WXnv/aowRAABgZbfY7AUAAID9mWAGAICGYAYAgIZgBgCAhmAGAIDGwZu9AJ3DDz98bN26dbMXAwCAm7kLLrjgH8cYW1Y6b78O5q1bt2bbtm2bvRgAANzMVdXHdnWeQzIAAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgcfBmL8D+auupb97sRdhnV5328M1eBACAr3v2MAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBjt4O5qg6qqgur6qx5+m5V9f6q2l5Vr6qqW87x3zBPb5/nb12ax1Pn+Cuq6iFrvjYAALDG9mQP8y8kuXzp9HOSPH+McY8k1yV5whz/hCTXzfHPn9Olqo5J8pgk35rkhCQvrKqD9m3xAQBgfe1WMFfVkUkenuSl83QleVCS185Jzkxy0hw+cZ7OPP/Bc/oTk7xyjPHFMcaVSbYnOW4N1gEAANbN7u5h/l9JfjnJV+fpOyf5zBjj+nn6E0mOmMNHJPl4kszzPzunv2H8Cpe5QVWdUlXbqmrbNddcs/trAgAA62DVYK6qH0zyqTHGBRuwPBljvGSMcewY49gtW7ZsxFUCAMAuHbwb0zwgySOq6mFJbpXkDkl+N8lhVXXw3It8ZJKr5/RXJzkqySeq6uAkhyb59NL4HZYvAwAA+6VV9zCPMZ46xjhyjLE1iw/tvX2M8eNJ3pHkkXOyk5O8cQ6/aZ7OPP/tY4wxxz9mfovG3ZIcneS8NVsTAABYB7uzh3lXfiXJK6vqWUkuTPKyOf5lSf64qrYnuTaLyM4Y49KqenWSy5Jcn+RJY4yv7MP1AwDAutujYB5jnJPknDn80azwLRdjjC8kedQuLv/sJM/e04UEAIDN4j/9AQBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAQzADAEBDMAMAQGPVYK6qW1XVeVV1UVVdWlW/McffrareX1Xbq+pVVXXLOf4b5unt8/ytS/N66hx/RVU9ZN3WCgAA1sju7GH+YpIHjTG+Pcl3JDmhqu6X5DlJnj/GuEeS65I8YU7/hCTXzfHPn9Olqo5J8pgk35rkhCQvrKqD1nBdAABgza0azGPhc/PkIfNnJHlQktfO8WcmOWkOnzhPZ57/4KqqOf6VY4wvjjGuTLI9yXFrsRIAALBedusY5qo6qKo+mORTSc5O8n+TfGaMcf2c5BNJjpjDRyT5eJLM8z+b5M7L41e4DAAA7Jd2K5jHGF8ZY3xHkiOz2Ct8z/VaoKo6paq2VdW2a665Zr2uBgAAdssefUvGGOMzSd6R5P5JDquqg+dZRya5eg5fneSoJJnnH5rk08vjV7jM8nW8ZIxx7Bjj2C1btuzJ4gEAwJrbnW/J2FJVh83hWyf5gSSXZxHOj5yTnZzkjXP4TfN05vlvH2OMOf4x81s07pbk6CTnrdF6AADAujh49Uly1yRnzm+0uEWSV48xzqqqy5K8sqqeleTCJC+b078syR9X1fYk12bxzRgZY1xaVa9OclmS65M8aYzxlbVdHQAAWFurBvMY4+Ik37nC+I9mhW+5GGN8IcmjdjGvZyd59p4vJgAAbA7/6Q8AABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqCGQAAGoIZAAAaghkAABqrBnNVHVVV76iqy6rq0qr6hTn+TlV1dlV9ZP6+4xxfVfWCqtpeVRdX1XctzevkOf1Hqurk9VstAABYG7uzh/n6JP9tjHFMkvsleVJVHZPk1CRvG2McneRt83SSPDTJ0fPnlCR/mCwCO8nTk9w3yXFJnr4jsgEAYH+1ajCPMT45xvjAHP7nJJcnOSLJiUnOnJOdmeSkOXxikj8aC+9LclhV3TXJQ5KcPca4doxxXZKzk5ywlisDAABrbY+OYa6qrUm+M8n7k9xljPHJedbfJ7nLHD4iyceXLvaJOW5X43e+jlOqaltVbbvmmmv2ZPEAAGDN7XYwV9XtkrwuyS+OMf5p+bwxxkgy1mKBxhgvGWMcO8Y4dsuWLWsxSwAA2Gu7FcxVdUgWsfzyMcbr5+h/mIdaZP7+1Bx/dZKjli5+5By3q/EAALDf2p1vyagkL0ty+Rjjd5bOelOSHd90cXKSNy6Nf9z8toz7JfnsPHTjLUmOr6o7zg/7HT/HAQDAfuvg3ZjmAUl+MsklVfXBOe6/Jzktyaur6glJPpbk0fO8v0jysCTbk3w+yU8lyRjj2qp6ZpLz53TPGGNcuxYrAQAA62XVYB5jvDtJ7eLsB68w/UjypF3M6/Qkp+/JAgIAwGbyn/4AAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgIZgBAKAhmAEAoCGYAQCgcfBmLwD7l62nvnmzF2FNXHXawzd7EQCAmwl7mAEAoCGYAQCgIZgBAKAhmAEAoOFDfxAfdgQAds0eZgAAaAhmAABoCGYAAGgIZgAAaAhmAABoCGYAAGgIZgAAaAhmAABoCGYAAGgIZgAAaAhmAABoCGYAAGgIZgAAaAhmAABoCGYAAGgIZgAAaAhmAABoCGYAAGgIZgAAaAhmAABoCGYAAGgIZgAAaAhmAABoCGYAAGisGsxVdXpVfaqqPrQ07k5VdXZVfWT+vuMcX1X1gqraXlUXV9V3LV3m5Dn9R6rq5PVZHQAAWFu7s4f5jCQn7DTu1CRvG2McneRt83SSPDTJ0fPnlCR/mCwCO8nTk9w3yXFJnr4jsgEAYH+2ajCPMd6Z5NqdRp+Y5Mw5fGaSk5bG/9FYeF+Sw6rqrkkekuTsMca1Y4zrkpydm0Y4AADsd/b2GOa7jDE+OYf/Psld5vARST6+NN0n5rhdjb+JqjqlqrZV1bZrrrlmLxcPAADWxj5/6G+MMZKMNViWHfN7yRjj2DHGsVu2bFmr2QIAwF7Z22D+h3moRebvT83xVyc5amm6I+e4XY0HAID92t4G85uS7Pimi5OTvHFp/OPmt2XcL8ln56Ebb0lyfFXdcX7Y7/g5DgAA9msHrzZBVb0iyQOTHF5Vn8ji2y5OS/LqqnpCko8lefSc/C+SPCzJ9iSfT/JTSTLGuLaqnpnk/DndM8YYO3+QENhgW09982Yvwpq46rSH79H0B+p6A7B3Vg3mMcZjd3HWg1eYdiR50i7mc3qS0/do6QAAYJP5T38AANBYdQ8zADcPDkUB2Dv2MAMAQEMwAwBAQzADAEBDMAMAQEMwAwBAw7dkAHCz5ttBgH1lDzMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQO3uwFAADWx9ZT37zZi7DPrjrt4Zu9CGAPMwAAdAQzAAA0BDMAADQEMwAANAQzAAA0fEsGAHCz4ttBWGuCGQDgZsAfCuvHIRkAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0BDMAADQEMwAANAQzAAA0NjwYK6qE6rqiqraXlWnbvT1AwDAntjQYK6qg5L8QZKHJjkmyWOr6piNXAYAANgTG72H+bgk28cYHx1jfCnJK5OcuMHLAAAAu63GGBt3ZVWPTHLCGOOn5+mfTHLfMcbPLU1zSpJT5slvSXLFhi3gxjs8yT9u9kJsAut9YLHeBxbrfWA5UNc7OXDX/ea83t88xtiy0hkHb/SSrGaM8ZIkL9ns5dgIVbVtjHHsZi/HRrPeBxbrfWCx3geWA3W9kwN33Q/U9d7oQzKuTnLU0ukj5zgAANgvbXQwn5/k6Kq6W1XdMsljkrxpg5cBAAB224YekjHGuL6qfi7JW5IclOT0McalG7kM+5kD4tCTFVjvA4v1PrBY7wPLgbreyYG77gfkem/oh/4AAODrjf/0BwAADcEMAAANwbzOqurXq+opzfknHYj/7bCqnlFV37/Zy7ErVbW1qj60j/P4xqp67Vot081NVV1VVYdv9nLsjqo6rKqeuNnLsT+oqmOr6gWbvRxroao+twHX8bNV9bj1vp6NVFWPr6rf341pvnHp9Etvbq91u3oOq6pHVNWpm7FM62l37vddXO5mcXvsd9/DfAA6KclZSS7b5OXYMFV10BjjaZu9HOttjPF3SR652cuxP6qqgzZ7GfbQYUmemOSFm7wcm26MsS3Jts1ejv3JfE77ykrnjTFetNHLs594fJIPJfm7JNnxD8sOBGOMN8U3gN3g5nJ72MO8DqrqV6vqw1X17iz+W2Gq6meq6vyquqiqXldVt6mq707yiCTPq6oPVtXdV5puA5f7J6rqvLksL66q+1bVxVV1q6q6bVVdWlX3qqoHVtU7q+rNVXVFVb2oqm4x53F8Vb23qj5QVa+pqtvN8VdV1XOq6gNJHlVVZ8z//JiqundV/U1VXVBVb6mqu87x58zLnDdvz++d4w+qqt+qqg/N5fv5bj774OCqenlVXV5Vr5332Q17FOaetnPm8L+bt9sHq+rCqrr98l7q+Zf566vqr6rqI1X13KXbfVe32WlVddlcx9+a4x411/uiqnrnPq7fXqmqX6qqJ8/h51fV2+fwg+bt9diqumQu53OWLve5qvrtqrooyf2Xxt+6qv6yqn5mw1dm952W5O7z/n3evA3On/fNb+yYqKreMLe/S2vxX0t3jP/cvNylVfXWqjpubt8frapHbMoa7WQ+xt88t60PVdWPVtV9quo9c9x5c7t+YFWdtXSZ0+d5F1bViXN8t72fMLf1i6rqbd18Nnj99+Y+vWF7nqefPdfrfVV1lzndDe8y1q6f025TVa+ej/c/q6r3V9W6/GOIldanWfYfmsty4dxu77LTvG5fVVdW1SHz9B3m6UclOTbJy+dj5tZz3Y+d0620DdzkOXSN13trVf1tLV57PlyL56rvr6pz5zZ63Px577z+91TVjtfvFV9zpp+f63JJVd1zTn/Dnth5fS+Y8/tozde9ed6K29x62KD7/ZCqenLd+Lr1yhVuj01/DdtrYww/a/iT5N5JLklymyR3SLI9yVOS3Hlpmmcl+fk5fEaSRy6dt+J0G7Dc/zbJnyc5ZJ5+YZLHzWX4rSR/kOSp87wHJvlCkn+dxdcDnp3FntTDk7wzyW3ndL+S5Glz+Kokv7x0fWfMyxyS5D1JtszxP5rF1w0myTlJfnsOPyzJW+fwf07y2iQHz9N36uazl7fH1iQjyQPm6dPn/XhVksPnuGOTnDOH/3xp2ttl8e7N1iQfmuMen+SjSQ5NcqskH8vin/iseJsluXMW/xZ+xzfZHDZ/X5LkiOVxm7CN3y/Ja+bwu5KcN2//p8+f/5dky7wN3p7kpDntSPLopflcNW+jtyZ53Gasyx5uDzvuy+Oz+FqlymKnw1lJvm/Htjh/3zqLvWt3Xlr3h87hP0vy1/M2+/YkH9zs9ZvL9SNJ/vfS6UPnNnufefoO8z59YJKz5rj/meQndmyPST6c5LbN9r4lyceT3G2n22vF+WzAOn9uH+/T5e15JPmhOfzcJL82h389yVPm8DlZ+TntKUlePIfvleT6JMeu0zrfZH2aZb9jbnwO+umlZX98kt+fw/8nNz7GT1ma5pzlddhxutkGbvIcusbrvXXert827+MLsnheryQnJnlD5jY+p//+JK+bwzd5zZm/r8qNr+VPTPLSFW6fM5K8Zl7nMUm2r7bNfZ3f73+X5Bt2PJZXuNymv4bt7Y9DMtbe9yb5szHG55Okqna8DXGvqnpWFi8Gt8viu6hXsrvTrbUHZxH751dVsnhQfSrJM7L4hzNfSPLkpenPG2N8NEmq6hVJvmdOc0ySc+c8bpnkvUuXedUK1/stWbxAnD0vc1CSTy6d//r5+4IsnvCSxRPZi8YY1yfJGOPaqrrXKvPZGx8fY5w7h/8kX7v+Ozs3ye9U1cuTvH6M8Ym5HMveNsb4bJJU1WVJvjmL+3ml2+yzWdyeL6vF3ryzlq7njKp6dW68bTbaBUnuXVV3SPLFJB/I4oXwe7N40TtnjHFNkszb4/uyeDH6SpLX7TSvNyZ57hjj5Ruz6Gvi+Plz4Tx9uyRHZ/GHz5Or6ofn+KPm+E8n+VKSv5rjL0nyxTHGl6vqkty4XW+2S5L8di3eFTgryWeSfHKMcX6SjDH+KUl22q6PT/KIuvFzGrdK8k1zeKXt/Y5J3jnGuHLO89pV5nP5Gq/jruzNfbrz9vyl3Pg4vSDJD+ziulZ6TvueJL+bJGOMD1XVxfuwLqtZaX12texHJnlVLd6tu2WSK1eY30uT/HIWj/GfSrLaO0X3y8rbwE2eQ/dwvXbHlWOMS5Kkqi7NYhsdS4/DQ5OcWVVHZxGTh8zL3eQ1Z2mey/fnf9jF9b5hjPHVJJct7a3ttrn1sFH3+8VZvLPwhnnezvaH17C9Ipg3zhlZ/DV2UVU9Pou9NPsy3VqrJGeOMZ76NSMXD5jbZfHEcask/zLP2vkLvMecx9ljjMfu4jr+ZYVxleTSMcb9VzgvWQRZsnhx6rbX1eazN1Zax+tz46FMt7rhjDFOq6o3Z7HX6NyqekgWwbvsi0vDO9Znl7dZVR2XxR8yj0zyc0keNMb42aq6b5KHJ7mgqu49xvj03q7g3pihd2UWew3ek8UT5L9Pco8s9rjcexcX/cK46XGe5yY5oar+dMxdDl8HKslvjjFe/DUjqx6YxQvr/ccYn6/F4To7tpEvL63fVzO3hTHGV6tqv3geHmN8uKq+K4tt+FlZvDuwmkryI2OMK75m5GIbXWl736P5bKC9uU933p6X7+NufXf3OW3NNeuzq2X/vSS/M8Z407zsr+88zzHGufNwhwcmOWiMsVcfll7pOXSM8bd7M6/G8jb51aXTX81inZ+Z5B1jjB+uqq1Z7BXf3Xnuzn2eLLa1Hb9vss2thw2+3x+exU6SH0ryq1X1bTtdbtNfw/aWY5jX3juTnFSLY7Zun8VGkyS3T/LJeczPjy9N/8/zvKwy3Xp7W5JHVtW/SpKqulNVfXOSFyf5H0lenuQ5S9MfV4t/cX6LLA5/eHeS9yV5QFXdY87jtlX1b1a53iuSbKmq+8/LHFJV37rKZc5O8p92hEZV3Wkv57Oab9oxvyQ/lsU6XpUbg/BHdkxYVXcfY1wyxnhOFnvk77mb17HibVaL45gPHWP8RZL/ksVb9zuu5/1j8aHJa7LYU7AZ3pXF28jvnMM/m8WekvOS/LuqOrwWH+x7bJK/aebztCTXZXHIz/5s+XH6liT/sW481vyI+bg5NMl18wXpnlnsSfu6UYtvNPj8GONPkjwvyX2T3LWq7jPPv/0Kcf+WLI7hrDnNd65yNe9L8n1Vdbc5/Z32cj5rbbPv03OTPHpe9zFZHDawHvZ0fQ5NcvUcPrmZ7o+S/GkWb9PvsPNr2w4rbgP78By6lpbX9/FL41d6zdlXu9rm1sOG3O+zB44aY7wji8MLD81ih9sN9qPXsD0mmNfYGOMDWRx6cFGSv8zigZ8sovP9WTwxLv/V/Mokv1SLg+vv3ky33st9WZJfS/LX8+3As7N4oHx5jPGnWXzo6T5V9aB5kfOT/H4Wb5lemcVhKNdk8STzijmP92aVJ70xxpey2IP6nFp8eOaDSb57lcV9aRbHyV48L/Njezmf1VyR5ElVdXkWbyX/YZLfSPK7VbUti7/Id/jFmh8ISfLlLO77VTW32e2TnDXHvTvJf50XeV7ND9RlsXf3on1cx731riR3TfLeMcY/ZLE3/V1jjE8mOTXJO+ayXTDGeOMq8/qFJLeupQ+G7W/mHpBz5+3+A1m8SLx3vpX72izur7/K4oOil2fxeHnfZi3vXvq2JOdV1QezOBb9aVn8Mfx78zF1dpbeVZmemcW7TxfX4i3uZ3ZXMLf3U5K8fs5zx2FaezSftTbG+Ots7n36wiz+4L8si737l2ZxWNZa29P1+fUkr6mqC5L8YzPdy7N4jnzF0rgzkryo5of+doxstoG9eg5dY89N8ptVdWG+dm/xTV5z9vWKmm1uPWzU/X5Qkj+Z63NhkheMMT6z02X2l9ewPeZfY7PH5lswTxlj/OAmLwrA1735bswhY4wvzB0nb03yLXNHwH6vFt/8cOIY4yc3e1nYOAfa/b5fHDsHAAew2yR5xzwUr5I88esoln8vyUOzOPaYA8SBeL/bwwwAAA3HMAMAQEMwAwBAQzADAEBDMAMAQEMwAwBA4/8D5mZOGcY5MNYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "viz = dtm.sum().sort_values(ascending=False).head(10)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.bar(viz.index, viz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'squarify' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-4efc0617d654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msquarify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwc_top20\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pct_total'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwc_top20\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.8\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'squarify' is not defined"
     ]
    }
   ],
   "source": [
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "#tfidf = TfidfVectorizer(max_features=1000) to compare to above\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Similiar to fit_predict\n",
    "dtm = tfidf.fit_transform(cleaner)\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    \n",
    "    doc = nlp(document)\n",
    "    \n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunning Parameters\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,1),\n",
    "                        max_df=.97,\n",
    "                        min_df=3,\n",
    "                        tokenizer=tokenize)\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "dtm = tfidf.fit_transform(cleaner) # Similiar to fit_predict\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal = [\"\"\"\n",
    "We are looking to hire a data scientist here in denver austin or philadelphia the position has the option to be remote\n",
    "proficiency in python sql machine learning datasets mongodb docker postgressql pandas python important natural language processing \n",
    "flexible schedule great benefits and insurance paid vacation family leave\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding similar results to my ideal job\n",
    "new = tfidf.transform(ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner[325]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner[254]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "NLP-S1 (Python3)",
   "language": "python",
   "name": "nlp-s1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
