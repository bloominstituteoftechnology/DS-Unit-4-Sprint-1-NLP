{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOMBkFKn6uEK"
   },
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "We talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Discovering the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "* Part 0: Warm-Up\n",
    "* Part 1: Describe how an LDA Model works\n",
    "* Part 2: Estimate an LDA Model with Gensim\n",
    "* Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxH0cRGX6uEL"
   },
   "source": [
    "# Part 0: TfidfVectorizer\n",
    "First we use sklearn TfidfVectorizer() to create a doc term matrix, dtm. And use that with a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnyNg8sQ6uEL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "boKWVkRz6uEO",
    "outputId": "2d3f688e-8cc8-44a4-9629-7c58285e1323"
   },
   "outputs": [],
   "source": [
    "# this is the dataset that we'll be using for topic modeling as well \n",
    "# RUNTIME ISSUE ADVICE: \n",
    "# IF YOUR CODE TAKES TOO LONG TO RUN, TRY TAKING A RANDOM SUBSAMPLE OF THE DATA. GET EVERYTHING TO RUN ON A SMALL DATASET, ONCE THAT WORKS INCREASE THE SIZE OF THE DATASET\n",
    "# ALTERNATIVELY, YOU COULD WORK WITH 3 OR 4 TOPICS INSTEAD OF ALL 20\n",
    "\n",
    "# for simplicity, I'm going to only work with 3 topics \n",
    "categories = [\"comp.sys.mac.hardware\", \n",
    "              \"comp.graphics\", \n",
    "              \"sci.space\"]\n",
    "data = fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hPpukADi7Ofv",
    "outputId": "e7687121-ebeb-4b2b-af87-f87228e7fb59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'comp.sys.mac.hardware', 'sci.space']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respectively associated with target labels\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "JbVoIoMm8HbR",
    "outputId": "c8d0bd77-f656-4cc1-d65f-54020ee5587b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: ayr1@cunixa.cc.columbia.edu (Amir Y Rosenblatt)\\nSubject: Power Supplies for Mac 512's\\nSummary: I need them\\nNntp-Posting-Host: cunixa.cc.columbia.edu\\nReply-To: ayr1@cunixa.cc.columbia.edu (Amir Y Rosenblatt)\\nOrganization: Columbia University\\nLines: 13\\n\\n\\nI thnik i'll be able to pick up  a piar of Mac 512K's for nothing, but\\ntheir power supplies are dead.  Anyone know where I can pick up a pair\\nof refurbished PS's for cheap (preferably mail order).\\nYes, I do have uses planned fior them.  One will be sold to a friend who\\njust needs a terminal to connect via modem to his e-mail account.\\nThe other will be used by me as a net client to run my downloads and/or\\nprinting.\\n  \\nAlso, what is the latest system software usable with these suckers?\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-39zg9a6uEQ"
   },
   "source": [
    "### GridSearch on Just Classifier\n",
    "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q3NmHEo6uEQ"
   },
   "outputs": [],
   "source": [
    "v1 = TfidfVectorizer(stop_words=\"english\")\n",
    "X = data['data'] # raw text data\n",
    "X_train = v1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 1755)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (1755, 28321))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), X_train.shape # doc-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LX3a4nUI6uES"
   },
   "outputs": [],
   "source": [
    "# parameter dict\n",
    "p1 = {\n",
    "    'n_estimators':[10,20],\n",
    "    'max_depth': [None, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "7OfA7KNQ6uEU",
    "outputId": "a00f5e73-6373-4bf0-bb79-11fb2de865af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 7], 'n_estimators': [10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "gs1 = GridSearchCV(clf, p1, cv=5,n_jobs=-1, verbose=1)\n",
    "gs1.fit(X_train, data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gDkMaXvG83Zt",
    "outputId": "f3a55d86-209d-47b2-dd44-c23532ffcf2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28321)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_from_website = [\"I like medical science and doctors and good health.\"]\n",
    "test_sample = v1.transform(user_data_from_website)\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BLgsZtKJ8o01",
    "outputId": "f0cb136d-b00a-44af-a0f9-7eb5f8586bf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gs1.predict(test_sample)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vLGkB8Vz9Otq",
    "outputId": "b0f83ac4-2a4d-4d84-b94d-73328a86a7f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.graphics'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names'][pred[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdVTuXKl6uEZ"
   },
   "source": [
    "### GridSearch with BOTH the Vectoizer & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "colab_type": "code",
    "id": "97TjUtoI6uEZ",
    "outputId": "207e8cb3-5e82-4077-ac25-2406d21c3607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acce...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': [None, 7],\n",
       "                         'clf__n_estimators': [10, 20],\n",
       "                         'vect__max_features': [1000, 5000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "v2 = TfidfVectorizer()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', v2),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "p2 = {\n",
    "    'vect__max_features':[1000,5000],\n",
    "    'clf__n_estimators':[10,20],\n",
    "    'clf__max_depth': [None, 7]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe, p2, cv=5,n_jobs=-1, verbose=1)\n",
    "gs2.fit(data['data'], data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdIE67Us6uEc"
   },
   "outputs": [],
   "source": [
    "pred = gs2.predict(user_data_from_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xhcb5G0W-Dch",
    "outputId": "ead7a46e-5c4e-401d-d9ca-89b6f42ef85d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.graphics'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names'][pred[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2R2ACd36uEd"
   },
   "source": [
    "Advantages to using GS with the Pipe:\n",
    "* Allows us to make predictions on raw text increasing reproducibility.\n",
    "* Allows us to tune the parameters of the vectorizer along side the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbZjG6U86uEe"
   },
   "source": [
    "# Part 1: Creating dictionary (id2word) and dtm(corpus) with gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n",
    "\n",
    "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/)\n",
    "\n",
    "[Topic Modeling with Gensim](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yPIlE_IeF0cX",
    "outputId": "11cab929-9e79-43fd-fee7-08f42113cf24"
   },
   "outputs": [],
   "source": [
    "# # Download spacy model\n",
    "# alternative way to download the pre-trained model\n",
    "# import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qapChu_UGBFc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# these are all gensim imports \n",
    "# check out the gensim docs: https://radimrehurek.com/gensim/\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# we use spacy to load in the word2vec model \n",
    "import spacy\n",
    "\n",
    "# all these imports are for the data viz tool that we use to look at the LDA results and manually determine the topics in our dataset \n",
    "# check out the docs: https://pyldavis.readthedocs.io/en/latest/readme.html\n",
    "# the docs also have an EXAMPLE NOTEBOOK that is more detailed about this data viz tool than our lecture notebook: https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "qaMsy1XAGLxc",
    "outputId": "0a981642-93ef-4a95-c6a2-c5ca7c5151e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# load text data into dataframe because pandas dataframes are our prefered way to perform data manipulations \n",
    "df = pd.DataFrame({\n",
    "    'content': data['data'],\n",
    "    'target': data['target'],\n",
    "    'target_names': [data['target_names'][i] for i in data['target']]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: meharg@kits.sfu.ca (Gersham William Meha...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: sheaffer@netcom.com (Robert Sheaffer)\\nS...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: winstead@faraday.ece.cmu.edu (Charles Ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: ralph.buttigieg@f635.n713.z3.fido.zeta.o...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: ednobles@sacam.OREN.ORTN.EDU (Edward d N...</td>\n",
       "      <td>0</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  From: meharg@kits.sfu.ca (Gersham William Meha...       1   \n",
       "1  From: sheaffer@netcom.com (Robert Sheaffer)\\nS...       2   \n",
       "2  From: winstead@faraday.ece.cmu.edu (Charles Ho...       1   \n",
       "3  From: ralph.buttigieg@f635.n713.z3.fido.zeta.o...       2   \n",
       "4  From: ednobles@sacam.OREN.ORTN.EDU (Edward d N...       0   \n",
       "\n",
       "            target_names  \n",
       "0  comp.sys.mac.hardware  \n",
       "1              sci.space  \n",
       "2  comp.sys.mac.hardware  \n",
       "3              sci.space  \n",
       "4          comp.graphics  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some data cleaning before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<ipython-input-48-5c5193c51fbc>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "  re.sub('\\S+@\\S+', '', text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vnrn  23hfh  devnvn'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"vnrn rnv@ejnr 23hfh evn@vn.ven devnvn\"\n",
    "re.sub('\\S+@\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "na2bkOcFGter",
    "outputId": "6c8d1a19-3719-4e28-d8c6-d3202fdd6257"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# my advise is to create a function called clean_data \n",
    "# where all cleaning transformations happen in that function\n",
    "# and you only have to call the .apply() method once\n",
    "\n",
    "def clean_data(text):\n",
    "    # Remove whitespace\n",
    "    text = text.strip()\n",
    "    # Remove Emails. \\S: non-space character, + is match one or more\n",
    "    # default is count=0 and replaces as many non overlapping match as it finds\n",
    "    text = re.sub(r'From: \\S+@\\S+', '', text, count=0)    \n",
    "    # Replace new line and other characters with single space. \\s: space character\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^0-9 a-zA-Z]+', '', text)\n",
    "    return text \n",
    "\n",
    "df['content'] = df['content'].apply(lambda row: clean_data(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gersham William Meharg Subject Re Centris 610 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Sheaffer Subject Re Astronomy Program O...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles Holden Winstead Subject ftp site for R...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ralph Buttigieg Subject Why not give 1 billion...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edward d Nobles Subject windows imagine Organi...</td>\n",
       "      <td>0</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  Gersham William Meharg Subject Re Centris 610 ...       1   \n",
       "1  Robert Sheaffer Subject Re Astronomy Program O...       2   \n",
       "2  Charles Holden Winstead Subject ftp site for R...       1   \n",
       "3  Ralph Buttigieg Subject Why not give 1 billion...       2   \n",
       "4  Edward d Nobles Subject windows imagine Organi...       0   \n",
       "\n",
       "            target_names  \n",
       "0  comp.sys.mac.hardware  \n",
       "1              sci.space  \n",
       "2  comp.sys.mac.hardware  \n",
       "3              sci.space  \n",
       "4          comp.graphics  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# if running locally on your laptop, it would be wise to take advantage of this parallelization tool\n",
    "# if running on Colab (which only has 2 cores), this tool might not be of use \n",
    "\n",
    "# check out the docs: https://github.com/nalepae/pandarallel/tree/v1.5.1\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize(progress_bar=True, nb_workers=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# load \n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize our cleaned up text data with spacy's token.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBPQXqEKE9P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# we are using spacy here to tokenize the text (after having cleaned the text)\n",
    "# what we are NOT using spacy for is to get those 300 dim vectors\n",
    "# LDA needs term frequencies, which the word2vec embedings are not \n",
    "#%%time\n",
    "\n",
    "# choosing to not use pandarallel here \n",
    "df['lemmas'] = df['content'].apply(lambda doc: [\n",
    "    token.lemma_ for token in nlp(doc) if (token.is_stop != True) and (token.is_punct != True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yvsyIpvKBlw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gersham William Meharg Subject Re Centris 610 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>[Gersham, William, Meharg, Subject, Centris, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Sheaffer Subject Re Astronomy Program O...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>[Robert, Sheaffer, Subject, Astronomy, Program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles Holden Winstead Subject ftp site for R...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>[Charles, Holden, Winstead, subject, ftp, site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ralph Buttigieg Subject Why not give 1 billion...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>[Ralph, Buttigieg, Subject, 1, billion, yearlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edward d Nobles Subject windows imagine Organi...</td>\n",
       "      <td>0</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>[Edward, d, Nobles, Subject, window, imagine, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  Gersham William Meharg Subject Re Centris 610 ...       1   \n",
       "1  Robert Sheaffer Subject Re Astronomy Program O...       2   \n",
       "2  Charles Holden Winstead Subject ftp site for R...       1   \n",
       "3  Ralph Buttigieg Subject Why not give 1 billion...       2   \n",
       "4  Edward d Nobles Subject windows imagine Organi...       0   \n",
       "\n",
       "            target_names                                             lemmas  \n",
       "0  comp.sys.mac.hardware  [Gersham, William, Meharg, Subject, Centris, 6...  \n",
       "1              sci.space  [Robert, Sheaffer, Subject, Astronomy, Program...  \n",
       "2  comp.sys.mac.hardware  [Charles, Holden, Winstead, subject, ftp, site...  \n",
       "3              sci.space  [Ralph, Buttigieg, Subject, 1, billion, yearlo...  \n",
       "4          comp.graphics  [Edward, d, Nobles, Subject, window, imagine, ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus (dtm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klqRpqtJxWc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "## the LDA model wants id2word and corpus as input \n",
    "\n",
    "# Create Dictionary\n",
    "# pass in tokens \n",
    "\n",
    "# check out docs for corpora.Dictionary: https://radimrehurek.com/gensim/corpora/dictionary.html\n",
    "id2word = corpora.Dictionary(df['lemmas'] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1', '16', '4160', '4fg', '610', '832x624', '8bit', 'BC', 'Burnaby', 'Canada']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2word[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['8bit',\n",
       " 'BC',\n",
       " 'Burnaby',\n",
       " 'Canada',\n",
       " 'Centris',\n",
       " 'Distribution',\n",
       " 'Fraser',\n",
       " 'Gersham',\n",
       " 'Lines',\n",
       " 'Meharg']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filters out the bad tokens\n",
    "id2word.filter_tokens(bad_ids=[0,1,2,3,4,5])\n",
    "[id2word[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MacDac',\n",
       " 'Smilor',\n",
       " 'applyi',\n",
       " 'internship',\n",
       " 'msmilorskatuscedu',\n",
       " 'ng',\n",
       " 'nyone',\n",
       " 'skat1psaifINNfc5',\n",
       " 'skatuscedu',\n",
       " 'smiloraludrauscedu']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2word[i] for i in range(len(id2word)-10, len(id2word),1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Document Term Frequency (Counter)\n",
    "corpus = [id2word.doc2bow(text) for text in df['lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1755, 1755)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(8, 1),\n",
       " (11, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (117, 1),\n",
       " (147, 1),\n",
       " (149, 1),\n",
       " (154, 1),\n",
       " (251, 1),\n",
       " (259, 1),\n",
       " (261, 1),\n",
       " (279, 1),\n",
       " (357, 2),\n",
       " (442, 1),\n",
       " (497, 2),\n",
       " (563, 1),\n",
       " (571, 2),\n",
       " (712, 1),\n",
       " (882, 1),\n",
       " (885, 1),\n",
       " (902, 1),\n",
       " (1588, 1),\n",
       " (2188, 1),\n",
       " (2231, 1),\n",
       " (3413, 1),\n",
       " (3451, 1),\n",
       " (3508, 1),\n",
       " (3843, 1),\n",
       " (4951, 1),\n",
       " (5647, 1),\n",
       " (8929, 2),\n",
       " (10440, 1),\n",
       " (10710, 1),\n",
       " (10711, 2),\n",
       " (10712, 1),\n",
       " (10713, 1),\n",
       " (10714, 2),\n",
       " (10916, 1),\n",
       " (12849, 1),\n",
       " (12850, 1),\n",
       " (12851, 1),\n",
       " (12852, 1),\n",
       " (12853, 1),\n",
       " (12854, 1),\n",
       " (12855, 1)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = 400\n",
    "corpus[doc_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we're doing in the cells between `id2word[200]` and `[(id2word[word_id], word_count) for word_id, word_count in corpus[5]]` is exploring how the objects we just created `id2word` and `corpus` are storing the tokens. Take some time to simply explore these objects, you might need to look up the documenation to get familar with these objects. These objects store our tokens and give them certain functionality that the LDA model needs in order to run. Thats' all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArZPxcP5LH1J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cost'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pat Subject Re Keeping Spacecraft on after Funding Cuts Organization Express Access Online Communications USA Lines 11 Distribution world NNTPPostingHost accessdigexnet Some birds require constant management for survival Pointing a sensor at the sun even when powered down may burn it out Pointing a parabolic antenna at Sol from venus orbit may trash the foci elements Even if you let teh bird drift it may get hosed by some cosmic phenomena pat'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Pat', 'Subject', 'keep', 'Spacecraft', 'Funding'], 45)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmas\"][5][:5], len(df[\"lemmas\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(8, 1), (11, 1), (17, 1), (66, 1), (113, 1)], 43)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[5][:5], len(corpus[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6K2jWxHJLOzK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Lines', 1), ('Organization', 1), ('Subject', 1), ('Online', 1), ('sun', 1)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[(id2word[word_id], word_count) for word_id, word_count in corpus[5][:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Estimate an LDA Model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.01 s, sys: 580 ms, total: 4.59 s\n",
      "Wall time: 4.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# even if you're running this notebook on CoLab (which only has 2 cores), you might still benefit from running this multicore version of the model\n",
    "# If you prefer, you can ignore this cell and use the non-multicore version of the model in the above cell. \n",
    "\n",
    "lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics = 3,\n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=10) # change workers to be N - 1, where N is the total number of cores that your computer has \n",
    "lda_multicore.save('lda_multicore.model')\n",
    "# https://radimrehurek.com/gensim/models/ldamulticore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# it's a good idea to save the model to file\n",
    "from gensim import models\n",
    "lda_multicore =  models.LdaModel.load('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the topics in LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JawR8yscLVNS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.006*\"Organization\" + 0.005*\"Space\" + 0.005*\"Subject\" + 0.005*\"space\" + '\n",
      "  '0.004*\"launch\" + 0.004*\"not\" + 0.004*\"write\" + 0.004*\"NASA\" + 0.003*\"line\" '\n",
      "  '+ 0.003*\"Lines\"'),\n",
      " (1,\n",
      "  '0.010*\"not\" + 0.009*\"Organization\" + 0.008*\"Subject\" + 0.007*\"write\" + '\n",
      "  '0.006*\"Lines\" + 0.005*\"know\" + 0.004*\"University\" + 0.004*\"line\" + '\n",
      "  '0.004*\"article\" + 0.004*\"problem\"'),\n",
      " (2,\n",
      "  '0.005*\"Organization\" + 0.005*\"write\" + 0.005*\"image\" + 0.004*\"Subject\" + '\n",
      "  '0.004*\"not\" + 0.004*\"line\" + 0.004*\"use\" + 0.003*\"system\" + '\n",
      "  '0.003*\"University\" + 0.003*\"Lines\"')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# here we are printing out the topic indices and the 10 most occuring tokens for each topic\n",
    "# this is one way to determine what topics you should create\n",
    "# However a much better way is to use the data viz tool below\n",
    "pprint(lda_multicore.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "doc_lda = lda_multicore[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(1, 0.25039184), (2, 0.7424954)],\n",
       " [(0, [2, 1]),\n",
       "  (1, [2, 1]),\n",
       "  (2, [2]),\n",
       "  (3, [2, 1]),\n",
       "  (4, [2, 1]),\n",
       "  (5, [2, 1]),\n",
       "  (6, [2, 1]),\n",
       "  (7, [2, 1]),\n",
       "  (8, [2, 1]),\n",
       "  (9, [2, 1]),\n",
       "  (10, [2, 1]),\n",
       "  (11, [2, 1]),\n",
       "  (12, [2, 1]),\n",
       "  (13, [2, 1]),\n",
       "  (14, [2, 1]),\n",
       "  (15, [1, 2]),\n",
       "  (16, [2, 1]),\n",
       "  (17, [2, 1]),\n",
       "  (18, [2, 1]),\n",
       "  (19, [2, 1]),\n",
       "  (20, [2, 1]),\n",
       "  (21, [1, 2]),\n",
       "  (22, [2, 1]),\n",
       "  (23, [2, 1]),\n",
       "  (24, [2, 1]),\n",
       "  (25, [2, 1]),\n",
       "  (26, [1, 2]),\n",
       "  (27, [1, 2]),\n",
       "  (28, [1, 2]),\n",
       "  (29, [2, 1]),\n",
       "  (30, [2, 1]),\n",
       "  (31, [2, 1]),\n",
       "  (32, [2, 1]),\n",
       "  (33, [2, 1]),\n",
       "  (34, [2, 1]),\n",
       "  (35, [2, 1]),\n",
       "  (36, [2, 1]),\n",
       "  (37, [2, 1]),\n",
       "  (38, [2, 1]),\n",
       "  (39, [2, 1]),\n",
       "  (40, [2, 1]),\n",
       "  (41, [2, 1]),\n",
       "  (42, [2, 1]),\n",
       "  (43, [2, 1])],\n",
       " [(0, [(1, 0.096580245), (2, 0.9030561)]),\n",
       "  (1, [(1, 0.0374899), (2, 0.96082133)]),\n",
       "  (2, [(2, 0.9937201)]),\n",
       "  (3, [(1, 0.32170418), (2, 1.6762093)]),\n",
       "  (4, [(1, 0.5800923), (2, 1.4195219)]),\n",
       "  (5, [(1, 0.31945893), (2, 0.6792855)]),\n",
       "  (6, [(1, 0.16739184), (2, 0.8287923)]),\n",
       "  (7, [(1, 0.017708253), (2, 2.9659107)]),\n",
       "  (8, [(1, 0.36645195), (2, 0.63256544)]),\n",
       "  (9, [(1, 0.017852668), (2, 2.9657733)]),\n",
       "  (10, [(1, 0.22405191), (2, 0.775398)]),\n",
       "  (11, [(1, 0.35333687), (2, 0.64558333)]),\n",
       "  (12, [(1, 0.24761513), (2, 0.75041664)]),\n",
       "  (13, [(1, 0.020726962), (2, 0.9572899)]),\n",
       "  (14, [(1, 0.019254778), (2, 0.96285385)]),\n",
       "  (15, [(1, 0.93437684), (2, 0.06431336)]),\n",
       "  (16, [(1, 0.23142645), (2, 0.76718724)]),\n",
       "  (17, [(1, 0.3591864), (2, 0.6397179)]),\n",
       "  (18, [(1, 0.30827457), (2, 0.6907797)]),\n",
       "  (19, [(1, 0.07697641), (2, 0.92284226)]),\n",
       "  (20, [(1, 0.11640532), (2, 0.88329214)]),\n",
       "  (21, [(1, 0.9435044), (2, 0.052387383)]),\n",
       "  (22, [(1, 0.019483034), (2, 0.9626097)]),\n",
       "  (23, [(1, 0.4241269), (2, 0.5753752)]),\n",
       "  (24, [(1, 0.17025445), (2, 0.8288161)]),\n",
       "  (25, [(1, 0.36566192), (2, 0.63209987)]),\n",
       "  (26, [(1, 0.81937647), (2, 0.17317657)]),\n",
       "  (27, [(1, 0.5672319), (2, 0.43137905)]),\n",
       "  (28, [(1, 0.51131725), (2, 0.48691672)]),\n",
       "  (29, [(1, 0.41114986), (2, 0.58813936)]),\n",
       "  (30, [(1, 0.28925738), (2, 0.7101486)]),\n",
       "  (31, [(1, 0.28736407), (2, 0.7116504)]),\n",
       "  (32, [(1, 0.18762583), (2, 0.81215256)]),\n",
       "  (33, [(1, 0.019233996), (2, 0.96288484)]),\n",
       "  (34, [(1, 0.24659106), (2, 0.75314385)]),\n",
       "  (35, [(1, 0.4340482), (2, 0.56500566)]),\n",
       "  (36, [(1, 0.33458292), (2, 0.66398436)]),\n",
       "  (37, [(1, 0.35349056), (2, 0.6460938)]),\n",
       "  (38, [(1, 0.45161113), (2, 0.54741216)]),\n",
       "  (39, [(1, 0.07741017), (2, 0.92097896)]),\n",
       "  (40, [(1, 0.09183384), (2, 0.9062359)]),\n",
       "  (41, [(1, 0.17383097), (2, 0.8260288)]),\n",
       "  (42, [(1, 0.3485174), (2, 0.6494793)]),\n",
       "  (43, [(1, 0.054743744), (2, 0.9440219)])])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [(document topic, topic weight)]\n",
    "# [word index, word topic]\n",
    "# for doc0\n",
    "doc_lda[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is topic Perplexity?\n",
    "**Perplexity** is a statistical measure of how well a probability model predicts a sample. As applied to LDA, for a given value of , you estimate the LDA model. Then given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents.\n",
    "\n",
    "Lower values of perplexity indicate lower misrepresentation of the words of the test documents by the trained topics.\n",
    "\n",
    "However, the statistic is somewhat meaningless on its own. The benefit of this statistic comes in comparing perplexity across different models with varying scores. The model with the lowest perplexity is generally considered the best.\n",
    "\n",
    "### What is topic coherence?\n",
    "Topic Coherence score measures a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is the game is a team sport, the game is played with a ball, the game demands great physical efforts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCjhr8k4LXSy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.856354670866946\n",
      "\n",
      "Coherence Score:  0.4707441338557459\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Perplexity\n",
    "# you can compute perplexity easily because it's a model attribute\n",
    "print('\\nPerplexity: ', lda_multicore.log_perplexity(corpus))  \n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "# to calculate Coherence, you need to import CoherenceModel from gensim \n",
    "coherence_model_lda = CoherenceModel(model=lda_multicore, \n",
    "                                     texts=df['lemmas'], \n",
    "                                     dictionary=id2word, \n",
    "                                     coherence='c_v')\n",
    "\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYXi480VLaHK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# this is a super useful tool for helping you determine names of topics \n",
    "# recall that you can click on 2.relevance in the bottom right-hand corner \n",
    "# to view the white paper to help you understand why lambda = 0.60 is optimial \n",
    "# this tool is taking a high dim dataset and projecting it into 2 dim in order to visualize it\n",
    "# each blue circle is a potential topic with corresponding words and their frequencies\n",
    "# ideally, there would be little overlap between topics (i.e. we want topics to be distinct)\n",
    "# to help this, we should clean the data well, train the model well, \n",
    "# however sometimes a document is meaningfully related to multiple topics \n",
    "# so this is one reason why human eyes need to be involved in this process (i.e. human judgement)\n",
    "\n",
    "\n",
    "# the 3 topics that I'm workign with here don't overlap at all \n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore,\n",
    "                              corpus, \n",
    "                              id2word)\n",
    "pyLDAvis.save_html(vis, \"./topics3.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjtXk8J3LaXC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# after training an LDA model, and if you have time, you can use this function \n",
    "# to try to find the ideal number of topics for your dataset\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.7 s, sys: 10 s, total: 57.7 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(\n",
    "    dictionary=id2word, corpus=corpus, texts=df['lemmas'], start=2, limit=7, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4452381546053546,\n",
       " 0.47487425537132727,\n",
       " 0.5235746030786393,\n",
       " 0.49770685825810307,\n",
       " 0.49302621965995463]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "recall that the higher the coherence score the better (meaning that the terms in the topic \n",
    "are related). The plot below shows that the highest scores correspond to a number of topics \n",
    "between 20 and 25\n",
    "again, this a human-in-the-loop process, you can't rely on a measurement alone to determine \n",
    "the ideal number of topics\n",
    "because of the 3 topics that I'm working with here don't really don't overlap, there is a \n",
    "clear winning for the ideal number of topics \n",
    "\"\"\"\n",
    "\n",
    "limit=7; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values, \"o-\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.4452\n",
      "Num Topics = 3  has Coherence Value of 0.4749\n",
      "Num Topics = 4  has Coherence Value of 0.5236\n",
      "Num Topics = 5  has Coherence Value of 0.4977\n",
      "Num Topics = 6  has Coherence Value of 0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahnam/opt/anaconda3/envs/ML_NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "REFERENCE_LS_DS_414_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML_NLP (Python3.7)",
   "language": "python",
   "name": "ml_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
